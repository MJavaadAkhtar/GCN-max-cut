{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from commons import *\n",
    "from dgl.nn.pytorch import GATConv, EdgeConv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TORCH_DTYPE = torch.float32\n",
    "\n",
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "def partition_weight(adj, s):\n",
    "    \"\"\"\n",
    "    Calculates the sum of weights of edges that are in different partitions.\n",
    "\n",
    "    :param adj: Adjacency matrix of the graph.\n",
    "    :param s: List indicating the partition of each edge (0 or 1).\n",
    "    :return: Sum of weights of edges in different partitions.\n",
    "    \"\"\"\n",
    "    s = np.array(s)\n",
    "    partition_matrix = np.not_equal.outer(s, s).astype(int)\n",
    "    weight = (adj * partition_matrix).sum() / 2\n",
    "    return weight\n",
    "\n",
    "def calculateAllCut(q_torch, s):\n",
    "    '''\n",
    "\n",
    "    :param q_torch: The adjacent matrix of the graph\n",
    "    :param s: The binary output from the neural network. s will be in form of [[prob1, prob2, ..., prob n], ...]\n",
    "    :return: The calculated cut loss value\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        totalCuts = len(s[0])\n",
    "        CutValue = 0\n",
    "        for i in range(totalCuts):\n",
    "            CutValue += partition_weight(q_torch, s[:,i])\n",
    "        return CutValue/2\n",
    "    return 0\n",
    "\n",
    "\n",
    "def printCombo(orig):\n",
    "    # Original dictionary\n",
    "    input_dict = orig\n",
    "\n",
    "    # Generate all permutations of the dictionary values\n",
    "    value_permutations = list(permutations(input_dict.values()))\n",
    "\n",
    "    # Create a list of dictionaries from the permutations\n",
    "    permuted_dicts = [{key: value for key, value in zip(input_dict.keys(), perm)} for perm in value_permutations]\n",
    "\n",
    "    return permuted_dicts\n",
    "\n",
    "def GetOptimal(net, dgl_graph, inp, q_torch, terminal = None):\n",
    "\n",
    "    probs = net(dgl_graph, inp, terminal)\n",
    "    binary_partitions = (probs >= 0.5).float()\n",
    "\n",
    "    for i in range(len(binary_partitions)-1):\n",
    "        if torch.sum(binary_partitions[i]) != 1:\n",
    "            binary_partitions[i] = torch.tensor([0,1,0])\n",
    "\n",
    "    cut_value_item = calculateAllCut(q_torch, binary_partitions)\n",
    "\n",
    "    return cut_value_item, binary_partitions\n",
    "\n",
    "def GetOptimalNetValue(net, dgl_graph, inp, q_torch, terminal_dict):\n",
    "    net.eval()\n",
    "    best_loss = float('inf')\n",
    "    best_binary = []\n",
    "    # if (dgl_graph.number_of_nodes() < 30):\n",
    "    #     inp = torch.ones((dgl_graph.number_of_nodes(), 30))\n",
    "\n",
    "    # find all potential combination of terminal nodes with respective indices\n",
    "\n",
    "    perm_items = printCombo(terminal_dict)\n",
    "    for i in perm_items:\n",
    "        probs = net(dgl_graph, inp, i)\n",
    "        binary_partitions = (probs >= 0.5).float()\n",
    "        # print([m for m in binary_partitions if sum(m)>1 or sum(m)==0])\n",
    "        # print(binary_partitions, q_torch)\n",
    "        cut_value_item = calculateAllCut(q_torch, binary_partitions)\n",
    "        if cut_value_item < best_loss:\n",
    "            best_loss = cut_value_item\n",
    "            best_binary = binary_partitions\n",
    "    return best_loss, best_binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 80    # e.g. 10\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        # h = override_fixed_nodes(h)\n",
    "\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test1(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "    # test_item_2 = {}\n",
    "    # test_item_2[0]=test_item[1]\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "        # embed = nn.Embedding(graph.number_of_nodes(), dim_embedding)\n",
    "        # embed = embed.type(TORCH_DTYPE).to(TORCH_DEVICE)\n",
    "        # inputs = embed.weight\n",
    "        #inputs = model.embed.weight\n",
    "        # cut_val, partition = GetOptimal(model,dgl_graph, inputs, adjacency_matrix, {terminal[0]:0, terminal[1]:1, terminal[2]:2})\n",
    "        # neural_cut.append(cut_val)\n",
    "        print(inputs, inputs.size())\n",
    "        logits = net(dgl_graph, inputs)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "        # for i in range(len(binary_partitions)-1):\n",
    "        #     if torch.sum(binary_partitions[i]) != 1:\n",
    "        #         binary_partitions[i] = torch.tensor([1,0,0])\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        # cut_value, (part_1, part_2) = nx.minimum_cut(test_item_2[0][2], test_item_2[0][3][1], test_item_2[0][3][0], flow_func=shortest_augmenting_path)\n",
    "\n",
    "        print(\"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_LossOrig.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_LossMinCut.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_LossNew.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Losscomb.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss.pth')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_3.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_4.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_5.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_6.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1('./final__80wayCut_Lossinter_min_cut_loss_7.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#with no terminal loss\n",
    "test1('./final__80wayCut_Lossinter_min_cut_loss_9.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with terminal loss\n",
    "test1('./final__80wayCut_Lossinter_min_cut_loss_9.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with terminal loss in NN\n",
    "test1('./final__80wayCut_Lossinter_min_cut_loss_9.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with terminal loss in NN\n",
    "test1('./final__80wayCut_Lossinter_min_cut_loss_9.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with terminal loss in NN\n",
    "test1('./final__80wayCut_Lossinter_min_cut_loss_9.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test2(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "    # test_item_2 = {}\n",
    "    # test_item_2[0]=test_item[1]\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "        # embed = nn.Embedding(graph.number_of_nodes(), dim_embedding)\n",
    "        # embed = embed.type(TORCH_DTYPE).to(TORCH_DEVICE)\n",
    "        # inputs = embed.weight\n",
    "        #inputs = model.embed.weight\n",
    "        # cut_val, partition = GetOptimal(model,dgl_graph, inputs, adjacency_matrix, {terminal[0]:0, terminal[1]:1, terminal[2]:2})\n",
    "        # neural_cut.append(cut_val)\n",
    "        # print(inputs, inputs.size())\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "        # for i in range(len(binary_partitions)-1):\n",
    "        #     if torch.sum(binary_partitions[i]) != 1:\n",
    "        #         binary_partitions[i] = torch.tensor([1,0,0])\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        # cut_value, (part_1, part_2) = nx.minimum_cut(test_item_2[0][2], test_item_2[0][3][1], test_item_2[0][3][0], flow_func=shortest_augmenting_path)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural 3-way min-cut value: tensor(672., dtype=torch.float64) 7.0 11.0 62.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(277., dtype=torch.float64) 9.0 5.0 66.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(498., dtype=torch.float64) 5.0 6.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(216., dtype=torch.float64) 9.0 6.0 65.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(202., dtype=torch.float64) 9.0 15.0 56.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(872., dtype=torch.float64) 10.0 12.0 58.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(752., dtype=torch.float64) 8.0 5.0 67.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(585., dtype=torch.float64) 3.0 13.0 64.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(359., dtype=torch.float64) 4.0 8.0 68.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(817., dtype=torch.float64) 13.0 8.0 59.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(337., dtype=torch.float64) 6.0 10.0 64.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_LossOrig_2.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural 3-way min-cut value: tensor(321., dtype=torch.float64) 38.0 0.0 42.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(37., dtype=torch.float64) 32.0 0.0 48.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(102., dtype=torch.float64) 25.0 0.0 55.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(135., dtype=torch.float64) 31.0 0.0 49.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(384., dtype=torch.float64) 23.0 0.0 57.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(59., dtype=torch.float64) 32.0 0.0 48.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(64., dtype=torch.float64) 29.0 0.0 51.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(776., dtype=torch.float64) 27.0 0.0 53.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(170., dtype=torch.float64) 32.0 0.0 48.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(132., dtype=torch.float64) 32.0 0.0 48.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(179., dtype=torch.float64) 39.0 0.0 41.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_Lossinter_min_cut_loss_9_new.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural 3-way min-cut value: tensor(629., dtype=torch.float64) 51.0 21.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(565., dtype=torch.float64) 69.0 5.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(734., dtype=torch.float64) 61.0 18.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(525., dtype=torch.float64) 56.0 21.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(252., dtype=torch.float64) 49.0 16.0 15.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(381., dtype=torch.float64) 61.0 18.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(209., dtype=torch.float64) 46.0 27.0 7.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(414., dtype=torch.float64) 38.0 30.0 12.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(365., dtype=torch.float64) 45.0 31.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(343., dtype=torch.float64) 48.0 20.0 12.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(601., dtype=torch.float64) 25.0 52.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_Lossinter_min_cut_loss_10_new.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural 3-way min-cut value: tensor(653., dtype=torch.float64) 76.0 2.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(10., dtype=torch.float64) 71.0 0.0 9.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(338., dtype=torch.float64) 75.0 4.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(206., dtype=torch.float64) 71.0 7.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(47., dtype=torch.float64) 72.0 0.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(91., dtype=torch.float64) 75.0 0.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(92., dtype=torch.float64) 67.0 9.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(232., dtype=torch.float64) 76.0 1.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(178., dtype=torch.float64) 69.0 5.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(297., dtype=torch.float64) 77.0 1.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "Neural 3-way min-cut value: tensor(28., dtype=torch.float64) 75.0 0.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_Lossinter_min_cut_loss_10_new.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(653., dtype=torch.float64) 76.0 2.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(10., dtype=torch.float64) 71.0 0.0 9.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(338., dtype=torch.float64) 75.0 4.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(206., dtype=torch.float64) 71.0 7.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(47., dtype=torch.float64) 62.0 10.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(91., dtype=torch.float64) 64.0 11.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(92., dtype=torch.float64) 67.0 9.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(232., dtype=torch.float64) 76.0 1.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(178., dtype=torch.float64) 69.0 5.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(297., dtype=torch.float64) 77.0 1.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(28., dtype=torch.float64) 22.0 8.0 50.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_Lossinter_min_cut_loss_10_new.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(338., dtype=torch.float64) 14.0 39.0 27.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(84., dtype=torch.float64) 7.0 55.0 18.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(478., dtype=torch.float64) 15.0 39.0 26.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(604., dtype=torch.float64) 8.0 44.0 28.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(270., dtype=torch.float64) 13.0 44.0 23.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(506., dtype=torch.float64) 18.0 38.0 24.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(610., dtype=torch.float64) 11.0 42.0 27.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(454., dtype=torch.float64) 8.0 48.0 24.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(542.5000, dtype=torch.float64) 20.0 38.0 21.0 Total Nodes:79.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 1\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(720., dtype=torch.float64) 15.0 34.0 31.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(814., dtype=torch.float64) 12.0 37.0 31.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2('./final__80wayCut_LossOrig_2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Associated with Exp2\n",
    "Removing terminal penalty, now using cloning\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(130., dtype=torch.float64) 70.0 6.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(12., dtype=torch.float64) 70.0 6.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(50., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 3.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(70., dtype=torch.float64) 70.0 5.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(180., dtype=torch.float64) 73.0 5.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(171., dtype=torch.float64) 73.0 4.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(167., dtype=torch.float64) 68.0 7.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(31., dtype=torch.float64) 72.0 2.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(210., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp2(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp2('./final__80wayCut_LossExp2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Associated with Exp1 - loss\n",
    "modified loss with terminal loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(653., dtype=torch.float64) 56.0 6.0 18.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(157., dtype=torch.float64) 69.0 1.0 10.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(619., dtype=torch.float64) 60.0 12.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(224., dtype=torch.float64) 53.0 15.0 12.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(118., dtype=torch.float64) 55.0 16.0 9.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(906., dtype=torch.float64) 50.0 20.0 10.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(627., dtype=torch.float64) 55.0 15.0 10.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(767., dtype=torch.float64) 46.0 11.0 23.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(193., dtype=torch.float64) 62.0 10.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(418., dtype=torch.float64) 53.0 13.0 14.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(802., dtype=torch.float64) 52.0 17.0 11.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        # logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp1_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Associated with Exp2 - loss\n",
    "modified loss with fixed terminal loss (using clone)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(559., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(262., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(338., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(498., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(429., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(427., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(543., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(492., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(473., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(295., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(443., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp2_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp3\n",
    "using binary loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(441., dtype=torch.float64) 12.0 5.0 63.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(134., dtype=torch.float64) 1.0 8.0 71.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(375., dtype=torch.float64) 1.0 5.0 74.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(218., dtype=torch.float64) 1.0 8.0 71.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(299., dtype=torch.float64) 1.0 10.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(105., dtype=torch.float64) 0.0 8.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(129., dtype=torch.float64) 7.0 4.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(413., dtype=torch.float64) 4.0 1.0 75.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(427., dtype=torch.float64) 1.0 1.0 78.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(330., dtype=torch.float64) 9.0 6.0 65.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(73., dtype=torch.float64) 0.0 6.0 74.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        # logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp3_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp4\n",
    "binary loss function with fixed penality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(429., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(150., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(171., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(345., dtype=torch.float64) 74.0 1.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(177., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(335., dtype=torch.float64) 73.0 1.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(375., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(350., dtype=torch.float64) 76.0 1.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(316., dtype=torch.float64) 74.0 1.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(83., dtype=torch.float64) 73.0 1.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(321., dtype=torch.float64) 75.0 1.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp4_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 5 - loss\n",
    "Changing the loss function to intake binary input and find exact loss value +  loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(127., dtype=torch.float64) 5.0 71.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(28., dtype=torch.float64) 8.0 68.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(60., dtype=torch.float64) 7.0 69.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(210., dtype=torch.float64) 5.0 72.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(133., dtype=torch.float64) 7.0 68.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(256., dtype=torch.float64) 5.0 71.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(227., dtype=torch.float64) 5.0 71.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(155., dtype=torch.float64) 5.0 72.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(176., dtype=torch.float64) 4.0 71.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(105., dtype=torch.float64) 6.0 68.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(137., dtype=torch.float64) 6.0 70.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp5_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 6 - loss\n",
    "Changing the loss function to intake binary input and find exact loss value +  loss function + terminal loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(472., dtype=torch.float64) 10.0 4.0 66.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(129., dtype=torch.float64) 1.0 8.0 71.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(302., dtype=torch.float64) 1.0 12.0 67.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(430., dtype=torch.float64) 7.0 12.0 61.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(399., dtype=torch.float64) 1.0 16.0 63.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(178., dtype=torch.float64) 7.0 18.0 55.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(302., dtype=torch.float64) 1.0 12.0 67.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(521., dtype=torch.float64) 7.0 24.0 49.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(525., dtype=torch.float64) 2.0 16.0 62.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(28., dtype=torch.float64) 0.0 6.0 74.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(640., dtype=torch.float64) 1.0 11.0 68.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        # logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp6_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 7 - loss\n",
    "Changing the loss function to intake binary input and find exact loss value +  loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(130., dtype=torch.float64) 69.0 6.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(12., dtype=torch.float64) 70.0 6.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(49., dtype=torch.float64) 73.0 3.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 3.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(70., dtype=torch.float64) 70.0 5.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(180., dtype=torch.float64) 73.0 5.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(161., dtype=torch.float64) 72.0 5.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(167., dtype=torch.float64) 68.0 7.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(31., dtype=torch.float64) 72.0 2.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(210., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./epoch300loss31906.0_80wayCut_LossExp7_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 8 - loss (2 - way cut)\n",
    "Changing the loss function to intake binary input and find exact loss value +  loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(130., dtype=torch.float64) 74.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(14., dtype=torch.float64) 73.0 7.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(33., dtype=torch.float64) 76.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(128., dtype=torch.float64) 77.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(25., dtype=torch.float64) 75.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(81., dtype=torch.float64) 76.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(90., dtype=torch.float64) 76.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(53., dtype=torch.float64) 76.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(95., dtype=torch.float64) 74.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(17., dtype=torch.float64) 78.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(159., dtype=torch.float64) 76.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    # output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 2,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp8_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 9\n",
    "Adding HA and HC, removing terminal loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(166., dtype=torch.float64) 5.0 6.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(28., dtype=torch.float64) 8.0 6.0 66.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(57., dtype=torch.float64) 7.0 4.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(176., dtype=torch.float64) 5.0 3.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(113., dtype=torch.float64) 7.0 5.0 68.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(175., dtype=torch.float64) 4.0 4.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(178., dtype=torch.float64) 4.0 4.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(90., dtype=torch.float64) 5.0 4.0 71.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(229., dtype=torch.float64) 4.0 7.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(83., dtype=torch.float64) 5.0 2.0 73.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(192., dtype=torch.float64) 6.0 6.0 68.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp9_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 10\n",
    "Adding HA and HC, keeping terminal loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(978., dtype=torch.float64) 59.0 15.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(285., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(250., dtype=torch.float64) 67.0 5.0 8.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(677., dtype=torch.float64) 56.0 12.0 12.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(302., dtype=torch.float64) 62.0 1.0 17.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(220., dtype=torch.float64) 53.0 5.0 22.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(461., dtype=torch.float64) 54.0 12.0 14.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([0., 1., 0.])2-tensor([1., 0., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(1059., dtype=torch.float64) 49.0 10.0 21.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 0., 1.]) 1-tensor([1., 0., 0.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(869., dtype=torch.float64) 37.0 24.0 19.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(692., dtype=torch.float64) 57.0 12.0 11.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([0., 1., 0.]) 1-tensor([1., 0., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(320., dtype=torch.float64) 47.0 22.0 11.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        # logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp10_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 11\n",
    "Adding HC, and node balancing loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(429., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(144., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(154., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(203., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(150., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(246., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(265., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(232., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(240., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(69., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(257., dtype=torch.float64) 79.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    # output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 2,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp11_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 12\n",
    "\n",
    "- expriment 6 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- keeping terminal loss\n",
    "- Using GATCOnv as base neural network\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(131., dtype=torch.float64) 69.0 7.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(20., dtype=torch.float64) 69.0 7.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(50., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(270., dtype=torch.float64) 73.0 3.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(52., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(170., dtype=torch.float64) 73.0 4.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(161., dtype=torch.float64) 72.0 5.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(171., dtype=torch.float64) 69.0 6.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(31., dtype=torch.float64) 72.0 2.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(210., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GATConv(in_feats, hidden_size, num_heads=1).to(device)\n",
    "        self.conv2 = GATConv(hidden_size, num_classes, num_heads=1).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs).squeeze(1)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h).squeeze(1)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp12_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 13\n",
    "\n",
    "- expriment 6 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- keeping terminal loss\n",
    "- Using Graph conv as base neural network\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(166., dtype=torch.float64) 5.0 6.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(40., dtype=torch.float64) 10.0 7.0 63.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(57., dtype=torch.float64) 7.0 4.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(176., dtype=torch.float64) 5.0 3.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(113., dtype=torch.float64) 7.0 5.0 68.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(175., dtype=torch.float64) 4.0 4.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(178., dtype=torch.float64) 4.0 4.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(90., dtype=torch.float64) 5.0 4.0 71.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(229., dtype=torch.float64) 4.0 7.0 69.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(91., dtype=torch.float64) 6.0 2.0 72.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(232., dtype=torch.float64) 6.0 4.0 70.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        dgl_graph.ndata['feat'] = adjacency_matrix\n",
    "        logits = net(dgl_graph, dgl_graph.ndata['feat'])\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp13_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 14\n",
    "\n",
    "- expriment 6 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- keeping terminal loss\n",
    "- Using Graph conv as base neural network, adding ndata attribute with more node related information\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(434., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(467., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(471., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(582., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(584., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(493., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(528., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(466., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(420., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(547., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(476., dtype=torch.float64) 1.0 78.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, hidden_size).to(device)\n",
    "        self.conv3 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv3(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        dgl_graph.ndata['feat'] = adjacency_matrix\n",
    "        logits = net(dgl_graph, dgl_graph.ndata['feat'])\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp14_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exp 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = EdgeConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = EdgeConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(130., dtype=torch.float64) 70.0 6.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(11., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(49., dtype=torch.float64) 73.0 3.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(274., dtype=torch.float64) 74.0 2.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(49., dtype=torch.float64) 70.0 6.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(171., dtype=torch.float64) 73.0 5.0 2.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(200., dtype=torch.float64) 72.0 4.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(161., dtype=torch.float64) 72.0 5.0 3.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(171., dtype=torch.float64) 69.0 6.0 5.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(31., dtype=torch.float64) 72.0 2.0 6.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(210., dtype=torch.float64) 71.0 5.0 4.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = EdgeConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = EdgeConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, adjacency_matrix)\n",
    "        logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>10):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp12_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(559., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "1 : number : Neural 3-way min-cut value: tensor(262., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "2 : number : Neural 3-way min-cut value: tensor(338., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "3 : number : Neural 3-way min-cut value: tensor(498., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "4 : number : Neural 3-way min-cut value: tensor(429., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "5 : number : Neural 3-way min-cut value: tensor(427., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "6 : number : Neural 3-way min-cut value: tensor(543., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "7 : number : Neural 3-way min-cut value: tensor(492., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "8 : number : Neural 3-way min-cut value: tensor(473., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "9 : number : Neural 3-way min-cut value: tensor(295., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n",
      "10 : number : Neural 3-way min-cut value: tensor(443., dtype=torch.float64) 78.0 1.0 1.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.])2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        h = override_fixed_nodes(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "test2('./final__80wayCut_LossExp1.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 16\n",
    "\n",
    "- expriment 16 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- removing terminal loss\n",
    "- training on dataset with 8Experiment 16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "(None,\n tensor([[0., 1., 1., 1., 0., 0., 0., 0.],\n         [1., 0., 1., 1., 0., 0., 0., 0.],\n         [1., 1., 0., 1., 0., 0., 0., 0.],\n         [1., 1., 1., 0., 1., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 1., 1., 1.],\n         [0., 0., 0., 0., 1., 0., 1., 1.],\n         [0., 0., 0., 0., 1., 1., 0., 1.],\n         [0., 0., 0., 0., 1., 1., 1., 0.]]),\n {'capacity': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n         1, 1])})"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def CreateDummyFunction(edges):\n",
    "    test_graph = nx.Graph()\n",
    "    test_graph.add_edges_from(edges)\n",
    "    test_graph.order()\n",
    "    return test_graph\n",
    "\n",
    "def DrawGraph(graph, color_map=\"white\"):\n",
    "    pos = nx.spring_layout(graph,seed=1)\n",
    "\n",
    "    # Visualize graph\n",
    "    options = {\n",
    "        \"font_size\": 16,\n",
    "        \"node_size\": 800,\n",
    "        \"node_color\": color_map,\n",
    "        \"edgecolors\": \"black\",\n",
    "        \"linewidths\": 5,\n",
    "        \"width\": 5,\n",
    "    }\n",
    "    nx.draw(graph, pos, with_labels=True, **options)\n",
    "\n",
    "    labels = nx.get_edge_attributes(graph,'weight')\n",
    "    nx.draw_networkx_edge_labels(graph,pos,edge_labels=labels)\n",
    "\n",
    "edges = [\n",
    "    (0, 1, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (0, 2, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (0, 3, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (1, 2, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (1, 3, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (2, 3, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (4, 5, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (4, 6, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (4, 7, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (5, 6, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (5, 7, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (6, 7, {\"weight\": 1, \"capacity\": 1}),\n",
    "    (3, 4, {\"weight\": 1, \"capacity\": 4})  # Single edge between the two groups\n",
    "]\n",
    "\n",
    "graph = CreateDummyFunction(edges)\n",
    "nx_directed_graph = graph.to_directed()\n",
    "graph_dgl = dgl.from_networkx(nx_graph=nx_directed_graph, edge_attrs=['capacity'])\n",
    "graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "q_torch = qubo_dict_to_torch(graph, gen_adj_matrix(graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "\n",
    "DrawGraph(graph), q_torch, graph_dgl.edata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cut_value, (part_1, part_2) = nx.minimum_cut(graph, 0, 5, flow_func=shortest_augmenting_path)\n",
    "cut_value, part_1, part_2\n",
    "\n",
    "G_copy = graph.copy(as_view=False)\n",
    "color_map = []\n",
    "for node in G_copy:\n",
    "    if node in part_1:\n",
    "        color_map.append('red')\n",
    "    elif node in part_2:\n",
    "        color_map.append('blue')\n",
    "    else:\n",
    "        color_map.append('gray')\n",
    "\n",
    "DrawGraph(G_copy, color_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        # h = override_fixed_nodes(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0],requires_grad=True) + h[0] - h[0].detach()\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0],requires_grad=True)+ h[1] - h[1].detach()\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    # output[2] = torch.tensor([0.0, 0.0, 1.0],requires_grad=True)+ h[2] - h[2].detach()\n",
    "    return output\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut val:tensor(3., dtype=torch.float64) node Sum [1. 7.]\n",
      "Terminalss: 0-tensor([1., 0.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 8 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 2,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience,\n",
    "    'nodes':n\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, './final__80wayCut_LossExp16_loss.pth')\n",
    "model.eval()\n",
    "\n",
    "logits = net(graph_dgl, q_torch)\n",
    "logits = override_fixed_nodes(logits)\n",
    "binary_partitions = (logits >= 0.5).float()\n",
    "cut = calculateAllCut(q_torch, binary_partitions)\n",
    "totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "print('cut val:' + str(cut), 'node Sum', totSum)\n",
    "print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "      \" 1-\"+ str(binary_partitions[1]))\n",
    "invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 17\n",
    "\n",
    "- expriment 17 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- removing terminal loss\n",
    "- training on dataset with 8Experiment 16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut val:tensor(1., dtype=torch.float64) node Sum [4. 4.]\n",
      "Terminalss: 0-tensor([0., 1.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 8 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 2,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience,\n",
    "    'nodes':n\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, './final__80wayCut_LossExp18_loss.pth')\n",
    "model.eval()\n",
    "\n",
    "logits = net(graph_dgl, q_torch)\n",
    "#logits = override_fixed_nodes(logits)\n",
    "binary_partitions = (logits >= 0.5).float()\n",
    "cut = calculateAllCut(q_torch, binary_partitions)\n",
    "totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "print('cut val:' + str(cut), 'node Sum', totSum)\n",
    "print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "      \" 1-\"+ str(binary_partitions[1]))\n",
    "invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "print(binary_partitions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut val:tensor(1., dtype=torch.float64) node Sum [4. 4.]\n",
      "Terminalss: 0-tensor([0., 1.]) 1-tensor([0., 1.])\n",
      "Invalids Nodes: 0\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 8 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 2,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience,\n",
    "    'nodes':n\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, './final__80wayCut_LossExp19_loss.pth')\n",
    "model.eval()\n",
    "\n",
    "logits = net(graph_dgl, q_torch)\n",
    "#logits = override_fixed_nodes(logits)\n",
    "binary_partitions = (logits >= 0.5).float()\n",
    "cut = calculateAllCut(q_torch, binary_partitions)\n",
    "totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "print('cut val:' + str(cut), 'node Sum', totSum)\n",
    "print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "      \" 1-\"+ str(binary_partitions[1]))\n",
    "invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "print(binary_partitions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut val:tensor(5., dtype=torch.float64) node Sum [2. 6.]\n",
      "Terminalss: 0-tensor([0., 1.]) 1-tensor([1., 0.])\n",
      "Invalids Nodes: 0\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]]) tensor([[2.9220e-04, 9.9971e-01],\n",
      "        [9.2511e-01, 7.4887e-02],\n",
      "        [1.8915e-02, 9.8109e-01],\n",
      "        [9.9979e-01, 2.1081e-04],\n",
      "        [1.4545e-07, 1.0000e+00],\n",
      "        [2.4033e-04, 9.9976e-01],\n",
      "        [3.1601e-01, 6.8399e-01],\n",
      "        [4.7680e-02, 9.5232e-01]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 8 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 2,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience,\n",
    "    'nodes':n\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, './final__80wayCut_LossExp20_loss.pth')\n",
    "model.eval()\n",
    "\n",
    "embed = nn.Embedding(8, dim_embedding)\n",
    "inputs = embed.weight\n",
    "logits = net(graph_dgl, inputs)\n",
    "#logits = override_fixed_nodes(logits)\n",
    "binary_partitions = (logits >= 0.5).float()\n",
    "cut = calculateAllCut(q_torch, binary_partitions)\n",
    "totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "print('cut val:' + str(cut), 'node Sum', totSum)\n",
    "print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "      \" 1-\"+ str(binary_partitions[1]))\n",
    "invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "print(binary_partitions, logits)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : number : Neural 3-way min-cut value: tensor(98., dtype=torch.float64) 9.0 4.0 67.0 Total Nodes:80.0\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 0., 1.])2-tensor([0., 1., 0.])\n",
      "Invalids Nodes: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 100, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 80 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[0] = torch.tensor([1.0, 0.0, 0.0])\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[1] = torch.tensor([0.0, 1.0, 0.0])\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[2] = torch.tensor([0.0, 0.0, 1.0])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def testexp1_loss(modelName):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=4096,patience=40)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    test_item = open_file('./testData/prepareDS.pkl')\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "    model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, modelName)\n",
    "    model.eval()\n",
    "\n",
    "    i = 0\n",
    "    neural_cut = []\n",
    "    for key, (dgl_graph, adjacency_matrix,graph, terminal) in test_item.items():\n",
    "\n",
    "        logits = net(dgl_graph, inputs)\n",
    "        #logits = override_fixed_nodes(logits)\n",
    "        binary_partitions = (logits >= 0.5).float()\n",
    "\n",
    "\n",
    "        cut = calculateAllCut(adjacency_matrix, binary_partitions)\n",
    "        # print(calculateAllCut)\n",
    "        totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "\n",
    "        print(i, \": number :\", \"Neural 3-way min-cut value: \" + str(cut) + \" \"  +  str(totSum[0])+ \" \"  +  str(totSum[1])\n",
    "              + \" \"  +  str(totSum[2])+ \" Total Nodes:\" + str(np.sum(totSum)))\n",
    "\n",
    "        print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "              \" 1-\"+ str(binary_partitions[1])+\n",
    "              \"2-\"+ str(binary_partitions[2]))\n",
    "\n",
    "        invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "        print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "\n",
    "\n",
    "        print(\"---------- \\n\")\n",
    "        i+=1\n",
    "\n",
    "        if (i>0):\n",
    "            break\n",
    "testexp1_loss('./final__80wayCut_LossExp21_loss.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def generate_graph(n, d=None, p=None, graph_type='reg', random_seed=0):\n",
    "    \"\"\"\n",
    "    Helper function to generate a NetworkX random graph of specified type,\n",
    "    given specified parameters (e.g. d-regular, d=3). Must provide one of\n",
    "    d or p, d with graph_type='reg', and p with graph_type in ['prob', 'erdos'].\n",
    "\n",
    "    Input:\n",
    "        n: Problem size\n",
    "        d: [Optional] Degree of each node in graph\n",
    "        p: [Optional] Probability of edge between two nodes\n",
    "        graph_type: Specifies graph type to generate\n",
    "        random_seed: Seed value for random generator\n",
    "    Output:\n",
    "        nx_graph: NetworkX OrderedGraph of specified type and parameters\n",
    "    \"\"\"\n",
    "    if graph_type == 'reg':\n",
    "        print(f'Generating d-regular graph with n={n}, d={d}, seed={random_seed}')\n",
    "        nx_temp = nx.random_regular_graph(d=d, n=n, seed=random_seed)\n",
    "    elif graph_type == 'reg_random':\n",
    "        print(f'Generating d-regular random graph with n={n}, d={d}')\n",
    "        nx_temp = nx.random_regular_graph(d=d, n=n)\n",
    "    elif graph_type == 'prob':\n",
    "        print(f'Generating p-probabilistic graph with n={n}, p={p}, seed={random_seed}')\n",
    "        nx_temp = nx.fast_gnp_random_graph(n, p, seed=random_seed)\n",
    "    elif graph_type == 'erdos':\n",
    "        print(f'Generating erdos-renyi graph with n={n}, p={p}, seed={random_seed}')\n",
    "        nx_temp = nx.erdos_renyi_graph(n, p, seed=random_seed)\n",
    "    else:\n",
    "        raise NotImplementedError(f'!! Graph type {graph_type} not handled !!')\n",
    "\n",
    "    # Networkx does not enforce node order by default\n",
    "    nx_temp = nx.relabel.convert_node_labels_to_integers(nx_temp)\n",
    "    # Need to pull nx graph into OrderedGraph so training will work properly\n",
    "    nx_graph = nx.Graph()\n",
    "    nx_graph.add_nodes_from(sorted(nx_temp.nodes()))\n",
    "    nx_graph.add_edges_from(nx_temp.edges)\n",
    "    nx_graph.order()\n",
    "    return nx_graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating d-regular graph with n=80, d=3, seed=1\n"
     ]
    }
   ],
   "source": [
    "# nx_generated_graph = {}\n",
    "#\n",
    "# for i in range (200):\n",
    "#     nx_graph = generate_graph(n=80, d=3, p=None, graph_type='reg', random_seed=i)\n",
    "#\n",
    "#     for u, v, d in nx_graph.edges(data=True):\n",
    "#         d['weight'] = 1\n",
    "#         d['capacity'] = 1\n",
    "#\n",
    "#     graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "#     graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "#     q_torch = qubo_dict_to_torch(nx_graph, gen_adj_matrix(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "#     terminals = [10,40,70]\n",
    "#     nx_generated_graph[i] = [graph_dgl, q_torch, nx_graph, terminals]\n",
    "\n",
    "nx_graph = generate_graph(n=80, d=3, p=None, graph_type='reg', random_seed=1)\n",
    "for u, v, d in nx_graph.edges(data=True):\n",
    "    d['weight'] = 1\n",
    "    d['capacity'] = 1\n",
    "graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "q_torch = qubo_dict_to_torch(nx_graph, gen_adj_matrix(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut val:tensor(106., dtype=torch.float64) node Sum [25. 28. 27.]\n",
      "Terminalss: 0-tensor([1., 0., 0.]) 1-tensor([0., 1., 0.]) 2-tensor([0., 0., 1.])\n",
      "Invalids Nodes: 0\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def hyperParameters(n = 80, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = 80 #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "\n",
    "n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(n=80,patience=40)\n",
    "\n",
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 3,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience,\n",
    "    'nodes':n\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "model, inputs =LoadNeuralModel(net, gnn_hypers, TORCH_DEVICE, './final__80MaxwayCut_LossExp1_loss.pth')\n",
    "model.eval()\n",
    "\n",
    "logits = net(graph_dgl, q_torch)\n",
    "#logits = override_fixed_nodes(logits)\n",
    "binary_partitions = (logits >= 0.5).float()\n",
    "cut = calculateAllCut(q_torch, binary_partitions)\n",
    "totSum = np.sum(binary_partitions.numpy(), axis=0)\n",
    "print('cut val:' + str(cut), 'node Sum', totSum)\n",
    "print(\"Terminalss: 0-\"+ str(binary_partitions[0])+\n",
    "      \" 1-\"+ str(binary_partitions[1]) + \" 2-\"+ str(binary_partitions[2]))\n",
    "invalidsCount = [m for m in binary_partitions if sum(m)!=1]\n",
    "print(\"Invalids Nodes: \" + str( len(invalidsCount)))\n",
    "print(binary_partitions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural 2-way min-cut value: 100.0\n",
      "Neural 2-way min-cut value: 100.0\n"
     ]
    }
   ],
   "source": [
    "# neural_cut = test2()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# heurestic_cut_k = LoadData('./testData/heurestic_cut_k.pkl')\n",
    "# #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# from matplotlib.ticker import ScalarFormatter\n",
    "# def barPlot_2(heurestic_cut, neural_cut):\n",
    "#     # Example data\n",
    "#     n_groups = len(heurestic_cut)\n",
    "#     index = np.arange(n_groups)\n",
    "#     bar_width = 0.35\n",
    "#\n",
    "#     # Create bars\n",
    "#     plt.figure(figsize=(30, 6))\n",
    "#     bar1 = plt.bar(index, heurestic_cut, bar_width, label='Heurestic')\n",
    "#     bar2 = plt.bar(index + bar_width, neural_cut, bar_width, label='Neural Network')\n",
    "#\n",
    "#     # Add details\n",
    "#     plt.xlabel('Graph Number')\n",
    "#     plt.ylabel('Minimum Cut Value')\n",
    "#     plt.title('Comparison of Minimum Cut Values by Algorithm')\n",
    "#     # plt.xticks(index + bar_width / 2, range(1, n_groups + 1))\n",
    "#     plt.legend()\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.gca().yaxis.set(major_formatter=ScalarFormatter(), minor_formatter=ScalarFormatter());\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 3000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barPlot_2( heurestic_cut_k, neural_cut)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}