{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from commons import *\n",
    "from dgl.nn.pytorch import GATConv, EdgeConv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TORCH_DTYPE = torch.float32\n",
    "def get_gnn(n_nodes, gnn_hypers, opt_params, torch_device, torch_dtype):\n",
    "    \"\"\"\n",
    "    Generate GNN instance with specified structure. Creates GNN, retrieves embedding layer,\n",
    "    and instantiates ADAM optimizer given those.\n",
    "\n",
    "    Input:\n",
    "        n_nodes: Problem size (number of nodes in graph)\n",
    "        gnn_hypers: Hyperparameters relevant to GNN structure\n",
    "        opt_params: Hyperparameters relevant to ADAM optimizer\n",
    "        torch_device: Whether to load pytorch variables onto CPU or GPU\n",
    "        torch_dtype: Datatype to use for pytorch variables\n",
    "    Output:\n",
    "        net: GNN instance\n",
    "        embed: Embedding layer to use as input to GNN\n",
    "        optimizer: ADAM optimizer instance\n",
    "    \"\"\"\n",
    "    dim_embedding = gnn_hypers['dim_embedding']\n",
    "    hidden_dim = gnn_hypers['hidden_dim']\n",
    "    dropout = gnn_hypers['dropout']\n",
    "    number_classes = gnn_hypers['number_classes']\n",
    "\n",
    "    # instantiate the GNN\n",
    "    net = GCNSoftmax(dim_embedding, hidden_dim, number_classes, dropout, torch_device)\n",
    "    net = net.type(torch_dtype).to(torch_device)\n",
    "    embed = nn.Embedding(n_nodes, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "    # set up Adam optimizer\n",
    "    params = chain(net.parameters(), embed.parameters())\n",
    "    optimizer = torch.optim.Adam(params, **opt_params)\n",
    "    return net, embed, optimizer\n",
    "\n",
    "def partition_weight(adj, s):\n",
    "    \"\"\"\n",
    "    Calculates the sum of weights of edges that are in different partitions.\n",
    "\n",
    "    :param adj: Adjacency matrix of the graph.\n",
    "    :param s: List indicating the partition of each edge (0 or 1).\n",
    "    :return: Sum of weights of edges in different partitions.\n",
    "    \"\"\"\n",
    "    s = np.array(s)\n",
    "    partition_matrix = np.not_equal.outer(s, s).astype(int)\n",
    "    weight = (adj * partition_matrix).sum() / 2\n",
    "    return weight\n",
    "\n",
    "import torch\n",
    "\n",
    "def partition_weight2(adj, s):\n",
    "    \"\"\"\n",
    "    Calculates the sum of weights of edges that are in different partitions.\n",
    "\n",
    "    :param adj: Adjacency matrix of the graph as a PyTorch tensor.\n",
    "    :param s: Tensor indicating the partition of each node (0 or 1).\n",
    "    :return: Sum of weights of edges in different partitions.\n",
    "    \"\"\"\n",
    "    # Ensure s is a tensor\n",
    "    # s = torch.tensor(s, dtype=torch.float32)\n",
    "\n",
    "    # Compute outer difference to create partition matrix\n",
    "    s = s.unsqueeze(0)  # Convert s to a row vector\n",
    "    t = s.t()           # Transpose s to a column vector\n",
    "    partition_matrix = (s != t).float()  # Compute outer product and convert boolean to float\n",
    "\n",
    "    # Calculate the weight of edges between different partitions\n",
    "    weight = (adj * partition_matrix).sum() / 2\n",
    "\n",
    "    return weight\n",
    "\n",
    "def calculateAllCut(q_torch, s):\n",
    "    '''\n",
    "\n",
    "    :param q_torch: The adjacent matrix of the graph\n",
    "    :param s: The binary output from the neural network. s will be in form of [[prob1, prob2, ..., prob n], ...]\n",
    "    :return: The calculated cut loss value\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        totalCuts = len(s[0])\n",
    "        CutValue = 0\n",
    "        for i in range(totalCuts):\n",
    "            CutValue += partition_weight2(q_torch, s[:,i])\n",
    "        return CutValue/2\n",
    "    return 0\n",
    "\n",
    "def hyperParameters(n = 80, d = 3, p = None, graph_type = 'reg', number_epochs = int(1e5),\n",
    "                    learning_rate = 1e-4, PROB_THRESHOLD = 0.5, tol = 1e-4, patience = 100):\n",
    "    dim_embedding = n #int(np.sqrt(4096))    # e.g. 10, used to be the one before\n",
    "    hidden_dim = int(dim_embedding/2)\n",
    "\n",
    "    return n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim\n",
    "def FIndAC(graph):\n",
    "    max_degree = max(dict(graph.degree()).values())\n",
    "    A_initial = max_degree + 1  # A is set to be one more than the maximum degree\n",
    "    C_initial = max_degree / 2  # C is set to half the maximum degree\n",
    "\n",
    "    return A_initial, C_initial\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HyperParameters initialization and related functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def printCombo(orig):\n",
    "    # Original dictionary\n",
    "    input_dict = orig\n",
    "\n",
    "    # Generate all permutations of the dictionary values\n",
    "    value_permutations = list(permutations(input_dict.values()))\n",
    "\n",
    "    # Create a list of dictionaries from the permutations\n",
    "    permuted_dicts = [{key: value for key, value in zip(input_dict.keys(), perm)} for perm in value_permutations]\n",
    "\n",
    "    return permuted_dicts\n",
    "\n",
    "def GetOptimalNetValue(net, dgl_graph, inp, q_torch, terminal_dict):\n",
    "    net.eval()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    if (dgl_graph.number_of_nodes() < 30):\n",
    "        inp = torch.ones((dgl_graph.number_of_nodes(), 30))\n",
    "\n",
    "    # find all potential combination of terminal nodes with respective indices\n",
    "\n",
    "    perm_items = printCombo(terminal_dict)\n",
    "    for i in perm_items:\n",
    "        probs = net(dgl_graph, inp, i)\n",
    "        binary_partitions = (probs >= 0.5).float()\n",
    "        cut_value_item = calculateAllCut(q_torch, binary_partitions)\n",
    "        if cut_value_item < best_loss:\n",
    "            best_loss = cut_value_item\n",
    "    return best_loss\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hamiltonian loss function\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def terminal_independence_penalty(s, terminal_nodes):\n",
    "    \"\"\"\n",
    "    Calculate a penalty that enforces each terminal node to be in a distinct partition.\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param terminal_nodes: A list of indices for terminal nodes.\n",
    "    :return: The penalty term.\n",
    "    \"\"\"\n",
    "    penalty = 0\n",
    "    num_terminals = len(terminal_nodes)\n",
    "    # Compare each pair of terminal nodes\n",
    "    for i in range(num_terminals):\n",
    "        for j in range(i + 1, num_terminals):\n",
    "            # Calculate the dot product of the probability vectors for the two terminals\n",
    "            dot_product = torch.dot(s[terminal_nodes[i]], s[terminal_nodes[j]])\n",
    "            # Penalize the similarity in their partition assignments (dot product should be close to 0)\n",
    "            penalty += dot_product\n",
    "    return penalty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calculate_HA_vectorized(s):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of HA.\n",
    "    :param s: A binary matrix of size |V| x |K| where s[i][j] is 1 if vertex i is in partition j.\n",
    "    :return: The HA value.\n",
    "    \"\"\"\n",
    "    # HA = ∑v∈V(∑k∈K(sv,k)−1)^2\n",
    "    HA = torch.sum((torch.sum(s, axis=1) - 1) ** 2)\n",
    "    return HA\n",
    "\n",
    "def calculate_HC_min_cut_intra_inter(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of HC to minimize cut size.\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The HC value focusing on minimizing edge weights between partitions.\n",
    "    \"\"\"\n",
    "    HC = 0\n",
    "    K = s.shape[1]\n",
    "    for k in range(K):\n",
    "        for l in range(k + 1, K):\n",
    "            partition_k = s[:, k].unsqueeze(1) * s[:, k].unsqueeze(0)  # Probability node pair both in partition k\n",
    "            partition_l = s[:, l].unsqueeze(1) * s[:, l].unsqueeze(0)  # Probability node pair both in partition l\n",
    "            # Edges between partitions k and l\n",
    "            inter_partition_edges = adjacency_matrix * (partition_k + partition_l)\n",
    "            HC += torch.sum(inter_partition_edges)\n",
    "\n",
    "    return HC\n",
    "\n",
    "def calculate_HC_min_cut_intra_inter2(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of HC to minimize cut size.\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The HC value focusing on minimizing edge weights between partitions.\n",
    "    \"\"\"\n",
    "    HC = 0\n",
    "    K = s.shape[1]\n",
    "    for k in range(K):\n",
    "        for l in range(k + 1, K):\n",
    "            partition_k = s[:, k].unsqueeze(1) * s[:, k].unsqueeze(0)  # Probability node pair both in partition k\n",
    "            partition_l = s[:, l].unsqueeze(1) * s[:, l].unsqueeze(0)  # Probability node pair both in partition l\n",
    "            # Edges between partitions k and l\n",
    "            inter_partition_edges = adjacency_matrix * (partition_k + partition_l)\n",
    "            HC += torch.sum(inter_partition_edges)\n",
    "\n",
    "    return HC\n",
    "\n",
    "def calculate_HC_min_cut_new(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Differentiable calculation of HC for minimizing edge weights between different partitions.\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The HC value, focusing on minimizing edge weights between partitions.\n",
    "    \"\"\"\n",
    "    K = s.shape[1]\n",
    "    V = s.shape[0]\n",
    "\n",
    "    # Create a full partition matrix indicating the likelihood of each node pair being in the same partition\n",
    "    partition_matrix = torch.matmul(s, s.T)\n",
    "\n",
    "    # Calculate the complement matrix, which indicates the likelihood of node pairs being in different partitions\n",
    "    complement_matrix = 1 - partition_matrix\n",
    "\n",
    "    # Apply adjacency matrix to only consider actual edges and their weights\n",
    "    inter_partition_edges = adjacency_matrix * complement_matrix\n",
    "\n",
    "    # Summing up all contributions for edges between different partitions\n",
    "    HC = torch.sum(inter_partition_edges)\n",
    "\n",
    "    return HC\n",
    "\n",
    "def calculate_HC_vectorized_old(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of HC.\n",
    "    :param s: A binary matrix of size |V| x |K|.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The HC value.\n",
    "    \"\"\"\n",
    "    # HC = ∑(u,v)∈E(1−∑k∈K(su,k*sv,k))*adjacency_matrix[u,v]\n",
    "    K = s.shape[1]\n",
    "    # Outer product to find pairs of vertices in the same partition and then weight by the adjacency matrix\n",
    "    prod = adjacency_matrix * (1 - s @ s.T)\n",
    "    HC = torch.sum(prod)\n",
    "    return HC\n",
    "import torch\n",
    "\n",
    "def min_cut_loss(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute a differentiable min-cut loss for a graph given node partition probabilities.\n",
    "\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The expected min-cut value, computed as a differentiable loss.\n",
    "    \"\"\"\n",
    "    V = s.size(0)  # Number of nodes\n",
    "    K = s.size(1)  # Number of partitions\n",
    "\n",
    "    # Ensure the partition matrix s sums to 1 over partitions\n",
    "    s = torch.softmax(s, dim=1)\n",
    "\n",
    "    # Compute the expected weight of edges within each partition\n",
    "    intra_partition_cut = torch.zeros((K, K), dtype=torch.float32)\n",
    "    for k in range(K):\n",
    "        for l in range(k + 1, K):\n",
    "            # Probability that a node pair (i, j) is split between partitions k and l\n",
    "            partition_k = s[:, k].unsqueeze(1)  # Shape: V x 1\n",
    "            partition_l = s[:, l].unsqueeze(0)  # Shape: 1 x V\n",
    "\n",
    "            # Compute the expected weight of the cut edges between partitions k and l\n",
    "            cut_weight = adjacency_matrix * (partition_k @ partition_l)\n",
    "            intra_partition_cut[k, l] = torch.sum(cut_weight)\n",
    "\n",
    "    # Sum up all contributions to get the total expected min-cut value\n",
    "    total_cut_weight = torch.sum(intra_partition_cut)\n",
    "\n",
    "    return total_cut_weight\n",
    "\n",
    "import torch\n",
    "\n",
    "# def min_cut_loss(s, adjacency_matrix):\n",
    "#     \"\"\"\n",
    "#     Compute a differentiable min-cut loss for a graph given node partition probabilities.\n",
    "#\n",
    "#     :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "#     :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "#     :return: The expected min-cut value, computed as a differentiable loss.\n",
    "#     \"\"\"\n",
    "#     V = s.size(0)  # Number of nodes\n",
    "#     K = s.size(1)  # Number of partitions\n",
    "#\n",
    "#     # Ensure the partition matrix s sums to 1 over partitions\n",
    "#     # s = torch.softmax(s, dim=1)\n",
    "#\n",
    "#     # Compute the expected weight of cut edges between each pair of partitions\n",
    "#     total_cut_weight = 0\n",
    "#     for k in range(K):\n",
    "#         for l in range(k + 1, K):\n",
    "#             # Probability that a node pair (i, j) is split between partitions k and l\n",
    "#             partition_k = s[:, k].unsqueeze(1)  # Shape: V x 1\n",
    "#             partition_l = s[:, l].unsqueeze(0)  # Shape: 1 x V\n",
    "#\n",
    "#             # Compute the expected weight of the cut edges between partitions k and l\n",
    "#             cut_weight = adjacency_matrix * (partition_k @ partition_l)\n",
    "#             total_cut_weight += torch.sum(cut_weight)\n",
    "#\n",
    "#     return total_cut_weight\n",
    "\n",
    "\n",
    "def calculate_HC_vectorized(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of HC for soft partitioning.\n",
    "    :param s: A probability matrix of size |V| x |K| where s[i][j] is the probability of vertex i being in partition j.\n",
    "    :param adjacency_matrix: A matrix representing the graph where the value at [i][j] is the weight of the edge between i and j.\n",
    "    :return: The HC value.\n",
    "    \"\"\"\n",
    "    # Initialize HC to 0\n",
    "    HC = 0\n",
    "\n",
    "    # Iterate over each partition to calculate its contribution to HC\n",
    "    for k in range(s.shape[1]):\n",
    "        # Compute the probability matrix for partition k\n",
    "        partition_prob_matrix = s[:, k].unsqueeze(1) * s[:, k].unsqueeze(0)\n",
    "\n",
    "        # Compute the contribution to HC for partition k\n",
    "        HC_k =adjacency_matrix * (1 - partition_prob_matrix)\n",
    "        # Sum up the contributions for partition k\n",
    "        HC += torch.sum(HC_k, dim=(0, 1))\n",
    "\n",
    "    # Since we've summed up the partition contributions twice (due to symmetry), divide by 2\n",
    "    HC = HC / 2\n",
    "\n",
    "    return HC\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor(30.)\n",
      "tensor(10.)\n",
      "tensor(10.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "s = torch.Tensor([[0,1,0],[0,1,0],[0,0,1]])\n",
    "# print(calculate_HA_vectorized(s))\n",
    "# print(calculate_HA_vectorized(torch.Tensor([[0,0.9,0.9],[0.9,0.9,0],[0,0,0.9]])))\n",
    "terminal_loss = torch.abs(s[0] - s[1]-s[2])\n",
    "# print(terminal_loss)\n",
    "# print(10 * (1 - terminal_loss))\n",
    "# print(torch.sum(10 * (1 - terminal_loss)))\n",
    "print(torch.abs(s[0] - s[1]))\n",
    "print(torch.abs(s[0] - s[2]))\n",
    "print(torch.abs(s[2] - s[1]))\n",
    "\n",
    "print(torch.sum(10 * (1-torch.abs(s[0] - s[1]))))\n",
    "print(torch.sum(10 * (1-torch.abs(s[0] - s[2]))))\n",
    "print(torch.sum(10 * (1-torch.abs(s[2] - s[1]))))\n",
    "print(terminal_independence_penalty(s, [0,1,2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def generate_graph(n, d=None, p=None, graph_type='reg', random_seed=0):\n",
    "    \"\"\"\n",
    "    Helper function to generate a NetworkX random graph of specified type,\n",
    "    given specified parameters (e.g. d-regular, d=3). Must provide one of\n",
    "    d or p, d with graph_type='reg', and p with graph_type in ['prob', 'erdos'].\n",
    "\n",
    "    Input:\n",
    "        n: Problem size\n",
    "        d: [Optional] Degree of each node in graph\n",
    "        p: [Optional] Probability of edge between two nodes\n",
    "        graph_type: Specifies graph type to generate\n",
    "        random_seed: Seed value for random generator\n",
    "    Output:\n",
    "        nx_graph: NetworkX OrderedGraph of specified type and parameters\n",
    "    \"\"\"\n",
    "    if graph_type == 'reg':\n",
    "        print(f'Generating d-regular graph with n={n}, d={d}, seed={random_seed}')\n",
    "        nx_temp = nx.random_regular_graph(d=d, n=n, seed=random_seed)\n",
    "    elif graph_type == 'reg_random':\n",
    "        print(f'Generating d-regular random graph with n={n}, d={d}')\n",
    "        nx_temp = nx.random_regular_graph(d=d, n=n)\n",
    "    elif graph_type == 'prob':\n",
    "        print(f'Generating p-probabilistic graph with n={n}, p={p}, seed={random_seed}')\n",
    "        nx_temp = nx.fast_gnp_random_graph(n, p, seed=random_seed)\n",
    "    elif graph_type == 'erdos':\n",
    "        print(f'Generating erdos-renyi graph with n={n}, p={p}, seed={random_seed}')\n",
    "        nx_temp = nx.erdos_renyi_graph(n, p, seed=random_seed)\n",
    "    else:\n",
    "        raise NotImplementedError(f'!! Graph type {graph_type} not handled !!')\n",
    "\n",
    "    # Networkx does not enforce node order by default\n",
    "    nx_temp = nx.relabel.convert_node_labels_to_integers(nx_temp)\n",
    "    # Need to pull nx graph into OrderedGraph so training will work properly\n",
    "    nx_graph = nx.Graph()\n",
    "    nx_graph.add_nodes_from(sorted(nx_temp.nodes()))\n",
    "    nx_graph.add_edges_from(nx_temp.edges)\n",
    "    nx_graph.order()\n",
    "    return nx_graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Graphs\n",
    "\n",
    "### Generating graph 200 training graph\n",
    "\n",
    "- Nodes = 80\n",
    "- Degree  = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# nx_generated_graph = {}\n",
    "#\n",
    "# for i in range (200):\n",
    "#     nx_graph = generate_graph(n=80, d=3, p=None, graph_type='reg', random_seed=i)\n",
    "#\n",
    "#     for u, v, d in nx_graph.edges(data=True):\n",
    "#         d['weight'] = 1\n",
    "#         d['capacity'] = 1\n",
    "#\n",
    "#     graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "#     graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "#     q_torch = qubo_dict_to_torch(nx_graph, gen_adj_matrix(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "#     terminals = [10,40,70]\n",
    "#     nx_generated_graph[i] = [graph_dgl, q_torch, nx_graph, terminals]\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# save_object(nx_generated_graph, './testData/nx_generated_graph_n80_d3_t200.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating graph 200 training graph\n",
    "\n",
    "- Nodes = 500\n",
    "- Degree  = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating d-regular graph with n=500, d=3, seed=0\n",
      "Generating d-regular graph with n=500, d=3, seed=1\n",
      "Generating d-regular graph with n=500, d=3, seed=2\n",
      "Generating d-regular graph with n=500, d=3, seed=3\n",
      "Generating d-regular graph with n=500, d=3, seed=4\n",
      "Generating d-regular graph with n=500, d=3, seed=5\n",
      "Generating d-regular graph with n=500, d=3, seed=6\n",
      "Generating d-regular graph with n=500, d=3, seed=7\n",
      "Generating d-regular graph with n=500, d=3, seed=8\n",
      "Generating d-regular graph with n=500, d=3, seed=9\n",
      "Generating d-regular graph with n=500, d=3, seed=10\n",
      "Generating d-regular graph with n=500, d=3, seed=11\n",
      "Generating d-regular graph with n=500, d=3, seed=12\n",
      "Generating d-regular graph with n=500, d=3, seed=13\n",
      "Generating d-regular graph with n=500, d=3, seed=14\n",
      "Generating d-regular graph with n=500, d=3, seed=15\n",
      "Generating d-regular graph with n=500, d=3, seed=16\n",
      "Generating d-regular graph with n=500, d=3, seed=17\n",
      "Generating d-regular graph with n=500, d=3, seed=18\n",
      "Generating d-regular graph with n=500, d=3, seed=19\n",
      "Generating d-regular graph with n=500, d=3, seed=20\n",
      "Generating d-regular graph with n=500, d=3, seed=21\n",
      "Generating d-regular graph with n=500, d=3, seed=22\n",
      "Generating d-regular graph with n=500, d=3, seed=23\n",
      "Generating d-regular graph with n=500, d=3, seed=24\n",
      "Generating d-regular graph with n=500, d=3, seed=25\n",
      "Generating d-regular graph with n=500, d=3, seed=26\n",
      "Generating d-regular graph with n=500, d=3, seed=27\n",
      "Generating d-regular graph with n=500, d=3, seed=28\n",
      "Generating d-regular graph with n=500, d=3, seed=29\n",
      "Generating d-regular graph with n=500, d=3, seed=30\n",
      "Generating d-regular graph with n=500, d=3, seed=31\n",
      "Generating d-regular graph with n=500, d=3, seed=32\n",
      "Generating d-regular graph with n=500, d=3, seed=33\n",
      "Generating d-regular graph with n=500, d=3, seed=34\n",
      "Generating d-regular graph with n=500, d=3, seed=35\n",
      "Generating d-regular graph with n=500, d=3, seed=36\n",
      "Generating d-regular graph with n=500, d=3, seed=37\n",
      "Generating d-regular graph with n=500, d=3, seed=38\n",
      "Generating d-regular graph with n=500, d=3, seed=39\n",
      "Generating d-regular graph with n=500, d=3, seed=40\n",
      "Generating d-regular graph with n=500, d=3, seed=41\n",
      "Generating d-regular graph with n=500, d=3, seed=42\n",
      "Generating d-regular graph with n=500, d=3, seed=43\n",
      "Generating d-regular graph with n=500, d=3, seed=44\n",
      "Generating d-regular graph with n=500, d=3, seed=45\n",
      "Generating d-regular graph with n=500, d=3, seed=46\n",
      "Generating d-regular graph with n=500, d=3, seed=47\n",
      "Generating d-regular graph with n=500, d=3, seed=48\n",
      "Generating d-regular graph with n=500, d=3, seed=49\n",
      "Generating d-regular graph with n=500, d=3, seed=50\n",
      "Generating d-regular graph with n=500, d=3, seed=51\n",
      "Generating d-regular graph with n=500, d=3, seed=52\n",
      "Generating d-regular graph with n=500, d=3, seed=53\n",
      "Generating d-regular graph with n=500, d=3, seed=54\n",
      "Generating d-regular graph with n=500, d=3, seed=55\n",
      "Generating d-regular graph with n=500, d=3, seed=56\n",
      "Generating d-regular graph with n=500, d=3, seed=57\n",
      "Generating d-regular graph with n=500, d=3, seed=58\n",
      "Generating d-regular graph with n=500, d=3, seed=59\n",
      "Generating d-regular graph with n=500, d=3, seed=60\n",
      "Generating d-regular graph with n=500, d=3, seed=61\n",
      "Generating d-regular graph with n=500, d=3, seed=62\n",
      "Generating d-regular graph with n=500, d=3, seed=63\n",
      "Generating d-regular graph with n=500, d=3, seed=64\n",
      "Generating d-regular graph with n=500, d=3, seed=65\n",
      "Generating d-regular graph with n=500, d=3, seed=66\n",
      "Generating d-regular graph with n=500, d=3, seed=67\n",
      "Generating d-regular graph with n=500, d=3, seed=68\n",
      "Generating d-regular graph with n=500, d=3, seed=69\n",
      "Generating d-regular graph with n=500, d=3, seed=70\n",
      "Generating d-regular graph with n=500, d=3, seed=71\n",
      "Generating d-regular graph with n=500, d=3, seed=72\n",
      "Generating d-regular graph with n=500, d=3, seed=73\n",
      "Generating d-regular graph with n=500, d=3, seed=74\n",
      "Generating d-regular graph with n=500, d=3, seed=75\n",
      "Generating d-regular graph with n=500, d=3, seed=76\n",
      "Generating d-regular graph with n=500, d=3, seed=77\n",
      "Generating d-regular graph with n=500, d=3, seed=78\n",
      "Generating d-regular graph with n=500, d=3, seed=79\n",
      "Generating d-regular graph with n=500, d=3, seed=80\n",
      "Generating d-regular graph with n=500, d=3, seed=81\n",
      "Generating d-regular graph with n=500, d=3, seed=82\n",
      "Generating d-regular graph with n=500, d=3, seed=83\n",
      "Generating d-regular graph with n=500, d=3, seed=84\n",
      "Generating d-regular graph with n=500, d=3, seed=85\n",
      "Generating d-regular graph with n=500, d=3, seed=86\n",
      "Generating d-regular graph with n=500, d=3, seed=87\n",
      "Generating d-regular graph with n=500, d=3, seed=88\n",
      "Generating d-regular graph with n=500, d=3, seed=89\n",
      "Generating d-regular graph with n=500, d=3, seed=90\n",
      "Generating d-regular graph with n=500, d=3, seed=91\n",
      "Generating d-regular graph with n=500, d=3, seed=92\n",
      "Generating d-regular graph with n=500, d=3, seed=93\n",
      "Generating d-regular graph with n=500, d=3, seed=94\n",
      "Generating d-regular graph with n=500, d=3, seed=95\n",
      "Generating d-regular graph with n=500, d=3, seed=96\n",
      "Generating d-regular graph with n=500, d=3, seed=97\n",
      "Generating d-regular graph with n=500, d=3, seed=98\n",
      "Generating d-regular graph with n=500, d=3, seed=99\n",
      "Generating d-regular graph with n=500, d=3, seed=100\n",
      "Generating d-regular graph with n=500, d=3, seed=101\n",
      "Generating d-regular graph with n=500, d=3, seed=102\n",
      "Generating d-regular graph with n=500, d=3, seed=103\n",
      "Generating d-regular graph with n=500, d=3, seed=104\n",
      "Generating d-regular graph with n=500, d=3, seed=105\n",
      "Generating d-regular graph with n=500, d=3, seed=106\n",
      "Generating d-regular graph with n=500, d=3, seed=107\n",
      "Generating d-regular graph with n=500, d=3, seed=108\n",
      "Generating d-regular graph with n=500, d=3, seed=109\n",
      "Generating d-regular graph with n=500, d=3, seed=110\n",
      "Generating d-regular graph with n=500, d=3, seed=111\n",
      "Generating d-regular graph with n=500, d=3, seed=112\n",
      "Generating d-regular graph with n=500, d=3, seed=113\n",
      "Generating d-regular graph with n=500, d=3, seed=114\n",
      "Generating d-regular graph with n=500, d=3, seed=115\n",
      "Generating d-regular graph with n=500, d=3, seed=116\n",
      "Generating d-regular graph with n=500, d=3, seed=117\n",
      "Generating d-regular graph with n=500, d=3, seed=118\n",
      "Generating d-regular graph with n=500, d=3, seed=119\n",
      "Generating d-regular graph with n=500, d=3, seed=120\n",
      "Generating d-regular graph with n=500, d=3, seed=121\n",
      "Generating d-regular graph with n=500, d=3, seed=122\n",
      "Generating d-regular graph with n=500, d=3, seed=123\n",
      "Generating d-regular graph with n=500, d=3, seed=124\n",
      "Generating d-regular graph with n=500, d=3, seed=125\n",
      "Generating d-regular graph with n=500, d=3, seed=126\n",
      "Generating d-regular graph with n=500, d=3, seed=127\n",
      "Generating d-regular graph with n=500, d=3, seed=128\n",
      "Generating d-regular graph with n=500, d=3, seed=129\n",
      "Generating d-regular graph with n=500, d=3, seed=130\n",
      "Generating d-regular graph with n=500, d=3, seed=131\n",
      "Generating d-regular graph with n=500, d=3, seed=132\n",
      "Generating d-regular graph with n=500, d=3, seed=133\n",
      "Generating d-regular graph with n=500, d=3, seed=134\n",
      "Generating d-regular graph with n=500, d=3, seed=135\n",
      "Generating d-regular graph with n=500, d=3, seed=136\n",
      "Generating d-regular graph with n=500, d=3, seed=137\n",
      "Generating d-regular graph with n=500, d=3, seed=138\n",
      "Generating d-regular graph with n=500, d=3, seed=139\n",
      "Generating d-regular graph with n=500, d=3, seed=140\n",
      "Generating d-regular graph with n=500, d=3, seed=141\n",
      "Generating d-regular graph with n=500, d=3, seed=142\n",
      "Generating d-regular graph with n=500, d=3, seed=143\n",
      "Generating d-regular graph with n=500, d=3, seed=144\n",
      "Generating d-regular graph with n=500, d=3, seed=145\n",
      "Generating d-regular graph with n=500, d=3, seed=146\n",
      "Generating d-regular graph with n=500, d=3, seed=147\n",
      "Generating d-regular graph with n=500, d=3, seed=148\n",
      "Generating d-regular graph with n=500, d=3, seed=149\n",
      "Generating d-regular graph with n=500, d=3, seed=150\n",
      "Generating d-regular graph with n=500, d=3, seed=151\n",
      "Generating d-regular graph with n=500, d=3, seed=152\n",
      "Generating d-regular graph with n=500, d=3, seed=153\n",
      "Generating d-regular graph with n=500, d=3, seed=154\n",
      "Generating d-regular graph with n=500, d=3, seed=155\n",
      "Generating d-regular graph with n=500, d=3, seed=156\n",
      "Generating d-regular graph with n=500, d=3, seed=157\n",
      "Generating d-regular graph with n=500, d=3, seed=158\n",
      "Generating d-regular graph with n=500, d=3, seed=159\n",
      "Generating d-regular graph with n=500, d=3, seed=160\n",
      "Generating d-regular graph with n=500, d=3, seed=161\n",
      "Generating d-regular graph with n=500, d=3, seed=162\n",
      "Generating d-regular graph with n=500, d=3, seed=163\n",
      "Generating d-regular graph with n=500, d=3, seed=164\n",
      "Generating d-regular graph with n=500, d=3, seed=165\n",
      "Generating d-regular graph with n=500, d=3, seed=166\n",
      "Generating d-regular graph with n=500, d=3, seed=167\n",
      "Generating d-regular graph with n=500, d=3, seed=168\n",
      "Generating d-regular graph with n=500, d=3, seed=169\n",
      "Generating d-regular graph with n=500, d=3, seed=170\n",
      "Generating d-regular graph with n=500, d=3, seed=171\n",
      "Generating d-regular graph with n=500, d=3, seed=172\n",
      "Generating d-regular graph with n=500, d=3, seed=173\n",
      "Generating d-regular graph with n=500, d=3, seed=174\n",
      "Generating d-regular graph with n=500, d=3, seed=175\n",
      "Generating d-regular graph with n=500, d=3, seed=176\n",
      "Generating d-regular graph with n=500, d=3, seed=177\n",
      "Generating d-regular graph with n=500, d=3, seed=178\n",
      "Generating d-regular graph with n=500, d=3, seed=179\n",
      "Generating d-regular graph with n=500, d=3, seed=180\n",
      "Generating d-regular graph with n=500, d=3, seed=181\n",
      "Generating d-regular graph with n=500, d=3, seed=182\n",
      "Generating d-regular graph with n=500, d=3, seed=183\n",
      "Generating d-regular graph with n=500, d=3, seed=184\n",
      "Generating d-regular graph with n=500, d=3, seed=185\n",
      "Generating d-regular graph with n=500, d=3, seed=186\n",
      "Generating d-regular graph with n=500, d=3, seed=187\n",
      "Generating d-regular graph with n=500, d=3, seed=188\n",
      "Generating d-regular graph with n=500, d=3, seed=189\n",
      "Generating d-regular graph with n=500, d=3, seed=190\n",
      "Generating d-regular graph with n=500, d=3, seed=191\n",
      "Generating d-regular graph with n=500, d=3, seed=192\n",
      "Generating d-regular graph with n=500, d=3, seed=193\n",
      "Generating d-regular graph with n=500, d=3, seed=194\n",
      "Generating d-regular graph with n=500, d=3, seed=195\n",
      "Generating d-regular graph with n=500, d=3, seed=196\n",
      "Generating d-regular graph with n=500, d=3, seed=197\n",
      "Generating d-regular graph with n=500, d=3, seed=198\n",
      "Generating d-regular graph with n=500, d=3, seed=199\n"
     ]
    }
   ],
   "source": [
    "# nx_generated_graph = {}\n",
    "#\n",
    "# for i in range (200):\n",
    "#     nx_graph = generate_graph(n=500, d=3, p=None, graph_type='reg', random_seed=i)\n",
    "#\n",
    "#     for u, v, d in nx_graph.edges(data=True):\n",
    "#         d['weight'] = 1\n",
    "#         d['capacity'] = 1\n",
    "#\n",
    "#     graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "#     graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "#     q_torch = qubo_dict_to_torch(nx_graph, gen_adj_matrix(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "#     terminals = [100,450,700]\n",
    "#     nx_generated_graph[i] = [graph_dgl, q_torch, nx_graph, terminals]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "save_object(nx_generated_graph, './testData/nx_generated_graph_n500_d3_t200.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating graph 200 training graph\n",
    "\n",
    "- Nodes = 1000\n",
    "- Degree  = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating d-regular graph with n=1000, d=3, seed=0\n",
      "Generating d-regular graph with n=1000, d=3, seed=1\n",
      "Generating d-regular graph with n=1000, d=3, seed=2\n",
      "Generating d-regular graph with n=1000, d=3, seed=3\n",
      "Generating d-regular graph with n=1000, d=3, seed=4\n",
      "Generating d-regular graph with n=1000, d=3, seed=5\n",
      "Generating d-regular graph with n=1000, d=3, seed=6\n",
      "Generating d-regular graph with n=1000, d=3, seed=7\n",
      "Generating d-regular graph with n=1000, d=3, seed=8\n",
      "Generating d-regular graph with n=1000, d=3, seed=9\n",
      "Generating d-regular graph with n=1000, d=3, seed=10\n",
      "Generating d-regular graph with n=1000, d=3, seed=11\n",
      "Generating d-regular graph with n=1000, d=3, seed=12\n",
      "Generating d-regular graph with n=1000, d=3, seed=13\n",
      "Generating d-regular graph with n=1000, d=3, seed=14\n",
      "Generating d-regular graph with n=1000, d=3, seed=15\n",
      "Generating d-regular graph with n=1000, d=3, seed=16\n",
      "Generating d-regular graph with n=1000, d=3, seed=17\n",
      "Generating d-regular graph with n=1000, d=3, seed=18\n",
      "Generating d-regular graph with n=1000, d=3, seed=19\n",
      "Generating d-regular graph with n=1000, d=3, seed=20\n",
      "Generating d-regular graph with n=1000, d=3, seed=21\n",
      "Generating d-regular graph with n=1000, d=3, seed=22\n",
      "Generating d-regular graph with n=1000, d=3, seed=23\n",
      "Generating d-regular graph with n=1000, d=3, seed=24\n",
      "Generating d-regular graph with n=1000, d=3, seed=25\n",
      "Generating d-regular graph with n=1000, d=3, seed=26\n",
      "Generating d-regular graph with n=1000, d=3, seed=27\n",
      "Generating d-regular graph with n=1000, d=3, seed=28\n",
      "Generating d-regular graph with n=1000, d=3, seed=29\n",
      "Generating d-regular graph with n=1000, d=3, seed=30\n",
      "Generating d-regular graph with n=1000, d=3, seed=31\n",
      "Generating d-regular graph with n=1000, d=3, seed=32\n",
      "Generating d-regular graph with n=1000, d=3, seed=33\n",
      "Generating d-regular graph with n=1000, d=3, seed=34\n",
      "Generating d-regular graph with n=1000, d=3, seed=35\n",
      "Generating d-regular graph with n=1000, d=3, seed=36\n",
      "Generating d-regular graph with n=1000, d=3, seed=37\n",
      "Generating d-regular graph with n=1000, d=3, seed=38\n",
      "Generating d-regular graph with n=1000, d=3, seed=39\n",
      "Generating d-regular graph with n=1000, d=3, seed=40\n",
      "Generating d-regular graph with n=1000, d=3, seed=41\n",
      "Generating d-regular graph with n=1000, d=3, seed=42\n",
      "Generating d-regular graph with n=1000, d=3, seed=43\n",
      "Generating d-regular graph with n=1000, d=3, seed=44\n",
      "Generating d-regular graph with n=1000, d=3, seed=45\n",
      "Generating d-regular graph with n=1000, d=3, seed=46\n",
      "Generating d-regular graph with n=1000, d=3, seed=47\n",
      "Generating d-regular graph with n=1000, d=3, seed=48\n",
      "Generating d-regular graph with n=1000, d=3, seed=49\n",
      "Generating d-regular graph with n=1000, d=3, seed=50\n",
      "Generating d-regular graph with n=1000, d=3, seed=51\n",
      "Generating d-regular graph with n=1000, d=3, seed=52\n",
      "Generating d-regular graph with n=1000, d=3, seed=53\n",
      "Generating d-regular graph with n=1000, d=3, seed=54\n",
      "Generating d-regular graph with n=1000, d=3, seed=55\n",
      "Generating d-regular graph with n=1000, d=3, seed=56\n",
      "Generating d-regular graph with n=1000, d=3, seed=57\n",
      "Generating d-regular graph with n=1000, d=3, seed=58\n",
      "Generating d-regular graph with n=1000, d=3, seed=59\n",
      "Generating d-regular graph with n=1000, d=3, seed=60\n",
      "Generating d-regular graph with n=1000, d=3, seed=61\n",
      "Generating d-regular graph with n=1000, d=3, seed=62\n",
      "Generating d-regular graph with n=1000, d=3, seed=63\n",
      "Generating d-regular graph with n=1000, d=3, seed=64\n",
      "Generating d-regular graph with n=1000, d=3, seed=65\n",
      "Generating d-regular graph with n=1000, d=3, seed=66\n",
      "Generating d-regular graph with n=1000, d=3, seed=67\n",
      "Generating d-regular graph with n=1000, d=3, seed=68\n",
      "Generating d-regular graph with n=1000, d=3, seed=69\n",
      "Generating d-regular graph with n=1000, d=3, seed=70\n",
      "Generating d-regular graph with n=1000, d=3, seed=71\n",
      "Generating d-regular graph with n=1000, d=3, seed=72\n",
      "Generating d-regular graph with n=1000, d=3, seed=73\n",
      "Generating d-regular graph with n=1000, d=3, seed=74\n",
      "Generating d-regular graph with n=1000, d=3, seed=75\n",
      "Generating d-regular graph with n=1000, d=3, seed=76\n",
      "Generating d-regular graph with n=1000, d=3, seed=77\n",
      "Generating d-regular graph with n=1000, d=3, seed=78\n",
      "Generating d-regular graph with n=1000, d=3, seed=79\n",
      "Generating d-regular graph with n=1000, d=3, seed=80\n",
      "Generating d-regular graph with n=1000, d=3, seed=81\n",
      "Generating d-regular graph with n=1000, d=3, seed=82\n",
      "Generating d-regular graph with n=1000, d=3, seed=83\n",
      "Generating d-regular graph with n=1000, d=3, seed=84\n",
      "Generating d-regular graph with n=1000, d=3, seed=85\n",
      "Generating d-regular graph with n=1000, d=3, seed=86\n",
      "Generating d-regular graph with n=1000, d=3, seed=87\n",
      "Generating d-regular graph with n=1000, d=3, seed=88\n",
      "Generating d-regular graph with n=1000, d=3, seed=89\n",
      "Generating d-regular graph with n=1000, d=3, seed=90\n",
      "Generating d-regular graph with n=1000, d=3, seed=91\n",
      "Generating d-regular graph with n=1000, d=3, seed=92\n",
      "Generating d-regular graph with n=1000, d=3, seed=93\n",
      "Generating d-regular graph with n=1000, d=3, seed=94\n",
      "Generating d-regular graph with n=1000, d=3, seed=95\n",
      "Generating d-regular graph with n=1000, d=3, seed=96\n",
      "Generating d-regular graph with n=1000, d=3, seed=97\n",
      "Generating d-regular graph with n=1000, d=3, seed=98\n",
      "Generating d-regular graph with n=1000, d=3, seed=99\n",
      "Generating d-regular graph with n=1000, d=3, seed=100\n",
      "Generating d-regular graph with n=1000, d=3, seed=101\n",
      "Generating d-regular graph with n=1000, d=3, seed=102\n",
      "Generating d-regular graph with n=1000, d=3, seed=103\n",
      "Generating d-regular graph with n=1000, d=3, seed=104\n",
      "Generating d-regular graph with n=1000, d=3, seed=105\n",
      "Generating d-regular graph with n=1000, d=3, seed=106\n",
      "Generating d-regular graph with n=1000, d=3, seed=107\n",
      "Generating d-regular graph with n=1000, d=3, seed=108\n",
      "Generating d-regular graph with n=1000, d=3, seed=109\n",
      "Generating d-regular graph with n=1000, d=3, seed=110\n",
      "Generating d-regular graph with n=1000, d=3, seed=111\n",
      "Generating d-regular graph with n=1000, d=3, seed=112\n",
      "Generating d-regular graph with n=1000, d=3, seed=113\n",
      "Generating d-regular graph with n=1000, d=3, seed=114\n",
      "Generating d-regular graph with n=1000, d=3, seed=115\n",
      "Generating d-regular graph with n=1000, d=3, seed=116\n",
      "Generating d-regular graph with n=1000, d=3, seed=117\n",
      "Generating d-regular graph with n=1000, d=3, seed=118\n",
      "Generating d-regular graph with n=1000, d=3, seed=119\n",
      "Generating d-regular graph with n=1000, d=3, seed=120\n",
      "Generating d-regular graph with n=1000, d=3, seed=121\n",
      "Generating d-regular graph with n=1000, d=3, seed=122\n",
      "Generating d-regular graph with n=1000, d=3, seed=123\n",
      "Generating d-regular graph with n=1000, d=3, seed=124\n",
      "Generating d-regular graph with n=1000, d=3, seed=125\n",
      "Generating d-regular graph with n=1000, d=3, seed=126\n",
      "Generating d-regular graph with n=1000, d=3, seed=127\n",
      "Generating d-regular graph with n=1000, d=3, seed=128\n",
      "Generating d-regular graph with n=1000, d=3, seed=129\n",
      "Generating d-regular graph with n=1000, d=3, seed=130\n",
      "Generating d-regular graph with n=1000, d=3, seed=131\n",
      "Generating d-regular graph with n=1000, d=3, seed=132\n",
      "Generating d-regular graph with n=1000, d=3, seed=133\n",
      "Generating d-regular graph with n=1000, d=3, seed=134\n",
      "Generating d-regular graph with n=1000, d=3, seed=135\n",
      "Generating d-regular graph with n=1000, d=3, seed=136\n",
      "Generating d-regular graph with n=1000, d=3, seed=137\n",
      "Generating d-regular graph with n=1000, d=3, seed=138\n",
      "Generating d-regular graph with n=1000, d=3, seed=139\n",
      "Generating d-regular graph with n=1000, d=3, seed=140\n",
      "Generating d-regular graph with n=1000, d=3, seed=141\n",
      "Generating d-regular graph with n=1000, d=3, seed=142\n",
      "Generating d-regular graph with n=1000, d=3, seed=143\n",
      "Generating d-regular graph with n=1000, d=3, seed=144\n",
      "Generating d-regular graph with n=1000, d=3, seed=145\n",
      "Generating d-regular graph with n=1000, d=3, seed=146\n",
      "Generating d-regular graph with n=1000, d=3, seed=147\n",
      "Generating d-regular graph with n=1000, d=3, seed=148\n",
      "Generating d-regular graph with n=1000, d=3, seed=149\n",
      "Generating d-regular graph with n=1000, d=3, seed=150\n",
      "Generating d-regular graph with n=1000, d=3, seed=151\n",
      "Generating d-regular graph with n=1000, d=3, seed=152\n",
      "Generating d-regular graph with n=1000, d=3, seed=153\n",
      "Generating d-regular graph with n=1000, d=3, seed=154\n",
      "Generating d-regular graph with n=1000, d=3, seed=155\n",
      "Generating d-regular graph with n=1000, d=3, seed=156\n",
      "Generating d-regular graph with n=1000, d=3, seed=157\n",
      "Generating d-regular graph with n=1000, d=3, seed=158\n",
      "Generating d-regular graph with n=1000, d=3, seed=159\n",
      "Generating d-regular graph with n=1000, d=3, seed=160\n",
      "Generating d-regular graph with n=1000, d=3, seed=161\n",
      "Generating d-regular graph with n=1000, d=3, seed=162\n",
      "Generating d-regular graph with n=1000, d=3, seed=163\n",
      "Generating d-regular graph with n=1000, d=3, seed=164\n",
      "Generating d-regular graph with n=1000, d=3, seed=165\n",
      "Generating d-regular graph with n=1000, d=3, seed=166\n",
      "Generating d-regular graph with n=1000, d=3, seed=167\n",
      "Generating d-regular graph with n=1000, d=3, seed=168\n",
      "Generating d-regular graph with n=1000, d=3, seed=169\n",
      "Generating d-regular graph with n=1000, d=3, seed=170\n",
      "Generating d-regular graph with n=1000, d=3, seed=171\n",
      "Generating d-regular graph with n=1000, d=3, seed=172\n",
      "Generating d-regular graph with n=1000, d=3, seed=173\n",
      "Generating d-regular graph with n=1000, d=3, seed=174\n",
      "Generating d-regular graph with n=1000, d=3, seed=175\n",
      "Generating d-regular graph with n=1000, d=3, seed=176\n",
      "Generating d-regular graph with n=1000, d=3, seed=177\n",
      "Generating d-regular graph with n=1000, d=3, seed=178\n",
      "Generating d-regular graph with n=1000, d=3, seed=179\n",
      "Generating d-regular graph with n=1000, d=3, seed=180\n",
      "Generating d-regular graph with n=1000, d=3, seed=181\n",
      "Generating d-regular graph with n=1000, d=3, seed=182\n",
      "Generating d-regular graph with n=1000, d=3, seed=183\n",
      "Generating d-regular graph with n=1000, d=3, seed=184\n",
      "Generating d-regular graph with n=1000, d=3, seed=185\n",
      "Generating d-regular graph with n=1000, d=3, seed=186\n",
      "Generating d-regular graph with n=1000, d=3, seed=187\n",
      "Generating d-regular graph with n=1000, d=3, seed=188\n",
      "Generating d-regular graph with n=1000, d=3, seed=189\n",
      "Generating d-regular graph with n=1000, d=3, seed=190\n",
      "Generating d-regular graph with n=1000, d=3, seed=191\n",
      "Generating d-regular graph with n=1000, d=3, seed=192\n",
      "Generating d-regular graph with n=1000, d=3, seed=193\n",
      "Generating d-regular graph with n=1000, d=3, seed=194\n",
      "Generating d-regular graph with n=1000, d=3, seed=195\n",
      "Generating d-regular graph with n=1000, d=3, seed=196\n",
      "Generating d-regular graph with n=1000, d=3, seed=197\n",
      "Generating d-regular graph with n=1000, d=3, seed=198\n",
      "Generating d-regular graph with n=1000, d=3, seed=199\n"
     ]
    }
   ],
   "source": [
    "# nx_generated_graph = {}\n",
    "#\n",
    "# for i in range (200):\n",
    "#     nx_graph = generate_graph(n=1000, d=3, p=None, graph_type='reg', random_seed=i)\n",
    "#\n",
    "#     for u, v, d in nx_graph.edges(data=True):\n",
    "#         d['weight'] = 1\n",
    "#         d['capacity'] = 1\n",
    "#\n",
    "#     graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "#     graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "#     q_torch = qubo_dict_to_torch(nx_graph, gen_adj_matrix(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)\n",
    "#     terminals = [200,400,700]\n",
    "#     nx_generated_graph[i] = [graph_dgl, q_torch, nx_graph, terminals]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "save_object(nx_generated_graph, './testData/nx_generated_graph_n1000_d3_t200.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train1(modelName, filename = './testData/nx_generated_graph_n80_d3_t200.pkl', n = 80):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(learning_rate=0.001, n=n,patience=20)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 3,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    datasetItem = open_file(filename)\n",
    "    # print(datasetItem)\n",
    "    # datasetItem_all = {}\n",
    "    # for key, (dgl_graph, adjacency_matrix,graph) in datasetItem.items():\n",
    "    #     A, C = FIndAC(graph)\n",
    "    #     datasetItem_all[key] = [dgl_graph, adjacency_matrix, graph, A, C]\n",
    "\n",
    "    # print(len(datasetItem), datasetItem[0][3])\n",
    "    # datasetItem_2 = {}\n",
    "    # datasetItem_2[0]=datasetItem[1]\n",
    "    # print(datasetItem_2)\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "\n",
    "\n",
    "    # print(datasetItem[1][2].nodes)\n",
    "    # # Visualize graph\n",
    "    # pos = nx.kamada_kawai_layout(datasetItem[1][2])\n",
    "    # nx.draw(datasetItem[1][2], pos, with_labels=True, node_color=[[.7, .7, .7]])\n",
    "    # cut_value, (part_1, part_2) = nx.minimum_cut(datasetItem_2[0][2], datasetItem_2[0][3][1], datasetItem_2[0][3][0], flow_func=shortest_augmenting_path)\n",
    "\n",
    "    # print(cut_value, len(part_1), len(part_2))\n",
    "\n",
    "    # resultList = []\n",
    "    # all_indexes = sorted(part_1.union(part_2))\n",
    "    # # Check membership for each index and append the appropriate pair to the result list\n",
    "    # for index in all_indexes:\n",
    "    #     if index in part_1:\n",
    "    #         resultList.append([1, 0])\n",
    "    #     elif index in part_2:\n",
    "    #         resultList.append([0, 1])\n",
    "\n",
    "    #\n",
    "    trained_net, bestLost, epoch, inp, lossList= run_gnn_training2(\n",
    "        datasetItem, net, optimizer, int(1000),\n",
    "        gnn_hypers['tolerance'], gnn_hypers['patience'], loss_terminal,gnn_hypers['dim_embedding'], gnn_hypers['number_classes'], modelName,  TORCH_DTYPE,  TORCH_DEVICE)\n",
    "\n",
    "    return trained_net, bestLost, epoch, inp, lossList\n",
    "\n",
    "def train_2wayNeural(modelName, filename='./testData/prepareDS.pkl'):\n",
    "    n, d, p, graph_type, number_epochs, learning_rate, PROB_THRESHOLD, tol, patience, dim_embedding, hidden_dim = hyperParameters(learning_rate=0.001, n=4096,patience=20)\n",
    "\n",
    "    # Establish pytorch GNN + optimizer\n",
    "    opt_params = {'lr': learning_rate}\n",
    "    gnn_hypers = {\n",
    "        'dim_embedding': dim_embedding,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': 0.0,\n",
    "        'number_classes': 2,\n",
    "        'prob_threshold': PROB_THRESHOLD,\n",
    "        'number_epochs': number_epochs,\n",
    "        'tolerance': tol,\n",
    "        'patience': patience,\n",
    "        'nodes':n\n",
    "    }\n",
    "    datasetItem = open_file(filename)\n",
    "    # print(datasetItem)\n",
    "    # datasetItem_all = {}\n",
    "    # for key, (dgl_graph, adjacency_matrix,graph) in datasetItem.items():\n",
    "    #     A, C = FIndAC(graph)\n",
    "    #     datasetItem_all[key] = [dgl_graph, adjacency_matrix, graph, A, C]\n",
    "\n",
    "    # print(len(datasetItem), datasetItem[0][3])\n",
    "    # datasetItem_2 = {}\n",
    "    # datasetItem_2[0]=datasetItem[1]\n",
    "    # print(datasetItem_2)\n",
    "\n",
    "    net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "\n",
    "\n",
    "    # print(datasetItem[1][2].nodes)\n",
    "    # # Visualize graph\n",
    "    # pos = nx.kamada_kawai_layout(datasetItem[1][2])\n",
    "    # nx.draw(datasetItem[1][2], pos, with_labels=True, node_color=[[.7, .7, .7]])\n",
    "    # cut_value, (part_1, part_2) = nx.minimum_cut(datasetItem_2[0][2], datasetItem_2[0][3][1], datasetItem_2[0][3][0], flow_func=shortest_augmenting_path)\n",
    "\n",
    "    # print(cut_value, len(part_1), len(part_2))\n",
    "\n",
    "    # resultList = []\n",
    "    # all_indexes = sorted(part_1.union(part_2))\n",
    "    # # Check membership for each index and append the appropriate pair to the result list\n",
    "    # for index in all_indexes:\n",
    "    #     if index in part_1:\n",
    "    #         resultList.append([1, 0])\n",
    "    #     elif index in part_2:\n",
    "    #         resultList.append([0, 1])\n",
    "\n",
    "    #\n",
    "    trained_net, bestLost, epoch, inp, lossList= run_gnn_training2(\n",
    "        datasetItem, net, optimizer, int(500),\n",
    "        gnn_hypers['tolerance'], gnn_hypers['patience'], loss_terminal,gnn_hypers['dim_embedding'], gnn_hypers['number_classes'], modelName,  TORCH_DTYPE,  TORCH_DEVICE)\n",
    "\n",
    "    return trained_net, bestLost, epoch, inp, lossList\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 1 - loss\n",
    "\n",
    "- expriment 5 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- removing terminal loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def max_to_one_hot(tensor):\n",
    "    # Find the index of the maximum value\n",
    "    max_index = torch.argmax(tensor)\n",
    "\n",
    "    # Create a one-hot encoded tensor\n",
    "    one_hot_tensor = torch.zeros_like(tensor)\n",
    "    one_hot_tensor[max_index] = 1.0\n",
    "\n",
    "    one_hot_tensor = one_hot_tensor + tensor - tensor.detach()\n",
    "\n",
    "    return one_hot_tensor\n",
    "\n",
    "def apply_max_to_one_hot(output):\n",
    "    return torch.stack([max_to_one_hot(output[i]) for i in range(output.size(0))])\n",
    "\n",
    "\n",
    "def run_gnn_training2(dataset, net, optimizer, number_epochs, tol, patience, loss_func, dim_embedding, total_classes=3, save_directory=None, torch_dtype = TORCH_DTYPE, torch_device = TORCH_DEVICE, labels=None):\n",
    "    \"\"\"\n",
    "    Train a GCN model with early stopping.\n",
    "    \"\"\"\n",
    "    # loss for a whole epoch\n",
    "    prev_loss = float('inf')  # Set initial loss to infinity for comparison\n",
    "    prev_cummulative_loss = float('inf')\n",
    "    cummulativeCount = 0\n",
    "    count = 0  # Patience counter\n",
    "    best_loss = float('inf')  # Initialize best loss to infinity\n",
    "    best_model_state = None  # Placeholder for the best model state\n",
    "    loss_list = []\n",
    "    epochList = []\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    t_gnn_start = time()\n",
    "\n",
    "    # contains information regarding all terminal nodes for the dataset\n",
    "    terminal_configs = {}\n",
    "    epochCount = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    A = nn.Parameter(torch.tensor([65.0]))\n",
    "    C = nn.Parameter(torch.tensor([32.5]))\n",
    "\n",
    "    embed = nn.Embedding(80, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "    inputs = embed.weight\n",
    "\n",
    "    for epoch in range(number_epochs):\n",
    "\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss for each epoch\n",
    "\n",
    "        for key, (dgl_graph, adjacency_matrix,graph, terminals) in dataset.items():\n",
    "            epochCount +=1\n",
    "\n",
    "\n",
    "            # Ensure model is in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Pass the graph and the input features to the model\n",
    "            logits = net(dgl_graph, adjacency_matrix)\n",
    "            logits = override_fixed_nodes(logits)\n",
    "            # Apply max to one-hot encoding\n",
    "            one_hot_output = apply_max_to_one_hot(logits)\n",
    "            # Compute the loss\n",
    "            # loss = loss_func(criterion, logits, labels, terminals[0], terminals[1])\n",
    "\n",
    "            loss = loss_func( one_hot_output, adjacency_matrix)\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update cumulative loss\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            # # Check for early stopping\n",
    "            if epoch > 0 and (cumulative_loss > prev_loss or abs(prev_loss - cumulative_loss) <= tol):\n",
    "                count += 1\n",
    "                if count >= patience: # play around with patience value, try lower one\n",
    "                    print(f'Stopping early at epoch {epoch}')\n",
    "                    break\n",
    "            else:\n",
    "                count = 0  # Reset patience counter if loss decreases\n",
    "\n",
    "            # Update best model\n",
    "            if cumulative_loss < best_loss:\n",
    "                best_loss = cumulative_loss\n",
    "                best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        # # Early stopping break from the outer loop\n",
    "        # if count >= patience:\n",
    "        #     count=0\n",
    "\n",
    "        prev_loss = cumulative_loss  # Update previous loss\n",
    "\n",
    "        if epoch % 100 == 0:  # Adjust printing frequency as needed\n",
    "            print(f'Epoch: {epoch}, Cumulative Loss: {cumulative_loss}')\n",
    "\n",
    "            if save_directory != None:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model': net.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lossList':loss_list,\n",
    "                    'inputs':inputs}\n",
    "                torch.save(checkpoint, './epoch'+str(epoch)+'loss'+str(cumulative_loss)+ save_directory)\n",
    "\n",
    "            if (prev_cummulative_loss == cummulativeCount):\n",
    "                cummulativeCount+=1\n",
    "\n",
    "                if cummulativeCount > 4:\n",
    "                    break\n",
    "            else:\n",
    "                prev_cummulative_loss = cumulative_loss\n",
    "\n",
    "\n",
    "    t_gnn = time() - t_gnn_start\n",
    "\n",
    "    # Load the best model state\n",
    "    if best_model_state is not None:\n",
    "        net.load_state_dict(best_model_state)\n",
    "\n",
    "    print(f'GNN training took {round(t_gnn, 3)} seconds.')\n",
    "    print(f'Best cumulative loss: {best_loss}')\n",
    "    loss = loss_func(logits, adjacency_matrix)\n",
    "    if save_directory != None:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lossList':loss_list,\n",
    "            'inputs':inputs}\n",
    "        torch.save(checkpoint, './final_'+save_directory)\n",
    "\n",
    "    return net, best_loss, epoch, inputs, loss_list\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        # h = override_fixed_nodes(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[10] = torch.tensor([1.0, 0.0, 0.0],requires_grad=True) + h[10] - h[10].detach()\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[40] = torch.tensor([0.0, 1.0, 0.0],requires_grad=True)+ h[40] - h[40].detach()\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[70] = torch.tensor([0.0, 0.0, 1.0],requires_grad=True)+ h[70] - h[70].detach()\n",
    "    return output\n",
    "\n",
    "def calculate_HC_vectorized(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute the minimum cut loss, which is the total weight of edges cut between partitions using vectorized operations.\n",
    "\n",
    "    Parameters:\n",
    "    s (torch.Tensor): Binary partition matrix of shape (num_nodes, num_partitions)\n",
    "    adjacency_matrix (torch.Tensor): Adjacency matrix of the graph of shape (num_nodes, num_nodes)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Scalar loss value representing the total weight of edges cut\n",
    "    \"\"\"\n",
    "    num_nodes, num_partitions = s.shape\n",
    "\n",
    "    # Compute the partition probability matrix for all partitions\n",
    "    partition_prob_matrix = s @ s.T\n",
    "\n",
    "    # Compute the cut value by summing weights of edges that connect nodes in different partitions\n",
    "    cut_value = adjacency_matrix * (1 - partition_prob_matrix)\n",
    "\n",
    "    # Sum up the contributions for all edges\n",
    "    loss = torch.sum(cut_value) / 2  # Divide by 2 to correct for double-counting\n",
    "\n",
    "    return loss\n",
    "\n",
    "def Loss(s, adjacency_matrix,  A=1, C=1):\n",
    "    HC = -1*calculate_HC_vectorized(s, adjacency_matrix)\n",
    "    return C * HC\n",
    "\n",
    "\n",
    "def loss_terminal(s, adjacency_matrix,  A=0, C=1, penalty=1000):\n",
    "    loss = Loss(s, adjacency_matrix, A, C)\n",
    "    # loss += penalty* terminal_independence_penalty(s, [0,1,2])\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cumulative Loss: -17853.0\n",
      "Stopping early at epoch 1\n",
      "Stopping early at epoch 2\n",
      "Stopping early at epoch 3\n",
      "Stopping early at epoch 4\n",
      "Stopping early at epoch 5\n",
      "Stopping early at epoch 7\n",
      "Stopping early at epoch 8\n",
      "Stopping early at epoch 9\n",
      "Stopping early at epoch 10\n",
      "Stopping early at epoch 11\n",
      "Stopping early at epoch 12\n",
      "Stopping early at epoch 13\n",
      "Stopping early at epoch 14\n",
      "Stopping early at epoch 15\n",
      "Stopping early at epoch 17\n",
      "Stopping early at epoch 18\n",
      "Stopping early at epoch 19\n",
      "Stopping early at epoch 20\n",
      "Stopping early at epoch 22\n",
      "Stopping early at epoch 23\n",
      "Stopping early at epoch 24\n",
      "Stopping early at epoch 25\n",
      "Stopping early at epoch 26\n",
      "Stopping early at epoch 28\n",
      "Stopping early at epoch 29\n",
      "Stopping early at epoch 30\n",
      "Stopping early at epoch 31\n",
      "Stopping early at epoch 32\n",
      "Stopping early at epoch 34\n",
      "Stopping early at epoch 35\n",
      "Stopping early at epoch 36\n",
      "Stopping early at epoch 37\n",
      "Stopping early at epoch 39\n",
      "Stopping early at epoch 40\n",
      "Stopping early at epoch 41\n",
      "Stopping early at epoch 42\n",
      "Stopping early at epoch 44\n",
      "Stopping early at epoch 45\n",
      "Stopping early at epoch 46\n",
      "Stopping early at epoch 47\n",
      "Stopping early at epoch 48\n",
      "Stopping early at epoch 50\n",
      "Stopping early at epoch 51\n",
      "Stopping early at epoch 53\n",
      "Stopping early at epoch 54\n",
      "Stopping early at epoch 55\n",
      "Stopping early at epoch 56\n",
      "Stopping early at epoch 57\n",
      "Stopping early at epoch 58\n",
      "Stopping early at epoch 60\n",
      "Stopping early at epoch 61\n",
      "Stopping early at epoch 62\n",
      "Stopping early at epoch 63\n",
      "Stopping early at epoch 64\n",
      "Stopping early at epoch 66\n",
      "Stopping early at epoch 67\n",
      "Stopping early at epoch 68\n",
      "Stopping early at epoch 69\n",
      "Stopping early at epoch 70\n",
      "Stopping early at epoch 72\n",
      "Stopping early at epoch 73\n",
      "Stopping early at epoch 74\n",
      "Stopping early at epoch 75\n",
      "Stopping early at epoch 77\n",
      "Stopping early at epoch 78\n",
      "Stopping early at epoch 79\n",
      "Stopping early at epoch 81\n",
      "Stopping early at epoch 82\n",
      "Stopping early at epoch 83\n",
      "Stopping early at epoch 85\n",
      "Stopping early at epoch 86\n",
      "Stopping early at epoch 87\n",
      "Stopping early at epoch 89\n",
      "Stopping early at epoch 90\n",
      "Stopping early at epoch 92\n",
      "Stopping early at epoch 93\n",
      "Stopping early at epoch 95\n",
      "Stopping early at epoch 96\n",
      "Stopping early at epoch 98\n",
      "Stopping early at epoch 99\n",
      "Stopping early at epoch 100\n",
      "Epoch: 100, Cumulative Loss: -105.0\n",
      "Stopping early at epoch 101\n",
      "Stopping early at epoch 102\n",
      "Stopping early at epoch 103\n",
      "Stopping early at epoch 104\n",
      "Stopping early at epoch 105\n",
      "Stopping early at epoch 106\n",
      "Stopping early at epoch 107\n",
      "Stopping early at epoch 109\n",
      "Stopping early at epoch 110\n",
      "Stopping early at epoch 111\n",
      "Stopping early at epoch 112\n",
      "Stopping early at epoch 113\n",
      "Stopping early at epoch 114\n",
      "Stopping early at epoch 115\n",
      "Stopping early at epoch 116\n",
      "Stopping early at epoch 118\n",
      "Stopping early at epoch 119\n",
      "Stopping early at epoch 120\n",
      "Stopping early at epoch 121\n",
      "Stopping early at epoch 122\n",
      "Stopping early at epoch 124\n",
      "Stopping early at epoch 125\n",
      "Stopping early at epoch 126\n",
      "Stopping early at epoch 127\n",
      "Stopping early at epoch 128\n",
      "Stopping early at epoch 129\n",
      "Stopping early at epoch 130\n",
      "Stopping early at epoch 131\n",
      "Stopping early at epoch 132\n",
      "Stopping early at epoch 133\n",
      "Stopping early at epoch 134\n",
      "Stopping early at epoch 135\n",
      "Stopping early at epoch 136\n",
      "Stopping early at epoch 137\n",
      "Stopping early at epoch 138\n",
      "Stopping early at epoch 140\n",
      "Stopping early at epoch 141\n",
      "Stopping early at epoch 142\n",
      "Stopping early at epoch 143\n",
      "Stopping early at epoch 145\n",
      "Stopping early at epoch 146\n",
      "Stopping early at epoch 148\n",
      "Stopping early at epoch 149\n",
      "Stopping early at epoch 150\n",
      "Stopping early at epoch 151\n",
      "Stopping early at epoch 152\n",
      "Stopping early at epoch 153\n",
      "Stopping early at epoch 154\n",
      "Stopping early at epoch 155\n",
      "Stopping early at epoch 156\n",
      "Stopping early at epoch 157\n",
      "Stopping early at epoch 158\n",
      "Stopping early at epoch 160\n",
      "Stopping early at epoch 161\n",
      "Stopping early at epoch 162\n",
      "Stopping early at epoch 163\n",
      "Stopping early at epoch 164\n",
      "Stopping early at epoch 165\n",
      "Stopping early at epoch 166\n",
      "Stopping early at epoch 167\n",
      "Stopping early at epoch 168\n",
      "Stopping early at epoch 169\n",
      "Stopping early at epoch 170\n",
      "Stopping early at epoch 171\n",
      "Stopping early at epoch 172\n",
      "Stopping early at epoch 173\n",
      "Stopping early at epoch 174\n",
      "Stopping early at epoch 175\n",
      "Stopping early at epoch 176\n",
      "Stopping early at epoch 177\n",
      "Stopping early at epoch 178\n",
      "Stopping early at epoch 179\n",
      "Stopping early at epoch 180\n",
      "Stopping early at epoch 181\n",
      "Stopping early at epoch 182\n",
      "Stopping early at epoch 183\n",
      "Stopping early at epoch 184\n",
      "Stopping early at epoch 185\n",
      "Stopping early at epoch 186\n",
      "Stopping early at epoch 188\n",
      "Stopping early at epoch 189\n",
      "Stopping early at epoch 190\n",
      "Stopping early at epoch 191\n",
      "Stopping early at epoch 192\n",
      "Stopping early at epoch 193\n",
      "Stopping early at epoch 194\n",
      "Stopping early at epoch 195\n",
      "Stopping early at epoch 196\n",
      "Stopping early at epoch 197\n",
      "Stopping early at epoch 198\n",
      "Stopping early at epoch 199\n",
      "Epoch: 200, Cumulative Loss: -21400.0\n",
      "Stopping early at epoch 201\n",
      "Stopping early at epoch 202\n",
      "Stopping early at epoch 203\n",
      "Stopping early at epoch 204\n",
      "Stopping early at epoch 205\n",
      "Stopping early at epoch 206\n",
      "Stopping early at epoch 207\n",
      "Stopping early at epoch 208\n",
      "Stopping early at epoch 209\n",
      "Stopping early at epoch 211\n",
      "Stopping early at epoch 212\n",
      "Stopping early at epoch 213\n",
      "Stopping early at epoch 214\n",
      "Stopping early at epoch 215\n",
      "Stopping early at epoch 216\n",
      "Stopping early at epoch 217\n",
      "Stopping early at epoch 218\n",
      "Stopping early at epoch 220\n",
      "Stopping early at epoch 221\n",
      "Stopping early at epoch 222\n",
      "Stopping early at epoch 223\n",
      "Stopping early at epoch 224\n",
      "Stopping early at epoch 225\n",
      "Stopping early at epoch 227\n",
      "Stopping early at epoch 228\n",
      "Stopping early at epoch 229\n",
      "Stopping early at epoch 230\n",
      "Stopping early at epoch 231\n",
      "Stopping early at epoch 232\n",
      "Stopping early at epoch 234\n",
      "Stopping early at epoch 235\n",
      "Stopping early at epoch 237\n",
      "Stopping early at epoch 238\n",
      "Stopping early at epoch 239\n",
      "Stopping early at epoch 240\n",
      "Stopping early at epoch 241\n",
      "Stopping early at epoch 242\n",
      "Stopping early at epoch 243\n",
      "Stopping early at epoch 244\n",
      "Stopping early at epoch 245\n",
      "Stopping early at epoch 246\n",
      "Stopping early at epoch 248\n",
      "Stopping early at epoch 249\n",
      "Stopping early at epoch 250\n",
      "Stopping early at epoch 251\n",
      "Stopping early at epoch 253\n",
      "Stopping early at epoch 254\n",
      "Stopping early at epoch 255\n",
      "Stopping early at epoch 256\n",
      "Stopping early at epoch 257\n",
      "Stopping early at epoch 258\n",
      "Stopping early at epoch 260\n",
      "Stopping early at epoch 261\n",
      "Stopping early at epoch 262\n",
      "Stopping early at epoch 263\n",
      "Stopping early at epoch 264\n",
      "Stopping early at epoch 265\n",
      "Stopping early at epoch 266\n",
      "Stopping early at epoch 267\n",
      "Stopping early at epoch 268\n",
      "Stopping early at epoch 269\n",
      "Stopping early at epoch 270\n",
      "Stopping early at epoch 271\n",
      "Stopping early at epoch 273\n",
      "Stopping early at epoch 274\n",
      "Stopping early at epoch 275\n",
      "Stopping early at epoch 276\n",
      "Stopping early at epoch 277\n",
      "Stopping early at epoch 278\n",
      "Stopping early at epoch 279\n",
      "Stopping early at epoch 281\n",
      "Stopping early at epoch 282\n",
      "Stopping early at epoch 283\n",
      "Stopping early at epoch 284\n",
      "Stopping early at epoch 285\n",
      "Stopping early at epoch 286\n",
      "Stopping early at epoch 287\n",
      "Stopping early at epoch 288\n",
      "Stopping early at epoch 289\n",
      "Stopping early at epoch 291\n",
      "Stopping early at epoch 292\n",
      "Stopping early at epoch 293\n",
      "Stopping early at epoch 294\n",
      "Stopping early at epoch 295\n",
      "Stopping early at epoch 296\n",
      "Stopping early at epoch 297\n",
      "Stopping early at epoch 298\n",
      "Stopping early at epoch 300\n",
      "Epoch: 300, Cumulative Loss: -2203.0\n",
      "Stopping early at epoch 301\n",
      "Stopping early at epoch 302\n",
      "Stopping early at epoch 303\n",
      "Stopping early at epoch 304\n",
      "Stopping early at epoch 305\n",
      "Stopping early at epoch 306\n",
      "Stopping early at epoch 307\n",
      "Stopping early at epoch 309\n",
      "Stopping early at epoch 310\n",
      "Stopping early at epoch 311\n",
      "Stopping early at epoch 312\n",
      "Stopping early at epoch 313\n",
      "Stopping early at epoch 314\n",
      "Stopping early at epoch 315\n",
      "Stopping early at epoch 316\n",
      "Stopping early at epoch 318\n",
      "Stopping early at epoch 319\n",
      "Stopping early at epoch 320\n",
      "Stopping early at epoch 321\n",
      "Stopping early at epoch 322\n",
      "Stopping early at epoch 323\n",
      "Stopping early at epoch 324\n",
      "Stopping early at epoch 326\n",
      "Stopping early at epoch 327\n",
      "Stopping early at epoch 328\n",
      "Stopping early at epoch 329\n",
      "Stopping early at epoch 330\n",
      "Stopping early at epoch 331\n",
      "Stopping early at epoch 332\n",
      "Stopping early at epoch 333\n",
      "Stopping early at epoch 335\n",
      "Stopping early at epoch 336\n",
      "Stopping early at epoch 337\n",
      "Stopping early at epoch 338\n",
      "Stopping early at epoch 339\n",
      "Stopping early at epoch 340\n",
      "Stopping early at epoch 341\n",
      "Stopping early at epoch 343\n",
      "Stopping early at epoch 344\n",
      "Stopping early at epoch 345\n",
      "Stopping early at epoch 346\n",
      "Stopping early at epoch 347\n",
      "Stopping early at epoch 348\n",
      "Stopping early at epoch 349\n",
      "Stopping early at epoch 351\n",
      "Stopping early at epoch 352\n",
      "Stopping early at epoch 353\n",
      "Stopping early at epoch 354\n",
      "Stopping early at epoch 355\n",
      "Stopping early at epoch 356\n",
      "Stopping early at epoch 357\n",
      "Stopping early at epoch 359\n",
      "Stopping early at epoch 360\n",
      "Stopping early at epoch 361\n",
      "Stopping early at epoch 362\n",
      "Stopping early at epoch 363\n",
      "Stopping early at epoch 364\n",
      "Stopping early at epoch 365\n",
      "Stopping early at epoch 367\n",
      "Stopping early at epoch 368\n",
      "Stopping early at epoch 369\n",
      "Stopping early at epoch 370\n",
      "Stopping early at epoch 371\n",
      "Stopping early at epoch 372\n",
      "Stopping early at epoch 374\n",
      "Stopping early at epoch 375\n",
      "Stopping early at epoch 376\n",
      "Stopping early at epoch 377\n",
      "Stopping early at epoch 378\n",
      "Stopping early at epoch 379\n",
      "Stopping early at epoch 381\n",
      "Stopping early at epoch 382\n",
      "Stopping early at epoch 383\n",
      "Stopping early at epoch 384\n",
      "Stopping early at epoch 385\n",
      "Stopping early at epoch 386\n",
      "Stopping early at epoch 388\n",
      "Stopping early at epoch 389\n",
      "Stopping early at epoch 390\n",
      "Stopping early at epoch 391\n",
      "Stopping early at epoch 392\n",
      "Stopping early at epoch 394\n",
      "Stopping early at epoch 395\n",
      "Stopping early at epoch 396\n",
      "Stopping early at epoch 397\n",
      "Stopping early at epoch 398\n",
      "Stopping early at epoch 399\n",
      "Epoch: 400, Cumulative Loss: -21669.0\n",
      "Stopping early at epoch 401\n",
      "Stopping early at epoch 402\n",
      "Stopping early at epoch 403\n",
      "Stopping early at epoch 404\n",
      "Stopping early at epoch 405\n",
      "Stopping early at epoch 407\n",
      "Stopping early at epoch 408\n",
      "Stopping early at epoch 409\n",
      "Stopping early at epoch 410\n",
      "Stopping early at epoch 411\n",
      "Stopping early at epoch 413\n",
      "Stopping early at epoch 414\n",
      "Stopping early at epoch 415\n",
      "Stopping early at epoch 416\n",
      "Stopping early at epoch 417\n",
      "Stopping early at epoch 419\n",
      "Stopping early at epoch 420\n",
      "Stopping early at epoch 421\n",
      "Stopping early at epoch 422\n",
      "Stopping early at epoch 423\n",
      "Stopping early at epoch 425\n",
      "Stopping early at epoch 426\n",
      "Stopping early at epoch 427\n",
      "Stopping early at epoch 428\n",
      "Stopping early at epoch 430\n",
      "Stopping early at epoch 431\n",
      "Stopping early at epoch 432\n",
      "Stopping early at epoch 433\n",
      "Stopping early at epoch 434\n",
      "Stopping early at epoch 436\n",
      "Stopping early at epoch 437\n",
      "Stopping early at epoch 438\n",
      "Stopping early at epoch 439\n",
      "Stopping early at epoch 440\n",
      "Stopping early at epoch 442\n",
      "Stopping early at epoch 443\n",
      "Stopping early at epoch 444\n",
      "Stopping early at epoch 445\n",
      "Stopping early at epoch 447\n",
      "Stopping early at epoch 448\n",
      "Stopping early at epoch 449\n",
      "Stopping early at epoch 450\n",
      "Stopping early at epoch 451\n",
      "Stopping early at epoch 453\n",
      "Stopping early at epoch 454\n",
      "Stopping early at epoch 455\n",
      "Stopping early at epoch 456\n",
      "Stopping early at epoch 457\n",
      "Stopping early at epoch 459\n",
      "Stopping early at epoch 460\n",
      "Stopping early at epoch 461\n",
      "Stopping early at epoch 462\n",
      "Stopping early at epoch 464\n",
      "Stopping early at epoch 465\n",
      "Stopping early at epoch 466\n",
      "Stopping early at epoch 467\n",
      "Stopping early at epoch 468\n",
      "Stopping early at epoch 470\n",
      "Stopping early at epoch 471\n",
      "Stopping early at epoch 472\n",
      "Stopping early at epoch 473\n",
      "Stopping early at epoch 475\n",
      "Stopping early at epoch 476\n",
      "Stopping early at epoch 477\n",
      "Stopping early at epoch 478\n",
      "Stopping early at epoch 479\n",
      "Stopping early at epoch 481\n",
      "Stopping early at epoch 482\n",
      "Stopping early at epoch 483\n",
      "Stopping early at epoch 485\n",
      "Stopping early at epoch 486\n",
      "Stopping early at epoch 487\n",
      "Stopping early at epoch 488\n",
      "Stopping early at epoch 489\n",
      "Stopping early at epoch 491\n",
      "Stopping early at epoch 492\n",
      "Stopping early at epoch 494\n",
      "Stopping early at epoch 495\n",
      "Stopping early at epoch 496\n",
      "Stopping early at epoch 497\n",
      "Stopping early at epoch 498\n",
      "Stopping early at epoch 500\n",
      "Epoch: 500, Cumulative Loss: -2229.0\n",
      "Stopping early at epoch 501\n",
      "Stopping early at epoch 502\n",
      "Stopping early at epoch 504\n",
      "Stopping early at epoch 505\n",
      "Stopping early at epoch 506\n",
      "Stopping early at epoch 507\n",
      "Stopping early at epoch 509\n",
      "Stopping early at epoch 510\n",
      "Stopping early at epoch 511\n",
      "Stopping early at epoch 513\n",
      "Stopping early at epoch 514\n",
      "Stopping early at epoch 515\n",
      "Stopping early at epoch 516\n",
      "Stopping early at epoch 518\n",
      "Stopping early at epoch 519\n",
      "Stopping early at epoch 521\n",
      "Stopping early at epoch 522\n",
      "Stopping early at epoch 523\n",
      "Stopping early at epoch 524\n",
      "Stopping early at epoch 525\n",
      "Stopping early at epoch 527\n",
      "Stopping early at epoch 528\n",
      "Stopping early at epoch 529\n",
      "Stopping early at epoch 530\n",
      "Stopping early at epoch 531\n",
      "Stopping early at epoch 532\n",
      "Stopping early at epoch 533\n",
      "Stopping early at epoch 534\n",
      "Stopping early at epoch 535\n",
      "Stopping early at epoch 536\n",
      "Stopping early at epoch 537\n",
      "Stopping early at epoch 538\n",
      "Stopping early at epoch 539\n",
      "Stopping early at epoch 540\n",
      "Stopping early at epoch 541\n",
      "Stopping early at epoch 542\n",
      "Stopping early at epoch 543\n",
      "Stopping early at epoch 544\n",
      "Stopping early at epoch 545\n",
      "Stopping early at epoch 546\n",
      "Stopping early at epoch 547\n",
      "Stopping early at epoch 548\n",
      "Stopping early at epoch 549\n",
      "Stopping early at epoch 550\n",
      "Stopping early at epoch 551\n",
      "Stopping early at epoch 552\n",
      "Stopping early at epoch 553\n",
      "Stopping early at epoch 554\n",
      "Stopping early at epoch 555\n",
      "Stopping early at epoch 556\n",
      "Stopping early at epoch 557\n",
      "Stopping early at epoch 558\n",
      "Stopping early at epoch 559\n",
      "Stopping early at epoch 560\n",
      "Stopping early at epoch 561\n",
      "Stopping early at epoch 562\n",
      "Stopping early at epoch 563\n",
      "Stopping early at epoch 564\n",
      "Stopping early at epoch 565\n",
      "Stopping early at epoch 566\n",
      "Stopping early at epoch 567\n",
      "Stopping early at epoch 568\n",
      "Stopping early at epoch 569\n",
      "Stopping early at epoch 570\n",
      "Stopping early at epoch 571\n",
      "Stopping early at epoch 572\n",
      "Stopping early at epoch 573\n",
      "Stopping early at epoch 574\n",
      "Stopping early at epoch 575\n",
      "Stopping early at epoch 576\n",
      "Stopping early at epoch 577\n",
      "Stopping early at epoch 578\n",
      "Stopping early at epoch 579\n",
      "Stopping early at epoch 580\n",
      "Stopping early at epoch 581\n",
      "Stopping early at epoch 582\n",
      "Stopping early at epoch 583\n",
      "Stopping early at epoch 584\n",
      "Stopping early at epoch 585\n",
      "Stopping early at epoch 586\n",
      "Stopping early at epoch 587\n",
      "Stopping early at epoch 588\n",
      "Stopping early at epoch 589\n",
      "Stopping early at epoch 590\n",
      "Stopping early at epoch 591\n",
      "Stopping early at epoch 592\n",
      "Stopping early at epoch 593\n",
      "Stopping early at epoch 594\n",
      "Stopping early at epoch 595\n",
      "Stopping early at epoch 596\n",
      "Stopping early at epoch 597\n",
      "Stopping early at epoch 598\n",
      "Stopping early at epoch 599\n",
      "Stopping early at epoch 600\n",
      "Epoch: 600, Cumulative Loss: -116.0\n",
      "Stopping early at epoch 601\n",
      "Stopping early at epoch 602\n",
      "Stopping early at epoch 603\n",
      "Stopping early at epoch 604\n",
      "Stopping early at epoch 605\n",
      "Stopping early at epoch 606\n",
      "Stopping early at epoch 607\n",
      "Stopping early at epoch 608\n",
      "Stopping early at epoch 609\n",
      "Stopping early at epoch 610\n",
      "Stopping early at epoch 611\n",
      "Stopping early at epoch 612\n",
      "Stopping early at epoch 613\n",
      "Stopping early at epoch 614\n",
      "Stopping early at epoch 615\n",
      "Stopping early at epoch 616\n",
      "Stopping early at epoch 617\n",
      "Stopping early at epoch 618\n",
      "Stopping early at epoch 619\n",
      "Stopping early at epoch 620\n",
      "Stopping early at epoch 621\n",
      "Stopping early at epoch 622\n",
      "Stopping early at epoch 623\n",
      "Stopping early at epoch 624\n",
      "Stopping early at epoch 625\n",
      "Stopping early at epoch 626\n",
      "Stopping early at epoch 627\n",
      "Stopping early at epoch 628\n",
      "Stopping early at epoch 629\n",
      "Stopping early at epoch 630\n",
      "Stopping early at epoch 631\n",
      "Stopping early at epoch 632\n",
      "Stopping early at epoch 633\n",
      "Stopping early at epoch 634\n",
      "Stopping early at epoch 635\n",
      "Stopping early at epoch 636\n",
      "Stopping early at epoch 637\n",
      "Stopping early at epoch 638\n",
      "Stopping early at epoch 639\n",
      "Stopping early at epoch 640\n",
      "Stopping early at epoch 641\n",
      "Stopping early at epoch 642\n",
      "Stopping early at epoch 643\n",
      "Stopping early at epoch 644\n",
      "Stopping early at epoch 645\n",
      "Stopping early at epoch 646\n",
      "Stopping early at epoch 647\n",
      "Stopping early at epoch 648\n",
      "Stopping early at epoch 649\n",
      "Stopping early at epoch 650\n",
      "Stopping early at epoch 651\n",
      "Stopping early at epoch 652\n",
      "Stopping early at epoch 653\n",
      "Stopping early at epoch 654\n",
      "Stopping early at epoch 655\n",
      "Stopping early at epoch 656\n",
      "Stopping early at epoch 657\n",
      "Stopping early at epoch 658\n",
      "Stopping early at epoch 659\n",
      "Stopping early at epoch 660\n",
      "Stopping early at epoch 661\n",
      "Stopping early at epoch 662\n",
      "Stopping early at epoch 663\n",
      "Stopping early at epoch 664\n",
      "Stopping early at epoch 665\n",
      "Stopping early at epoch 666\n",
      "Stopping early at epoch 667\n",
      "Stopping early at epoch 668\n",
      "Stopping early at epoch 669\n",
      "Stopping early at epoch 670\n",
      "Stopping early at epoch 671\n",
      "Stopping early at epoch 672\n",
      "Stopping early at epoch 673\n",
      "Stopping early at epoch 674\n",
      "Stopping early at epoch 675\n",
      "Stopping early at epoch 676\n",
      "Stopping early at epoch 677\n",
      "Stopping early at epoch 678\n",
      "Stopping early at epoch 679\n",
      "Stopping early at epoch 680\n",
      "Stopping early at epoch 681\n",
      "Stopping early at epoch 682\n",
      "Stopping early at epoch 683\n",
      "Stopping early at epoch 684\n",
      "Stopping early at epoch 685\n",
      "Stopping early at epoch 686\n",
      "Stopping early at epoch 687\n",
      "Stopping early at epoch 688\n",
      "Stopping early at epoch 689\n",
      "Stopping early at epoch 690\n",
      "Stopping early at epoch 691\n",
      "Stopping early at epoch 692\n",
      "Stopping early at epoch 693\n",
      "Stopping early at epoch 694\n",
      "Stopping early at epoch 695\n",
      "Stopping early at epoch 696\n",
      "Stopping early at epoch 697\n",
      "Stopping early at epoch 698\n",
      "Stopping early at epoch 699\n",
      "Stopping early at epoch 700\n",
      "Epoch: 700, Cumulative Loss: -116.0\n",
      "Stopping early at epoch 701\n",
      "Stopping early at epoch 702\n",
      "Stopping early at epoch 703\n",
      "Stopping early at epoch 704\n",
      "Stopping early at epoch 705\n",
      "Stopping early at epoch 706\n",
      "Stopping early at epoch 707\n",
      "Stopping early at epoch 708\n",
      "Stopping early at epoch 709\n",
      "Stopping early at epoch 710\n",
      "Stopping early at epoch 711\n",
      "Stopping early at epoch 712\n",
      "Stopping early at epoch 713\n",
      "Stopping early at epoch 714\n",
      "Stopping early at epoch 715\n",
      "Stopping early at epoch 716\n",
      "Stopping early at epoch 717\n",
      "Stopping early at epoch 718\n",
      "Stopping early at epoch 719\n",
      "Stopping early at epoch 720\n",
      "Stopping early at epoch 721\n",
      "Stopping early at epoch 722\n",
      "Stopping early at epoch 723\n",
      "Stopping early at epoch 724\n",
      "Stopping early at epoch 725\n",
      "Stopping early at epoch 726\n",
      "Stopping early at epoch 727\n",
      "Stopping early at epoch 728\n",
      "Stopping early at epoch 729\n",
      "Stopping early at epoch 730\n",
      "Stopping early at epoch 731\n",
      "Stopping early at epoch 732\n",
      "Stopping early at epoch 733\n",
      "Stopping early at epoch 734\n",
      "Stopping early at epoch 735\n",
      "Stopping early at epoch 736\n",
      "Stopping early at epoch 737\n",
      "Stopping early at epoch 738\n",
      "Stopping early at epoch 739\n",
      "Stopping early at epoch 740\n",
      "Stopping early at epoch 741\n",
      "Stopping early at epoch 742\n",
      "Stopping early at epoch 743\n",
      "Stopping early at epoch 744\n",
      "Stopping early at epoch 745\n",
      "Stopping early at epoch 746\n",
      "Stopping early at epoch 747\n",
      "Stopping early at epoch 748\n",
      "Stopping early at epoch 749\n",
      "Stopping early at epoch 750\n",
      "Stopping early at epoch 751\n",
      "Stopping early at epoch 752\n",
      "Stopping early at epoch 753\n",
      "Stopping early at epoch 754\n",
      "Stopping early at epoch 755\n",
      "Stopping early at epoch 756\n",
      "Stopping early at epoch 757\n",
      "Stopping early at epoch 758\n",
      "Stopping early at epoch 759\n",
      "Stopping early at epoch 760\n",
      "Stopping early at epoch 761\n",
      "Stopping early at epoch 762\n",
      "Stopping early at epoch 763\n",
      "Stopping early at epoch 764\n",
      "Stopping early at epoch 765\n",
      "Stopping early at epoch 766\n",
      "Stopping early at epoch 767\n",
      "Stopping early at epoch 768\n",
      "Stopping early at epoch 769\n",
      "Stopping early at epoch 770\n",
      "Stopping early at epoch 771\n",
      "Stopping early at epoch 772\n",
      "Stopping early at epoch 773\n",
      "Stopping early at epoch 774\n",
      "Stopping early at epoch 775\n",
      "Stopping early at epoch 776\n",
      "Stopping early at epoch 777\n",
      "Stopping early at epoch 778\n",
      "Stopping early at epoch 779\n",
      "Stopping early at epoch 780\n",
      "Stopping early at epoch 781\n",
      "Stopping early at epoch 782\n",
      "Stopping early at epoch 783\n",
      "Stopping early at epoch 784\n",
      "Stopping early at epoch 785\n",
      "Stopping early at epoch 786\n",
      "Stopping early at epoch 787\n",
      "Stopping early at epoch 788\n",
      "Stopping early at epoch 789\n",
      "Stopping early at epoch 790\n",
      "Stopping early at epoch 791\n",
      "Stopping early at epoch 792\n",
      "Stopping early at epoch 793\n",
      "Stopping early at epoch 794\n",
      "Stopping early at epoch 795\n",
      "Stopping early at epoch 796\n",
      "Stopping early at epoch 797\n",
      "Stopping early at epoch 798\n",
      "Stopping early at epoch 799\n",
      "Stopping early at epoch 800\n",
      "Epoch: 800, Cumulative Loss: -116.0\n",
      "Stopping early at epoch 801\n",
      "Stopping early at epoch 802\n",
      "Stopping early at epoch 803\n",
      "Stopping early at epoch 804\n",
      "Stopping early at epoch 805\n",
      "Stopping early at epoch 806\n",
      "Stopping early at epoch 807\n",
      "Stopping early at epoch 808\n",
      "Stopping early at epoch 809\n",
      "Stopping early at epoch 810\n",
      "Stopping early at epoch 811\n",
      "Stopping early at epoch 812\n",
      "Stopping early at epoch 813\n",
      "Stopping early at epoch 814\n",
      "Stopping early at epoch 815\n",
      "Stopping early at epoch 816\n",
      "Stopping early at epoch 817\n",
      "Stopping early at epoch 818\n",
      "Stopping early at epoch 819\n",
      "Stopping early at epoch 820\n",
      "Stopping early at epoch 821\n",
      "Stopping early at epoch 822\n",
      "Stopping early at epoch 823\n",
      "Stopping early at epoch 824\n",
      "Stopping early at epoch 825\n",
      "Stopping early at epoch 826\n",
      "Stopping early at epoch 827\n",
      "Stopping early at epoch 828\n",
      "Stopping early at epoch 829\n",
      "Stopping early at epoch 830\n",
      "Stopping early at epoch 831\n",
      "Stopping early at epoch 832\n",
      "Stopping early at epoch 833\n",
      "Stopping early at epoch 834\n",
      "Stopping early at epoch 835\n",
      "Stopping early at epoch 836\n",
      "Stopping early at epoch 837\n",
      "Stopping early at epoch 838\n",
      "Stopping early at epoch 839\n",
      "Stopping early at epoch 840\n",
      "Stopping early at epoch 841\n",
      "Stopping early at epoch 842\n",
      "Stopping early at epoch 843\n",
      "Stopping early at epoch 844\n",
      "Stopping early at epoch 845\n",
      "Stopping early at epoch 846\n",
      "Stopping early at epoch 847\n",
      "Stopping early at epoch 848\n",
      "Stopping early at epoch 849\n",
      "Stopping early at epoch 850\n",
      "Stopping early at epoch 851\n",
      "Stopping early at epoch 852\n",
      "Stopping early at epoch 853\n",
      "Stopping early at epoch 854\n",
      "Stopping early at epoch 855\n",
      "Stopping early at epoch 856\n",
      "Stopping early at epoch 857\n",
      "Stopping early at epoch 858\n",
      "Stopping early at epoch 859\n",
      "Stopping early at epoch 860\n",
      "Stopping early at epoch 861\n",
      "Stopping early at epoch 862\n",
      "Stopping early at epoch 863\n",
      "Stopping early at epoch 864\n",
      "Stopping early at epoch 865\n",
      "Stopping early at epoch 866\n",
      "Stopping early at epoch 867\n",
      "Stopping early at epoch 868\n",
      "Stopping early at epoch 869\n",
      "Stopping early at epoch 870\n",
      "Stopping early at epoch 871\n",
      "Stopping early at epoch 872\n",
      "Stopping early at epoch 873\n",
      "Stopping early at epoch 874\n",
      "Stopping early at epoch 875\n",
      "Stopping early at epoch 876\n",
      "Stopping early at epoch 877\n",
      "Stopping early at epoch 878\n",
      "Stopping early at epoch 879\n",
      "Stopping early at epoch 880\n",
      "Stopping early at epoch 881\n",
      "Stopping early at epoch 882\n",
      "Stopping early at epoch 883\n",
      "Stopping early at epoch 884\n",
      "Stopping early at epoch 885\n",
      "Stopping early at epoch 886\n",
      "Stopping early at epoch 887\n",
      "Stopping early at epoch 888\n",
      "Stopping early at epoch 889\n",
      "Stopping early at epoch 890\n",
      "Stopping early at epoch 891\n",
      "Stopping early at epoch 892\n",
      "Stopping early at epoch 893\n",
      "Stopping early at epoch 894\n",
      "Stopping early at epoch 895\n",
      "Stopping early at epoch 896\n",
      "Stopping early at epoch 897\n",
      "Stopping early at epoch 898\n",
      "Stopping early at epoch 899\n",
      "Stopping early at epoch 900\n",
      "Epoch: 900, Cumulative Loss: -116.0\n",
      "Stopping early at epoch 901\n",
      "Stopping early at epoch 902\n",
      "Stopping early at epoch 903\n",
      "Stopping early at epoch 904\n",
      "Stopping early at epoch 905\n",
      "Stopping early at epoch 906\n",
      "Stopping early at epoch 907\n",
      "Stopping early at epoch 908\n",
      "Stopping early at epoch 909\n",
      "Stopping early at epoch 910\n",
      "Stopping early at epoch 911\n",
      "Stopping early at epoch 912\n",
      "Stopping early at epoch 913\n",
      "Stopping early at epoch 914\n",
      "Stopping early at epoch 915\n",
      "Stopping early at epoch 916\n",
      "Stopping early at epoch 917\n",
      "Stopping early at epoch 918\n",
      "Stopping early at epoch 919\n",
      "Stopping early at epoch 920\n",
      "Stopping early at epoch 921\n",
      "Stopping early at epoch 922\n",
      "Stopping early at epoch 923\n",
      "Stopping early at epoch 924\n",
      "Stopping early at epoch 925\n",
      "Stopping early at epoch 926\n",
      "Stopping early at epoch 927\n",
      "Stopping early at epoch 928\n",
      "Stopping early at epoch 929\n",
      "Stopping early at epoch 930\n",
      "Stopping early at epoch 931\n",
      "Stopping early at epoch 932\n",
      "Stopping early at epoch 933\n",
      "Stopping early at epoch 934\n",
      "Stopping early at epoch 935\n",
      "Stopping early at epoch 936\n",
      "Stopping early at epoch 937\n",
      "Stopping early at epoch 938\n",
      "Stopping early at epoch 939\n",
      "Stopping early at epoch 940\n",
      "Stopping early at epoch 941\n",
      "Stopping early at epoch 942\n",
      "Stopping early at epoch 943\n",
      "Stopping early at epoch 944\n",
      "Stopping early at epoch 945\n",
      "Stopping early at epoch 946\n",
      "Stopping early at epoch 947\n",
      "Stopping early at epoch 948\n",
      "Stopping early at epoch 949\n",
      "Stopping early at epoch 950\n",
      "Stopping early at epoch 951\n",
      "Stopping early at epoch 952\n",
      "Stopping early at epoch 953\n",
      "Stopping early at epoch 954\n",
      "Stopping early at epoch 955\n",
      "Stopping early at epoch 956\n",
      "Stopping early at epoch 957\n",
      "Stopping early at epoch 958\n",
      "Stopping early at epoch 959\n",
      "Stopping early at epoch 960\n",
      "Stopping early at epoch 961\n",
      "Stopping early at epoch 962\n",
      "Stopping early at epoch 963\n",
      "Stopping early at epoch 964\n",
      "Stopping early at epoch 965\n",
      "Stopping early at epoch 966\n",
      "Stopping early at epoch 967\n",
      "Stopping early at epoch 968\n",
      "Stopping early at epoch 969\n",
      "Stopping early at epoch 970\n",
      "Stopping early at epoch 971\n",
      "Stopping early at epoch 972\n",
      "Stopping early at epoch 973\n",
      "Stopping early at epoch 974\n",
      "Stopping early at epoch 975\n",
      "Stopping early at epoch 976\n",
      "Stopping early at epoch 977\n",
      "Stopping early at epoch 978\n",
      "Stopping early at epoch 979\n",
      "Stopping early at epoch 980\n",
      "Stopping early at epoch 981\n",
      "Stopping early at epoch 982\n",
      "Stopping early at epoch 983\n",
      "Stopping early at epoch 984\n",
      "Stopping early at epoch 985\n",
      "Stopping early at epoch 986\n",
      "Stopping early at epoch 987\n",
      "Stopping early at epoch 988\n",
      "Stopping early at epoch 989\n",
      "Stopping early at epoch 990\n",
      "Stopping early at epoch 991\n",
      "Stopping early at epoch 992\n",
      "Stopping early at epoch 993\n",
      "Stopping early at epoch 994\n",
      "Stopping early at epoch 995\n",
      "Stopping early at epoch 996\n",
      "Stopping early at epoch 997\n",
      "Stopping early at epoch 998\n",
      "Stopping early at epoch 999\n",
      "GNN training took 47.05 seconds.\n",
      "Best cumulative loss: -21755.0\n"
     ]
    }
   ],
   "source": [
    "trained_net, bestLost, epoch, inp, lossList = train1('_80MaxwayCut_LossExp1_loss.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 2 - loss\n",
    "\n",
    "- expriment 2 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- removing terminal loss\n",
    "- graph n=500, d=3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def max_to_one_hot(tensor):\n",
    "    # Find the index of the maximum value\n",
    "    max_index = torch.argmax(tensor)\n",
    "\n",
    "    # Create a one-hot encoded tensor\n",
    "    one_hot_tensor = torch.zeros_like(tensor)\n",
    "    one_hot_tensor[max_index] = 1.0\n",
    "\n",
    "    one_hot_tensor = one_hot_tensor + tensor - tensor.detach()\n",
    "\n",
    "    return one_hot_tensor\n",
    "\n",
    "def apply_max_to_one_hot(output):\n",
    "    return torch.stack([max_to_one_hot(output[i]) for i in range(output.size(0))])\n",
    "\n",
    "\n",
    "def run_gnn_training2(dataset, net, optimizer, number_epochs, tol, patience, loss_func, dim_embedding, total_classes=3, save_directory=None, torch_dtype = TORCH_DTYPE, torch_device = TORCH_DEVICE, labels=None):\n",
    "    \"\"\"\n",
    "    Train a GCN model with early stopping.\n",
    "    \"\"\"\n",
    "    # loss for a whole epoch\n",
    "    prev_loss = float('inf')  # Set initial loss to infinity for comparison\n",
    "    prev_cummulative_loss = float('inf')\n",
    "    cummulativeCount = 0\n",
    "    count = 0  # Patience counter\n",
    "    best_loss = float('inf')  # Initialize best loss to infinity\n",
    "    best_model_state = None  # Placeholder for the best model state\n",
    "    loss_list = []\n",
    "    epochList = []\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    t_gnn_start = time()\n",
    "\n",
    "    # contains information regarding all terminal nodes for the dataset\n",
    "    terminal_configs = {}\n",
    "    epochCount = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    A = nn.Parameter(torch.tensor([65.0]))\n",
    "    C = nn.Parameter(torch.tensor([32.5]))\n",
    "\n",
    "    embed = nn.Embedding(500, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "    inputs = embed.weight\n",
    "\n",
    "    for epoch in range(number_epochs):\n",
    "\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss for each epoch\n",
    "\n",
    "        for key, (dgl_graph, adjacency_matrix,graph, terminals) in dataset.items():\n",
    "            epochCount +=1\n",
    "\n",
    "\n",
    "            # Ensure model is in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Pass the graph and the input features to the model\n",
    "            logits = net(dgl_graph, adjacency_matrix)\n",
    "            logits = override_fixed_nodes(logits)\n",
    "            # Apply max to one-hot encoding\n",
    "            one_hot_output = apply_max_to_one_hot(logits)\n",
    "            # Compute the loss\n",
    "            # loss = loss_func(criterion, logits, labels, terminals[0], terminals[1])\n",
    "\n",
    "            loss = loss_func( one_hot_output, adjacency_matrix)\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update cumulative loss\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            # # Check for early stopping\n",
    "            if epoch > 0 and (cumulative_loss > prev_loss or abs(prev_loss - cumulative_loss) <= tol):\n",
    "                count += 1\n",
    "                if count >= patience: # play around with patience value, try lower one\n",
    "                    print(f'Stopping early at epoch {epoch}')\n",
    "                    break\n",
    "            else:\n",
    "                count = 0  # Reset patience counter if loss decreases\n",
    "\n",
    "            # Update best model\n",
    "            if cumulative_loss < best_loss:\n",
    "                best_loss = cumulative_loss\n",
    "                best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        # # Early stopping break from the outer loop\n",
    "        # if count >= patience:\n",
    "        #     count=0\n",
    "\n",
    "        prev_loss = cumulative_loss  # Update previous loss\n",
    "\n",
    "        if epoch % 100 == 0:  # Adjust printing frequency as needed\n",
    "            print(f'Epoch: {epoch}, Cumulative Loss: {cumulative_loss}')\n",
    "\n",
    "            if save_directory != None:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model': net.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lossList':loss_list,\n",
    "                    'inputs':inputs}\n",
    "                torch.save(checkpoint, './epoch'+str(epoch)+'loss'+str(cumulative_loss)+ save_directory)\n",
    "\n",
    "            if (prev_cummulative_loss == cummulativeCount):\n",
    "                cummulativeCount+=1\n",
    "\n",
    "                if cummulativeCount > 4:\n",
    "                    break\n",
    "            else:\n",
    "                prev_cummulative_loss = cumulative_loss\n",
    "\n",
    "\n",
    "    t_gnn = time() - t_gnn_start\n",
    "\n",
    "    # Load the best model state\n",
    "    if best_model_state is not None:\n",
    "        net.load_state_dict(best_model_state)\n",
    "\n",
    "    print(f'GNN training took {round(t_gnn, 3)} seconds.')\n",
    "    print(f'Best cumulative loss: {best_loss}')\n",
    "    loss = loss_func(logits, adjacency_matrix)\n",
    "    if save_directory != None:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lossList':loss_list,\n",
    "            'inputs':inputs}\n",
    "        torch.save(checkpoint, './final_'+save_directory)\n",
    "\n",
    "    return net, best_loss, epoch, inputs, loss_list\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        # h = override_fixed_nodes(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[100] = torch.tensor([1.0, 0.0, 0.0],requires_grad=True) + h[10] - h[10].detach()\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[300] = torch.tensor([0.0, 1.0, 0.0],requires_grad=True)+ h[40] - h[40].detach()\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[450] = torch.tensor([0.0, 0.0, 1.0],requires_grad=True)+ h[70] - h[70].detach()\n",
    "    return output\n",
    "\n",
    "def calculate_HC_vectorized(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute the minimum cut loss, which is the total weight of edges cut between partitions using vectorized operations.\n",
    "\n",
    "    Parameters:\n",
    "    s (torch.Tensor): Binary partition matrix of shape (num_nodes, num_partitions)\n",
    "    adjacency_matrix (torch.Tensor): Adjacency matrix of the graph of shape (num_nodes, num_nodes)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Scalar loss value representing the total weight of edges cut\n",
    "    \"\"\"\n",
    "    num_nodes, num_partitions = s.shape\n",
    "\n",
    "    # Compute the partition probability matrix for all partitions\n",
    "    partition_prob_matrix = s @ s.T\n",
    "\n",
    "    # Compute the cut value by summing weights of edges that connect nodes in different partitions\n",
    "    cut_value = adjacency_matrix * (1 - partition_prob_matrix)\n",
    "\n",
    "    # Sum up the contributions for all edges\n",
    "    loss = torch.sum(cut_value) / 2  # Divide by 2 to correct for double-counting\n",
    "\n",
    "    return loss\n",
    "\n",
    "def Loss(s, adjacency_matrix,  A=1, C=1):\n",
    "    HC = -1*calculate_HC_vectorized(s, adjacency_matrix)\n",
    "    return C * HC\n",
    "\n",
    "\n",
    "def loss_terminal(s, adjacency_matrix,  A=0, C=1, penalty=1000):\n",
    "    loss = Loss(s, adjacency_matrix, A, C)\n",
    "    # loss += penalty* terminal_independence_penalty(s, [0,1,2])\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cumulative Loss: -119754.0\n",
      "Stopping early at epoch 1\n",
      "Stopping early at epoch 2\n",
      "Stopping early at epoch 3\n",
      "Stopping early at epoch 5\n",
      "Stopping early at epoch 6\n",
      "Stopping early at epoch 7\n",
      "Stopping early at epoch 9\n",
      "Stopping early at epoch 10\n",
      "Stopping early at epoch 12\n",
      "Stopping early at epoch 13\n",
      "Stopping early at epoch 14\n",
      "Stopping early at epoch 16\n",
      "Stopping early at epoch 17\n",
      "Stopping early at epoch 18\n",
      "Stopping early at epoch 20\n",
      "Stopping early at epoch 21\n",
      "Stopping early at epoch 23\n",
      "Stopping early at epoch 24\n",
      "Stopping early at epoch 25\n",
      "Stopping early at epoch 27\n",
      "Stopping early at epoch 28\n",
      "Stopping early at epoch 29\n",
      "Stopping early at epoch 30\n",
      "Stopping early at epoch 32\n",
      "Stopping early at epoch 33\n",
      "Stopping early at epoch 34\n",
      "Stopping early at epoch 36\n",
      "Stopping early at epoch 37\n",
      "Stopping early at epoch 38\n",
      "Stopping early at epoch 40\n",
      "Stopping early at epoch 41\n",
      "Stopping early at epoch 42\n",
      "Stopping early at epoch 43\n",
      "Stopping early at epoch 44\n",
      "Stopping early at epoch 45\n",
      "Stopping early at epoch 46\n",
      "Stopping early at epoch 48\n",
      "Stopping early at epoch 49\n",
      "Stopping early at epoch 50\n",
      "Stopping early at epoch 52\n",
      "Stopping early at epoch 53\n",
      "Stopping early at epoch 54\n",
      "Stopping early at epoch 56\n",
      "Stopping early at epoch 57\n",
      "Stopping early at epoch 58\n",
      "Stopping early at epoch 59\n",
      "Stopping early at epoch 61\n",
      "Stopping early at epoch 62\n",
      "Stopping early at epoch 63\n",
      "Stopping early at epoch 65\n",
      "Stopping early at epoch 66\n",
      "Stopping early at epoch 67\n",
      "Stopping early at epoch 68\n",
      "Stopping early at epoch 70\n",
      "Stopping early at epoch 71\n",
      "Stopping early at epoch 72\n",
      "Stopping early at epoch 74\n",
      "Stopping early at epoch 75\n",
      "Stopping early at epoch 76\n",
      "Stopping early at epoch 78\n",
      "Stopping early at epoch 79\n",
      "Stopping early at epoch 80\n",
      "Stopping early at epoch 81\n",
      "Stopping early at epoch 82\n",
      "Stopping early at epoch 83\n",
      "Stopping early at epoch 84\n",
      "Stopping early at epoch 86\n",
      "Stopping early at epoch 87\n",
      "Stopping early at epoch 88\n",
      "Stopping early at epoch 89\n",
      "Stopping early at epoch 90\n",
      "Stopping early at epoch 92\n",
      "Stopping early at epoch 93\n",
      "Stopping early at epoch 94\n",
      "Stopping early at epoch 95\n",
      "Stopping early at epoch 97\n",
      "Stopping early at epoch 98\n",
      "Stopping early at epoch 100\n",
      "Epoch: 100, Cumulative Loss: -13694.0\n",
      "Stopping early at epoch 101\n",
      "Stopping early at epoch 102\n",
      "Stopping early at epoch 103\n",
      "Stopping early at epoch 104\n",
      "Stopping early at epoch 106\n",
      "Stopping early at epoch 107\n",
      "Stopping early at epoch 108\n",
      "Stopping early at epoch 109\n",
      "Stopping early at epoch 110\n",
      "Stopping early at epoch 111\n",
      "Stopping early at epoch 112\n",
      "Stopping early at epoch 114\n",
      "Stopping early at epoch 115\n",
      "Stopping early at epoch 117\n",
      "Stopping early at epoch 118\n",
      "Stopping early at epoch 119\n",
      "Stopping early at epoch 120\n",
      "Stopping early at epoch 122\n",
      "Stopping early at epoch 123\n",
      "Stopping early at epoch 124\n",
      "Stopping early at epoch 126\n",
      "Stopping early at epoch 127\n",
      "Stopping early at epoch 128\n",
      "Stopping early at epoch 129\n",
      "Stopping early at epoch 130\n",
      "Stopping early at epoch 131\n",
      "Stopping early at epoch 132\n",
      "Stopping early at epoch 133\n",
      "Stopping early at epoch 134\n",
      "Stopping early at epoch 135\n",
      "Stopping early at epoch 136\n",
      "Stopping early at epoch 137\n",
      "Stopping early at epoch 138\n",
      "Stopping early at epoch 139\n",
      "Stopping early at epoch 140\n",
      "Stopping early at epoch 141\n",
      "Stopping early at epoch 142\n",
      "Stopping early at epoch 143\n",
      "Stopping early at epoch 144\n",
      "Stopping early at epoch 145\n",
      "Stopping early at epoch 146\n",
      "Stopping early at epoch 147\n",
      "Stopping early at epoch 148\n",
      "Stopping early at epoch 149\n",
      "Stopping early at epoch 150\n",
      "Stopping early at epoch 151\n",
      "Stopping early at epoch 152\n",
      "Stopping early at epoch 153\n",
      "Stopping early at epoch 154\n",
      "Stopping early at epoch 155\n",
      "Stopping early at epoch 156\n",
      "Stopping early at epoch 157\n",
      "Stopping early at epoch 158\n",
      "Stopping early at epoch 159\n",
      "Stopping early at epoch 160\n",
      "Stopping early at epoch 161\n",
      "Stopping early at epoch 162\n",
      "Stopping early at epoch 163\n",
      "Stopping early at epoch 164\n",
      "Stopping early at epoch 165\n",
      "Stopping early at epoch 166\n",
      "Stopping early at epoch 167\n",
      "Stopping early at epoch 168\n",
      "Stopping early at epoch 169\n",
      "Stopping early at epoch 170\n",
      "Stopping early at epoch 171\n",
      "Stopping early at epoch 172\n",
      "Stopping early at epoch 173\n",
      "Stopping early at epoch 174\n",
      "Stopping early at epoch 175\n",
      "Stopping early at epoch 176\n",
      "Stopping early at epoch 177\n",
      "Stopping early at epoch 178\n",
      "Stopping early at epoch 179\n",
      "Stopping early at epoch 180\n",
      "Stopping early at epoch 181\n",
      "Stopping early at epoch 183\n",
      "Stopping early at epoch 184\n",
      "Stopping early at epoch 185\n",
      "Stopping early at epoch 186\n",
      "Stopping early at epoch 187\n",
      "Stopping early at epoch 188\n",
      "Stopping early at epoch 189\n",
      "Stopping early at epoch 190\n",
      "Stopping early at epoch 191\n",
      "Stopping early at epoch 192\n",
      "Stopping early at epoch 193\n",
      "Stopping early at epoch 194\n",
      "Stopping early at epoch 195\n",
      "Stopping early at epoch 196\n",
      "Stopping early at epoch 197\n",
      "Stopping early at epoch 198\n",
      "Stopping early at epoch 199\n",
      "Stopping early at epoch 200\n",
      "Epoch: 200, Cumulative Loss: -715.0\n",
      "Stopping early at epoch 201\n",
      "Stopping early at epoch 202\n",
      "Stopping early at epoch 203\n",
      "Stopping early at epoch 204\n",
      "Stopping early at epoch 205\n",
      "Stopping early at epoch 206\n",
      "Stopping early at epoch 207\n",
      "Stopping early at epoch 208\n",
      "Stopping early at epoch 209\n",
      "Stopping early at epoch 210\n",
      "Stopping early at epoch 211\n",
      "Stopping early at epoch 212\n",
      "Stopping early at epoch 213\n",
      "Stopping early at epoch 214\n",
      "Stopping early at epoch 215\n",
      "Stopping early at epoch 216\n",
      "Stopping early at epoch 217\n",
      "Stopping early at epoch 218\n",
      "Stopping early at epoch 219\n",
      "Stopping early at epoch 220\n",
      "Stopping early at epoch 221\n",
      "Stopping early at epoch 223\n",
      "Stopping early at epoch 224\n",
      "Stopping early at epoch 225\n",
      "Stopping early at epoch 226\n",
      "Stopping early at epoch 227\n",
      "Stopping early at epoch 228\n",
      "Stopping early at epoch 229\n",
      "Stopping early at epoch 230\n",
      "Stopping early at epoch 231\n",
      "Stopping early at epoch 232\n",
      "Stopping early at epoch 233\n",
      "Stopping early at epoch 234\n",
      "Stopping early at epoch 235\n",
      "Stopping early at epoch 236\n",
      "Stopping early at epoch 237\n",
      "Stopping early at epoch 238\n",
      "Stopping early at epoch 239\n",
      "Stopping early at epoch 240\n",
      "Stopping early at epoch 241\n",
      "Stopping early at epoch 242\n",
      "Stopping early at epoch 243\n",
      "Stopping early at epoch 244\n",
      "Stopping early at epoch 245\n",
      "Stopping early at epoch 246\n",
      "Stopping early at epoch 247\n",
      "Stopping early at epoch 248\n",
      "Stopping early at epoch 249\n",
      "Stopping early at epoch 250\n",
      "Stopping early at epoch 251\n",
      "Stopping early at epoch 252\n",
      "Stopping early at epoch 253\n",
      "Stopping early at epoch 254\n",
      "Stopping early at epoch 255\n",
      "Stopping early at epoch 256\n",
      "Stopping early at epoch 257\n",
      "Stopping early at epoch 258\n",
      "Stopping early at epoch 259\n",
      "Stopping early at epoch 260\n",
      "Stopping early at epoch 261\n",
      "Stopping early at epoch 263\n",
      "Stopping early at epoch 264\n",
      "Stopping early at epoch 265\n",
      "Stopping early at epoch 266\n",
      "Stopping early at epoch 267\n",
      "Stopping early at epoch 268\n",
      "Stopping early at epoch 269\n",
      "Stopping early at epoch 270\n",
      "Stopping early at epoch 271\n",
      "Stopping early at epoch 272\n",
      "Stopping early at epoch 273\n",
      "Stopping early at epoch 274\n",
      "Stopping early at epoch 275\n",
      "Stopping early at epoch 276\n",
      "Stopping early at epoch 277\n",
      "Stopping early at epoch 278\n",
      "Stopping early at epoch 279\n",
      "Stopping early at epoch 280\n",
      "Stopping early at epoch 281\n",
      "Stopping early at epoch 282\n",
      "Stopping early at epoch 283\n",
      "Stopping early at epoch 284\n",
      "Stopping early at epoch 285\n",
      "Stopping early at epoch 286\n",
      "Stopping early at epoch 287\n",
      "Stopping early at epoch 288\n",
      "Stopping early at epoch 289\n",
      "Stopping early at epoch 290\n",
      "Stopping early at epoch 292\n",
      "Stopping early at epoch 293\n",
      "Stopping early at epoch 294\n",
      "Stopping early at epoch 295\n",
      "Stopping early at epoch 296\n",
      "Stopping early at epoch 297\n",
      "Stopping early at epoch 298\n",
      "Stopping early at epoch 299\n",
      "Stopping early at epoch 300\n",
      "Epoch: 300, Cumulative Loss: -715.0\n",
      "Stopping early at epoch 301\n",
      "Stopping early at epoch 302\n",
      "Stopping early at epoch 303\n",
      "Stopping early at epoch 304\n",
      "Stopping early at epoch 305\n",
      "Stopping early at epoch 306\n",
      "Stopping early at epoch 307\n",
      "Stopping early at epoch 308\n",
      "Stopping early at epoch 309\n",
      "Stopping early at epoch 310\n",
      "Stopping early at epoch 311\n",
      "Stopping early at epoch 312\n",
      "Stopping early at epoch 313\n",
      "Stopping early at epoch 314\n",
      "Stopping early at epoch 315\n",
      "Stopping early at epoch 317\n",
      "Stopping early at epoch 318\n",
      "Stopping early at epoch 319\n",
      "Stopping early at epoch 320\n",
      "Stopping early at epoch 321\n",
      "Stopping early at epoch 322\n",
      "Stopping early at epoch 323\n",
      "Stopping early at epoch 324\n",
      "Stopping early at epoch 325\n",
      "Stopping early at epoch 326\n",
      "Stopping early at epoch 327\n",
      "Stopping early at epoch 328\n",
      "Stopping early at epoch 329\n",
      "Stopping early at epoch 330\n",
      "Stopping early at epoch 331\n",
      "Stopping early at epoch 332\n",
      "Stopping early at epoch 333\n",
      "Stopping early at epoch 335\n",
      "Stopping early at epoch 336\n",
      "Stopping early at epoch 337\n",
      "Stopping early at epoch 338\n",
      "Stopping early at epoch 339\n",
      "Stopping early at epoch 340\n",
      "Stopping early at epoch 341\n",
      "Stopping early at epoch 342\n",
      "Stopping early at epoch 343\n",
      "Stopping early at epoch 344\n",
      "Stopping early at epoch 345\n",
      "Stopping early at epoch 346\n",
      "Stopping early at epoch 347\n",
      "Stopping early at epoch 348\n",
      "Stopping early at epoch 349\n",
      "Stopping early at epoch 350\n",
      "Stopping early at epoch 351\n",
      "Stopping early at epoch 352\n",
      "Stopping early at epoch 353\n",
      "Stopping early at epoch 354\n",
      "Stopping early at epoch 355\n",
      "Stopping early at epoch 357\n",
      "Stopping early at epoch 358\n",
      "Stopping early at epoch 359\n",
      "Stopping early at epoch 360\n",
      "Stopping early at epoch 361\n",
      "Stopping early at epoch 362\n",
      "Stopping early at epoch 363\n",
      "Stopping early at epoch 364\n",
      "Stopping early at epoch 365\n",
      "Stopping early at epoch 366\n",
      "Stopping early at epoch 367\n",
      "Stopping early at epoch 368\n",
      "Stopping early at epoch 369\n",
      "Stopping early at epoch 370\n",
      "Stopping early at epoch 372\n",
      "Stopping early at epoch 373\n",
      "Stopping early at epoch 374\n",
      "Stopping early at epoch 375\n",
      "Stopping early at epoch 376\n",
      "Stopping early at epoch 377\n",
      "Stopping early at epoch 378\n",
      "Stopping early at epoch 379\n",
      "Stopping early at epoch 380\n",
      "Stopping early at epoch 381\n",
      "Stopping early at epoch 383\n",
      "Stopping early at epoch 384\n",
      "Stopping early at epoch 385\n",
      "Stopping early at epoch 386\n",
      "Stopping early at epoch 387\n",
      "Stopping early at epoch 388\n",
      "Stopping early at epoch 389\n",
      "Stopping early at epoch 390\n",
      "Stopping early at epoch 391\n",
      "Stopping early at epoch 393\n",
      "Stopping early at epoch 394\n",
      "Stopping early at epoch 395\n",
      "Stopping early at epoch 396\n",
      "Stopping early at epoch 397\n",
      "Stopping early at epoch 398\n",
      "Stopping early at epoch 399\n",
      "Stopping early at epoch 400\n",
      "Epoch: 400, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 401\n",
      "Stopping early at epoch 402\n",
      "Stopping early at epoch 403\n",
      "Stopping early at epoch 404\n",
      "Stopping early at epoch 405\n",
      "Stopping early at epoch 406\n",
      "Stopping early at epoch 407\n",
      "Stopping early at epoch 408\n",
      "Stopping early at epoch 409\n",
      "Stopping early at epoch 410\n",
      "Stopping early at epoch 411\n",
      "Stopping early at epoch 412\n",
      "Stopping early at epoch 413\n",
      "Stopping early at epoch 414\n",
      "Stopping early at epoch 415\n",
      "Stopping early at epoch 416\n",
      "Stopping early at epoch 417\n",
      "Stopping early at epoch 418\n",
      "Stopping early at epoch 419\n",
      "Stopping early at epoch 420\n",
      "Stopping early at epoch 421\n",
      "Stopping early at epoch 422\n",
      "Stopping early at epoch 423\n",
      "Stopping early at epoch 424\n",
      "Stopping early at epoch 425\n",
      "Stopping early at epoch 426\n",
      "Stopping early at epoch 427\n",
      "Stopping early at epoch 428\n",
      "Stopping early at epoch 429\n",
      "Stopping early at epoch 430\n",
      "Stopping early at epoch 431\n",
      "Stopping early at epoch 432\n",
      "Stopping early at epoch 433\n",
      "Stopping early at epoch 434\n",
      "Stopping early at epoch 435\n",
      "Stopping early at epoch 436\n",
      "Stopping early at epoch 437\n",
      "Stopping early at epoch 438\n",
      "Stopping early at epoch 439\n",
      "Stopping early at epoch 440\n",
      "Stopping early at epoch 441\n",
      "Stopping early at epoch 442\n",
      "Stopping early at epoch 443\n",
      "Stopping early at epoch 444\n",
      "Stopping early at epoch 445\n",
      "Stopping early at epoch 446\n",
      "Stopping early at epoch 447\n",
      "Stopping early at epoch 448\n",
      "Stopping early at epoch 449\n",
      "Stopping early at epoch 450\n",
      "Stopping early at epoch 451\n",
      "Stopping early at epoch 452\n",
      "Stopping early at epoch 453\n",
      "Stopping early at epoch 454\n",
      "Stopping early at epoch 455\n",
      "Stopping early at epoch 456\n",
      "Stopping early at epoch 457\n",
      "Stopping early at epoch 458\n",
      "Stopping early at epoch 459\n",
      "Stopping early at epoch 460\n",
      "Stopping early at epoch 461\n",
      "Stopping early at epoch 462\n",
      "Stopping early at epoch 463\n",
      "Stopping early at epoch 464\n",
      "Stopping early at epoch 465\n",
      "Stopping early at epoch 466\n",
      "Stopping early at epoch 467\n",
      "Stopping early at epoch 468\n",
      "Stopping early at epoch 469\n",
      "Stopping early at epoch 470\n",
      "Stopping early at epoch 471\n",
      "Stopping early at epoch 472\n",
      "Stopping early at epoch 473\n",
      "Stopping early at epoch 474\n",
      "Stopping early at epoch 475\n",
      "Stopping early at epoch 476\n",
      "Stopping early at epoch 477\n",
      "Stopping early at epoch 478\n",
      "Stopping early at epoch 479\n",
      "Stopping early at epoch 480\n",
      "Stopping early at epoch 481\n",
      "Stopping early at epoch 482\n",
      "Stopping early at epoch 483\n",
      "Stopping early at epoch 484\n",
      "Stopping early at epoch 485\n",
      "Stopping early at epoch 486\n",
      "Stopping early at epoch 487\n",
      "Stopping early at epoch 488\n",
      "Stopping early at epoch 489\n",
      "Stopping early at epoch 490\n",
      "Stopping early at epoch 491\n",
      "Stopping early at epoch 492\n",
      "Stopping early at epoch 493\n",
      "Stopping early at epoch 494\n",
      "Stopping early at epoch 495\n",
      "Stopping early at epoch 496\n",
      "Stopping early at epoch 497\n",
      "Stopping early at epoch 498\n",
      "Stopping early at epoch 499\n",
      "Stopping early at epoch 500\n",
      "Epoch: 500, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 501\n",
      "Stopping early at epoch 502\n",
      "Stopping early at epoch 503\n",
      "Stopping early at epoch 504\n",
      "Stopping early at epoch 505\n",
      "Stopping early at epoch 506\n",
      "Stopping early at epoch 507\n",
      "Stopping early at epoch 508\n",
      "Stopping early at epoch 509\n",
      "Stopping early at epoch 510\n",
      "Stopping early at epoch 511\n",
      "Stopping early at epoch 512\n",
      "Stopping early at epoch 513\n",
      "Stopping early at epoch 514\n",
      "Stopping early at epoch 515\n",
      "Stopping early at epoch 516\n",
      "Stopping early at epoch 517\n",
      "Stopping early at epoch 518\n",
      "Stopping early at epoch 519\n",
      "Stopping early at epoch 520\n",
      "Stopping early at epoch 521\n",
      "Stopping early at epoch 522\n",
      "Stopping early at epoch 523\n",
      "Stopping early at epoch 524\n",
      "Stopping early at epoch 525\n",
      "Stopping early at epoch 526\n",
      "Stopping early at epoch 527\n",
      "Stopping early at epoch 528\n",
      "Stopping early at epoch 529\n",
      "Stopping early at epoch 530\n",
      "Stopping early at epoch 531\n",
      "Stopping early at epoch 532\n",
      "Stopping early at epoch 533\n",
      "Stopping early at epoch 534\n",
      "Stopping early at epoch 535\n",
      "Stopping early at epoch 536\n",
      "Stopping early at epoch 537\n",
      "Stopping early at epoch 538\n",
      "Stopping early at epoch 539\n",
      "Stopping early at epoch 540\n",
      "Stopping early at epoch 541\n",
      "Stopping early at epoch 542\n",
      "Stopping early at epoch 543\n",
      "Stopping early at epoch 544\n",
      "Stopping early at epoch 545\n",
      "Stopping early at epoch 546\n",
      "Stopping early at epoch 547\n",
      "Stopping early at epoch 548\n",
      "Stopping early at epoch 549\n",
      "Stopping early at epoch 550\n",
      "Stopping early at epoch 551\n",
      "Stopping early at epoch 552\n",
      "Stopping early at epoch 553\n",
      "Stopping early at epoch 554\n",
      "Stopping early at epoch 555\n",
      "Stopping early at epoch 556\n",
      "Stopping early at epoch 557\n",
      "Stopping early at epoch 558\n",
      "Stopping early at epoch 559\n",
      "Stopping early at epoch 560\n",
      "Stopping early at epoch 561\n",
      "Stopping early at epoch 562\n",
      "Stopping early at epoch 563\n",
      "Stopping early at epoch 564\n",
      "Stopping early at epoch 565\n",
      "Stopping early at epoch 566\n",
      "Stopping early at epoch 567\n",
      "Stopping early at epoch 568\n",
      "Stopping early at epoch 569\n",
      "Stopping early at epoch 570\n",
      "Stopping early at epoch 571\n",
      "Stopping early at epoch 572\n",
      "Stopping early at epoch 573\n",
      "Stopping early at epoch 574\n",
      "Stopping early at epoch 575\n",
      "Stopping early at epoch 576\n",
      "Stopping early at epoch 577\n",
      "Stopping early at epoch 578\n",
      "Stopping early at epoch 579\n",
      "Stopping early at epoch 580\n",
      "Stopping early at epoch 581\n",
      "Stopping early at epoch 582\n",
      "Stopping early at epoch 583\n",
      "Stopping early at epoch 584\n",
      "Stopping early at epoch 585\n",
      "Stopping early at epoch 586\n",
      "Stopping early at epoch 587\n",
      "Stopping early at epoch 588\n",
      "Stopping early at epoch 589\n",
      "Stopping early at epoch 590\n",
      "Stopping early at epoch 591\n",
      "Stopping early at epoch 592\n",
      "Stopping early at epoch 593\n",
      "Stopping early at epoch 594\n",
      "Stopping early at epoch 595\n",
      "Stopping early at epoch 596\n",
      "Stopping early at epoch 597\n",
      "Stopping early at epoch 598\n",
      "Stopping early at epoch 599\n",
      "Stopping early at epoch 600\n",
      "Epoch: 600, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 601\n",
      "Stopping early at epoch 602\n",
      "Stopping early at epoch 603\n",
      "Stopping early at epoch 604\n",
      "Stopping early at epoch 605\n",
      "Stopping early at epoch 606\n",
      "Stopping early at epoch 607\n",
      "Stopping early at epoch 608\n",
      "Stopping early at epoch 609\n",
      "Stopping early at epoch 610\n",
      "Stopping early at epoch 611\n",
      "Stopping early at epoch 612\n",
      "Stopping early at epoch 613\n",
      "Stopping early at epoch 614\n",
      "Stopping early at epoch 615\n",
      "Stopping early at epoch 616\n",
      "Stopping early at epoch 617\n",
      "Stopping early at epoch 618\n",
      "Stopping early at epoch 619\n",
      "Stopping early at epoch 620\n",
      "Stopping early at epoch 621\n",
      "Stopping early at epoch 622\n",
      "Stopping early at epoch 623\n",
      "Stopping early at epoch 624\n",
      "Stopping early at epoch 625\n",
      "Stopping early at epoch 626\n",
      "Stopping early at epoch 627\n",
      "Stopping early at epoch 628\n",
      "Stopping early at epoch 629\n",
      "Stopping early at epoch 630\n",
      "Stopping early at epoch 631\n",
      "Stopping early at epoch 632\n",
      "Stopping early at epoch 633\n",
      "Stopping early at epoch 634\n",
      "Stopping early at epoch 635\n",
      "Stopping early at epoch 636\n",
      "Stopping early at epoch 637\n",
      "Stopping early at epoch 638\n",
      "Stopping early at epoch 639\n",
      "Stopping early at epoch 640\n",
      "Stopping early at epoch 641\n",
      "Stopping early at epoch 642\n",
      "Stopping early at epoch 643\n",
      "Stopping early at epoch 644\n",
      "Stopping early at epoch 645\n",
      "Stopping early at epoch 646\n",
      "Stopping early at epoch 647\n",
      "Stopping early at epoch 648\n",
      "Stopping early at epoch 649\n",
      "Stopping early at epoch 650\n",
      "Stopping early at epoch 651\n",
      "Stopping early at epoch 652\n",
      "Stopping early at epoch 653\n",
      "Stopping early at epoch 654\n",
      "Stopping early at epoch 655\n",
      "Stopping early at epoch 656\n",
      "Stopping early at epoch 657\n",
      "Stopping early at epoch 658\n",
      "Stopping early at epoch 659\n",
      "Stopping early at epoch 660\n",
      "Stopping early at epoch 661\n",
      "Stopping early at epoch 662\n",
      "Stopping early at epoch 663\n",
      "Stopping early at epoch 664\n",
      "Stopping early at epoch 665\n",
      "Stopping early at epoch 666\n",
      "Stopping early at epoch 667\n",
      "Stopping early at epoch 668\n",
      "Stopping early at epoch 669\n",
      "Stopping early at epoch 670\n",
      "Stopping early at epoch 671\n",
      "Stopping early at epoch 672\n",
      "Stopping early at epoch 673\n",
      "Stopping early at epoch 674\n",
      "Stopping early at epoch 675\n",
      "Stopping early at epoch 676\n",
      "Stopping early at epoch 677\n",
      "Stopping early at epoch 678\n",
      "Stopping early at epoch 679\n",
      "Stopping early at epoch 680\n",
      "Stopping early at epoch 681\n",
      "Stopping early at epoch 682\n",
      "Stopping early at epoch 683\n",
      "Stopping early at epoch 684\n",
      "Stopping early at epoch 685\n",
      "Stopping early at epoch 686\n",
      "Stopping early at epoch 687\n",
      "Stopping early at epoch 688\n",
      "Stopping early at epoch 689\n",
      "Stopping early at epoch 690\n",
      "Stopping early at epoch 691\n",
      "Stopping early at epoch 692\n",
      "Stopping early at epoch 693\n",
      "Stopping early at epoch 694\n",
      "Stopping early at epoch 695\n",
      "Stopping early at epoch 696\n",
      "Stopping early at epoch 697\n",
      "Stopping early at epoch 698\n",
      "Stopping early at epoch 699\n",
      "Stopping early at epoch 700\n",
      "Epoch: 700, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 701\n",
      "Stopping early at epoch 702\n",
      "Stopping early at epoch 703\n",
      "Stopping early at epoch 704\n",
      "Stopping early at epoch 705\n",
      "Stopping early at epoch 706\n",
      "Stopping early at epoch 707\n",
      "Stopping early at epoch 708\n",
      "Stopping early at epoch 709\n",
      "Stopping early at epoch 710\n",
      "Stopping early at epoch 711\n",
      "Stopping early at epoch 712\n",
      "Stopping early at epoch 713\n",
      "Stopping early at epoch 714\n",
      "Stopping early at epoch 715\n",
      "Stopping early at epoch 716\n",
      "Stopping early at epoch 717\n",
      "Stopping early at epoch 718\n",
      "Stopping early at epoch 719\n",
      "Stopping early at epoch 720\n",
      "Stopping early at epoch 721\n",
      "Stopping early at epoch 722\n",
      "Stopping early at epoch 723\n",
      "Stopping early at epoch 724\n",
      "Stopping early at epoch 725\n",
      "Stopping early at epoch 726\n",
      "Stopping early at epoch 727\n",
      "Stopping early at epoch 728\n",
      "Stopping early at epoch 729\n",
      "Stopping early at epoch 730\n",
      "Stopping early at epoch 731\n",
      "Stopping early at epoch 732\n",
      "Stopping early at epoch 733\n",
      "Stopping early at epoch 734\n",
      "Stopping early at epoch 735\n",
      "Stopping early at epoch 736\n",
      "Stopping early at epoch 737\n",
      "Stopping early at epoch 738\n",
      "Stopping early at epoch 739\n",
      "Stopping early at epoch 740\n",
      "Stopping early at epoch 741\n",
      "Stopping early at epoch 742\n",
      "Stopping early at epoch 743\n",
      "Stopping early at epoch 744\n",
      "Stopping early at epoch 745\n",
      "Stopping early at epoch 746\n",
      "Stopping early at epoch 747\n",
      "Stopping early at epoch 748\n",
      "Stopping early at epoch 749\n",
      "Stopping early at epoch 750\n",
      "Stopping early at epoch 751\n",
      "Stopping early at epoch 752\n",
      "Stopping early at epoch 753\n",
      "Stopping early at epoch 754\n",
      "Stopping early at epoch 755\n",
      "Stopping early at epoch 756\n",
      "Stopping early at epoch 757\n",
      "Stopping early at epoch 758\n",
      "Stopping early at epoch 759\n",
      "Stopping early at epoch 760\n",
      "Stopping early at epoch 761\n",
      "Stopping early at epoch 762\n",
      "Stopping early at epoch 763\n",
      "Stopping early at epoch 764\n",
      "Stopping early at epoch 765\n",
      "Stopping early at epoch 766\n",
      "Stopping early at epoch 767\n",
      "Stopping early at epoch 768\n",
      "Stopping early at epoch 769\n",
      "Stopping early at epoch 770\n",
      "Stopping early at epoch 771\n",
      "Stopping early at epoch 772\n",
      "Stopping early at epoch 773\n",
      "Stopping early at epoch 774\n",
      "Stopping early at epoch 775\n",
      "Stopping early at epoch 776\n",
      "Stopping early at epoch 777\n",
      "Stopping early at epoch 778\n",
      "Stopping early at epoch 779\n",
      "Stopping early at epoch 780\n",
      "Stopping early at epoch 781\n",
      "Stopping early at epoch 782\n",
      "Stopping early at epoch 783\n",
      "Stopping early at epoch 784\n",
      "Stopping early at epoch 785\n",
      "Stopping early at epoch 786\n",
      "Stopping early at epoch 787\n",
      "Stopping early at epoch 788\n",
      "Stopping early at epoch 789\n",
      "Stopping early at epoch 790\n",
      "Stopping early at epoch 791\n",
      "Stopping early at epoch 792\n",
      "Stopping early at epoch 793\n",
      "Stopping early at epoch 794\n",
      "Stopping early at epoch 795\n",
      "Stopping early at epoch 796\n",
      "Stopping early at epoch 797\n",
      "Stopping early at epoch 798\n",
      "Stopping early at epoch 799\n",
      "Stopping early at epoch 800\n",
      "Epoch: 800, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 801\n",
      "Stopping early at epoch 802\n",
      "Stopping early at epoch 803\n",
      "Stopping early at epoch 804\n",
      "Stopping early at epoch 805\n",
      "Stopping early at epoch 806\n",
      "Stopping early at epoch 807\n",
      "Stopping early at epoch 808\n",
      "Stopping early at epoch 809\n",
      "Stopping early at epoch 810\n",
      "Stopping early at epoch 811\n",
      "Stopping early at epoch 812\n",
      "Stopping early at epoch 813\n",
      "Stopping early at epoch 814\n",
      "Stopping early at epoch 815\n",
      "Stopping early at epoch 816\n",
      "Stopping early at epoch 817\n",
      "Stopping early at epoch 818\n",
      "Stopping early at epoch 819\n",
      "Stopping early at epoch 820\n",
      "Stopping early at epoch 821\n",
      "Stopping early at epoch 822\n",
      "Stopping early at epoch 823\n",
      "Stopping early at epoch 824\n",
      "Stopping early at epoch 825\n",
      "Stopping early at epoch 826\n",
      "Stopping early at epoch 827\n",
      "Stopping early at epoch 828\n",
      "Stopping early at epoch 829\n",
      "Stopping early at epoch 830\n",
      "Stopping early at epoch 831\n",
      "Stopping early at epoch 832\n",
      "Stopping early at epoch 833\n",
      "Stopping early at epoch 834\n",
      "Stopping early at epoch 835\n",
      "Stopping early at epoch 836\n",
      "Stopping early at epoch 837\n",
      "Stopping early at epoch 838\n",
      "Stopping early at epoch 839\n",
      "Stopping early at epoch 840\n",
      "Stopping early at epoch 841\n",
      "Stopping early at epoch 842\n",
      "Stopping early at epoch 843\n",
      "Stopping early at epoch 844\n",
      "Stopping early at epoch 845\n",
      "Stopping early at epoch 846\n",
      "Stopping early at epoch 847\n",
      "Stopping early at epoch 848\n",
      "Stopping early at epoch 849\n",
      "Stopping early at epoch 850\n",
      "Stopping early at epoch 851\n",
      "Stopping early at epoch 852\n",
      "Stopping early at epoch 853\n",
      "Stopping early at epoch 854\n",
      "Stopping early at epoch 855\n",
      "Stopping early at epoch 856\n",
      "Stopping early at epoch 857\n",
      "Stopping early at epoch 858\n",
      "Stopping early at epoch 859\n",
      "Stopping early at epoch 860\n",
      "Stopping early at epoch 861\n",
      "Stopping early at epoch 862\n",
      "Stopping early at epoch 863\n",
      "Stopping early at epoch 864\n",
      "Stopping early at epoch 865\n",
      "Stopping early at epoch 866\n",
      "Stopping early at epoch 867\n",
      "Stopping early at epoch 868\n",
      "Stopping early at epoch 869\n",
      "Stopping early at epoch 870\n",
      "Stopping early at epoch 871\n",
      "Stopping early at epoch 872\n",
      "Stopping early at epoch 873\n",
      "Stopping early at epoch 874\n",
      "Stopping early at epoch 875\n",
      "Stopping early at epoch 876\n",
      "Stopping early at epoch 877\n",
      "Stopping early at epoch 878\n",
      "Stopping early at epoch 879\n",
      "Stopping early at epoch 880\n",
      "Stopping early at epoch 881\n",
      "Stopping early at epoch 882\n",
      "Stopping early at epoch 883\n",
      "Stopping early at epoch 884\n",
      "Stopping early at epoch 885\n",
      "Stopping early at epoch 886\n",
      "Stopping early at epoch 887\n",
      "Stopping early at epoch 888\n",
      "Stopping early at epoch 889\n",
      "Stopping early at epoch 890\n",
      "Stopping early at epoch 891\n",
      "Stopping early at epoch 892\n",
      "Stopping early at epoch 893\n",
      "Stopping early at epoch 894\n",
      "Stopping early at epoch 895\n",
      "Stopping early at epoch 896\n",
      "Stopping early at epoch 897\n",
      "Stopping early at epoch 898\n",
      "Stopping early at epoch 899\n",
      "Stopping early at epoch 900\n",
      "Epoch: 900, Cumulative Loss: -716.0\n",
      "Stopping early at epoch 901\n",
      "Stopping early at epoch 902\n",
      "Stopping early at epoch 903\n",
      "Stopping early at epoch 904\n",
      "Stopping early at epoch 905\n",
      "Stopping early at epoch 906\n",
      "Stopping early at epoch 907\n",
      "Stopping early at epoch 908\n",
      "Stopping early at epoch 909\n",
      "Stopping early at epoch 910\n",
      "Stopping early at epoch 911\n",
      "Stopping early at epoch 912\n",
      "Stopping early at epoch 913\n",
      "Stopping early at epoch 914\n",
      "Stopping early at epoch 915\n",
      "Stopping early at epoch 916\n",
      "Stopping early at epoch 917\n",
      "Stopping early at epoch 918\n",
      "Stopping early at epoch 919\n",
      "Stopping early at epoch 920\n",
      "Stopping early at epoch 921\n",
      "Stopping early at epoch 922\n",
      "Stopping early at epoch 923\n",
      "Stopping early at epoch 924\n",
      "Stopping early at epoch 925\n",
      "Stopping early at epoch 926\n",
      "Stopping early at epoch 927\n",
      "Stopping early at epoch 928\n",
      "Stopping early at epoch 929\n",
      "Stopping early at epoch 930\n",
      "Stopping early at epoch 931\n",
      "Stopping early at epoch 932\n",
      "Stopping early at epoch 933\n",
      "Stopping early at epoch 934\n",
      "Stopping early at epoch 935\n",
      "Stopping early at epoch 936\n",
      "Stopping early at epoch 937\n",
      "Stopping early at epoch 938\n",
      "Stopping early at epoch 939\n",
      "Stopping early at epoch 940\n",
      "Stopping early at epoch 941\n",
      "Stopping early at epoch 942\n",
      "Stopping early at epoch 943\n",
      "Stopping early at epoch 944\n",
      "Stopping early at epoch 945\n",
      "Stopping early at epoch 946\n",
      "Stopping early at epoch 947\n",
      "Stopping early at epoch 948\n",
      "Stopping early at epoch 949\n",
      "Stopping early at epoch 950\n",
      "Stopping early at epoch 951\n",
      "Stopping early at epoch 952\n",
      "Stopping early at epoch 953\n",
      "Stopping early at epoch 954\n",
      "Stopping early at epoch 955\n",
      "Stopping early at epoch 956\n",
      "Stopping early at epoch 957\n",
      "Stopping early at epoch 958\n",
      "Stopping early at epoch 959\n",
      "Stopping early at epoch 960\n",
      "Stopping early at epoch 961\n",
      "Stopping early at epoch 962\n",
      "Stopping early at epoch 963\n",
      "Stopping early at epoch 964\n",
      "Stopping early at epoch 965\n",
      "Stopping early at epoch 966\n",
      "Stopping early at epoch 967\n",
      "Stopping early at epoch 968\n",
      "Stopping early at epoch 969\n",
      "Stopping early at epoch 970\n",
      "Stopping early at epoch 971\n",
      "Stopping early at epoch 972\n",
      "Stopping early at epoch 973\n",
      "Stopping early at epoch 974\n",
      "Stopping early at epoch 975\n",
      "Stopping early at epoch 976\n",
      "Stopping early at epoch 977\n",
      "Stopping early at epoch 978\n",
      "Stopping early at epoch 979\n",
      "Stopping early at epoch 980\n",
      "Stopping early at epoch 981\n",
      "Stopping early at epoch 982\n",
      "Stopping early at epoch 983\n",
      "Stopping early at epoch 984\n",
      "Stopping early at epoch 985\n",
      "Stopping early at epoch 986\n",
      "Stopping early at epoch 987\n",
      "Stopping early at epoch 988\n",
      "Stopping early at epoch 989\n",
      "Stopping early at epoch 990\n",
      "Stopping early at epoch 991\n",
      "Stopping early at epoch 992\n",
      "Stopping early at epoch 993\n",
      "Stopping early at epoch 994\n",
      "Stopping early at epoch 995\n",
      "Stopping early at epoch 996\n",
      "Stopping early at epoch 997\n",
      "Stopping early at epoch 998\n",
      "Stopping early at epoch 999\n",
      "GNN training took 901.987 seconds.\n",
      "Best cumulative loss: -136124.0\n"
     ]
    }
   ],
   "source": [
    "trained_net, bestLost, epoch, inp, lossList = train1('_80MaxwayCut_LossExp2_loss.pth', './testData/nx_generated_graph_n500_d3_t200.pkl', 500)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exp 3 - loss\n",
    "\n",
    "- expriment 3 of modifying the loss function (purely binary input) and find exact loss value (vectorized)\n",
    "- removing terminal loss\n",
    "- graph n=1000, d=3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def max_to_one_hot(tensor):\n",
    "    # Find the index of the maximum value\n",
    "    max_index = torch.argmax(tensor)\n",
    "\n",
    "    # Create a one-hot encoded tensor\n",
    "    one_hot_tensor = torch.zeros_like(tensor)\n",
    "    one_hot_tensor[max_index] = 1.0\n",
    "\n",
    "    one_hot_tensor = one_hot_tensor + tensor - tensor.detach()\n",
    "\n",
    "    return one_hot_tensor\n",
    "\n",
    "def apply_max_to_one_hot(output):\n",
    "    return torch.stack([max_to_one_hot(output[i]) for i in range(output.size(0))])\n",
    "\n",
    "\n",
    "def run_gnn_training2(dataset, net, optimizer, number_epochs, tol, patience, loss_func, dim_embedding, total_classes=3, save_directory=None, torch_dtype = TORCH_DTYPE, torch_device = TORCH_DEVICE, labels=None):\n",
    "    \"\"\"\n",
    "    Train a GCN model with early stopping.\n",
    "    \"\"\"\n",
    "    # loss for a whole epoch\n",
    "    prev_loss = float('inf')  # Set initial loss to infinity for comparison\n",
    "    prev_cummulative_loss = float('inf')\n",
    "    cummulativeCount = 0\n",
    "    count = 0  # Patience counter\n",
    "    best_loss = float('inf')  # Initialize best loss to infinity\n",
    "    best_model_state = None  # Placeholder for the best model state\n",
    "    loss_list = []\n",
    "    epochList = []\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    t_gnn_start = time()\n",
    "\n",
    "    # contains information regarding all terminal nodes for the dataset\n",
    "    terminal_configs = {}\n",
    "    epochCount = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    A = nn.Parameter(torch.tensor([65.0]))\n",
    "    C = nn.Parameter(torch.tensor([32.5]))\n",
    "\n",
    "    embed = nn.Embedding(1000, dim_embedding)\n",
    "    embed = embed.type(torch_dtype).to(torch_device)\n",
    "    inputs = embed.weight\n",
    "\n",
    "    for epoch in range(number_epochs):\n",
    "\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss for each epoch\n",
    "\n",
    "        for key, (dgl_graph, adjacency_matrix,graph, terminals) in dataset.items():\n",
    "            epochCount +=1\n",
    "\n",
    "\n",
    "            # Ensure model is in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Pass the graph and the input features to the model\n",
    "            logits = net(dgl_graph, adjacency_matrix)\n",
    "            logits = override_fixed_nodes(logits)\n",
    "            # Apply max to one-hot encoding\n",
    "            one_hot_output = apply_max_to_one_hot(logits)\n",
    "            # Compute the loss\n",
    "            # loss = loss_func(criterion, logits, labels, terminals[0], terminals[1])\n",
    "\n",
    "            loss = loss_func( one_hot_output, adjacency_matrix)\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update cumulative loss\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            # # Check for early stopping\n",
    "            if epoch > 0 and (cumulative_loss > prev_loss or abs(prev_loss - cumulative_loss) <= tol):\n",
    "                count += 1\n",
    "                if count >= patience: # play around with patience value, try lower one\n",
    "                    print(f'Stopping early at epoch {epoch}')\n",
    "                    break\n",
    "            else:\n",
    "                count = 0  # Reset patience counter if loss decreases\n",
    "\n",
    "            # Update best model\n",
    "            if cumulative_loss < best_loss:\n",
    "                best_loss = cumulative_loss\n",
    "                best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        # # Early stopping break from the outer loop\n",
    "        # if count >= patience:\n",
    "        #     count=0\n",
    "\n",
    "        prev_loss = cumulative_loss  # Update previous loss\n",
    "\n",
    "        if epoch % 100 == 0:  # Adjust printing frequency as needed\n",
    "            print(f'Epoch: {epoch}, Cumulative Loss: {cumulative_loss}')\n",
    "\n",
    "            if save_directory != None:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model': net.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lossList':loss_list,\n",
    "                    'inputs':inputs}\n",
    "                torch.save(checkpoint, './epoch'+str(epoch)+'loss'+str(cumulative_loss)+ save_directory)\n",
    "\n",
    "            if (prev_cummulative_loss == cummulativeCount):\n",
    "                cummulativeCount+=1\n",
    "\n",
    "                if cummulativeCount > 4:\n",
    "                    break\n",
    "            else:\n",
    "                prev_cummulative_loss = cumulative_loss\n",
    "\n",
    "\n",
    "    t_gnn = time() - t_gnn_start\n",
    "\n",
    "    # Load the best model state\n",
    "    if best_model_state is not None:\n",
    "        net.load_state_dict(best_model_state)\n",
    "\n",
    "    print(f'GNN training took {round(t_gnn, 3)} seconds.')\n",
    "    print(f'Best cumulative loss: {best_loss}')\n",
    "    loss = loss_func(logits, adjacency_matrix)\n",
    "    if save_directory != None:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lossList':loss_list,\n",
    "            'inputs':inputs}\n",
    "        torch.save(checkpoint, './final_'+save_directory)\n",
    "\n",
    "    return net, best_loss, epoch, inputs, loss_list\n",
    "\n",
    "class GCNSoftmax(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes, dropout, device):\n",
    "        super(GCNSoftmax, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Basic forward pass\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.softmax(h, dim=1)  # Apply softmax over the classes dimension\n",
    "        # h = F.sigmoid(h)\n",
    "        # h = override_fixed_nodes(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "def override_fixed_nodes(h):\n",
    "    output = h.clone()\n",
    "    # Set the output for node 0 to [1, 0, 0]\n",
    "    output[200] = torch.tensor([1.0, 0.0, 0.0],requires_grad=True) + h[200] - h[200].detach()\n",
    "    # Set the output for node 1 to [0, 1, 0]\n",
    "    output[400] = torch.tensor([0.0, 1.0, 0.0],requires_grad=True)+ h[400] - h[400].detach()\n",
    "    # Set the output for node 2 to [0, 0, 1]\n",
    "    output[700] = torch.tensor([0.0, 0.0, 1.0],requires_grad=True)+ h[700] - h[700].detach()\n",
    "    return output\n",
    "\n",
    "def calculate_HC_vectorized(s, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute the minimum cut loss, which is the total weight of edges cut between partitions using vectorized operations.\n",
    "\n",
    "    Parameters:\n",
    "    s (torch.Tensor): Binary partition matrix of shape (num_nodes, num_partitions)\n",
    "    adjacency_matrix (torch.Tensor): Adjacency matrix of the graph of shape (num_nodes, num_nodes)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Scalar loss value representing the total weight of edges cut\n",
    "    \"\"\"\n",
    "    num_nodes, num_partitions = s.shape\n",
    "\n",
    "    # Compute the partition probability matrix for all partitions\n",
    "    partition_prob_matrix = s @ s.T\n",
    "\n",
    "    # Compute the cut value by summing weights of edges that connect nodes in different partitions\n",
    "    cut_value = adjacency_matrix * (1 - partition_prob_matrix)\n",
    "\n",
    "    # Sum up the contributions for all edges\n",
    "    loss = torch.sum(cut_value) / 2  # Divide by 2 to correct for double-counting\n",
    "\n",
    "    return loss\n",
    "\n",
    "def Loss(s, adjacency_matrix,  A=1, C=1):\n",
    "    HC = -1*calculate_HC_vectorized(s, adjacency_matrix)\n",
    "    return C * HC\n",
    "\n",
    "\n",
    "def loss_terminal(s, adjacency_matrix,  A=0, C=1, penalty=1000):\n",
    "    loss = Loss(s, adjacency_matrix, A, C)\n",
    "    # loss += penalty* terminal_independence_penalty(s, [0,1,2])\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cumulative Loss: -240338.0\n",
      "Stopping early at epoch 1\n",
      "Stopping early at epoch 2\n",
      "Stopping early at epoch 4\n",
      "Stopping early at epoch 5\n",
      "Stopping early at epoch 7\n",
      "Stopping early at epoch 8\n",
      "Stopping early at epoch 9\n",
      "Stopping early at epoch 11\n",
      "Stopping early at epoch 12\n",
      "Stopping early at epoch 14\n",
      "Stopping early at epoch 15\n",
      "Stopping early at epoch 16\n",
      "Stopping early at epoch 18\n",
      "Stopping early at epoch 19\n",
      "Stopping early at epoch 21\n",
      "Stopping early at epoch 22\n",
      "Stopping early at epoch 23\n",
      "Stopping early at epoch 24\n",
      "Stopping early at epoch 26\n",
      "Stopping early at epoch 27\n",
      "Stopping early at epoch 29\n",
      "Stopping early at epoch 30\n",
      "Stopping early at epoch 32\n",
      "Stopping early at epoch 33\n",
      "Stopping early at epoch 34\n",
      "Stopping early at epoch 36\n",
      "Stopping early at epoch 37\n",
      "Stopping early at epoch 38\n",
      "Stopping early at epoch 39\n",
      "Stopping early at epoch 41\n",
      "Stopping early at epoch 42\n",
      "Stopping early at epoch 44\n",
      "Stopping early at epoch 45\n",
      "Stopping early at epoch 47\n",
      "Stopping early at epoch 48\n",
      "Stopping early at epoch 50\n",
      "Stopping early at epoch 51\n",
      "Stopping early at epoch 53\n",
      "Stopping early at epoch 54\n",
      "Stopping early at epoch 55\n",
      "Stopping early at epoch 57\n",
      "Stopping early at epoch 58\n",
      "Stopping early at epoch 59\n",
      "Stopping early at epoch 60\n",
      "Stopping early at epoch 62\n",
      "Stopping early at epoch 63\n",
      "Stopping early at epoch 64\n",
      "Stopping early at epoch 65\n",
      "Stopping early at epoch 67\n",
      "Stopping early at epoch 68\n",
      "Stopping early at epoch 69\n",
      "Stopping early at epoch 71\n",
      "Stopping early at epoch 72\n",
      "Stopping early at epoch 73\n",
      "Stopping early at epoch 75\n",
      "Stopping early at epoch 76\n",
      "Stopping early at epoch 78\n",
      "Stopping early at epoch 79\n",
      "Stopping early at epoch 81\n",
      "Stopping early at epoch 82\n",
      "Stopping early at epoch 84\n",
      "Stopping early at epoch 85\n",
      "Stopping early at epoch 86\n",
      "Stopping early at epoch 87\n",
      "Stopping early at epoch 88\n",
      "Stopping early at epoch 90\n",
      "Stopping early at epoch 91\n",
      "Stopping early at epoch 92\n",
      "Stopping early at epoch 93\n",
      "Stopping early at epoch 94\n",
      "Stopping early at epoch 95\n",
      "Stopping early at epoch 96\n",
      "Stopping early at epoch 97\n",
      "Stopping early at epoch 98\n",
      "Stopping early at epoch 100\n",
      "Epoch: 100, Cumulative Loss: -27640.0\n",
      "Stopping early at epoch 101\n",
      "Stopping early at epoch 102\n",
      "Stopping early at epoch 103\n",
      "Stopping early at epoch 104\n",
      "Stopping early at epoch 106\n",
      "Stopping early at epoch 107\n",
      "Stopping early at epoch 108\n",
      "Stopping early at epoch 109\n",
      "Stopping early at epoch 110\n",
      "Stopping early at epoch 111\n",
      "Stopping early at epoch 112\n",
      "Stopping early at epoch 113\n",
      "Stopping early at epoch 114\n",
      "Stopping early at epoch 115\n",
      "Stopping early at epoch 117\n",
      "Stopping early at epoch 118\n",
      "Stopping early at epoch 119\n",
      "Stopping early at epoch 120\n",
      "Stopping early at epoch 121\n",
      "Stopping early at epoch 122\n",
      "Stopping early at epoch 123\n",
      "Stopping early at epoch 125\n",
      "Stopping early at epoch 126\n",
      "Stopping early at epoch 127\n",
      "Stopping early at epoch 128\n",
      "Stopping early at epoch 130\n",
      "Stopping early at epoch 131\n",
      "Stopping early at epoch 132\n",
      "Stopping early at epoch 134\n",
      "Stopping early at epoch 135\n",
      "Stopping early at epoch 136\n",
      "Stopping early at epoch 137\n",
      "Stopping early at epoch 138\n",
      "Stopping early at epoch 139\n",
      "Stopping early at epoch 141\n",
      "Stopping early at epoch 142\n",
      "Stopping early at epoch 143\n",
      "Stopping early at epoch 144\n",
      "Stopping early at epoch 145\n",
      "Stopping early at epoch 146\n",
      "Stopping early at epoch 147\n",
      "Stopping early at epoch 149\n",
      "Stopping early at epoch 150\n",
      "Stopping early at epoch 151\n",
      "Stopping early at epoch 152\n",
      "Stopping early at epoch 153\n",
      "Stopping early at epoch 155\n",
      "Stopping early at epoch 156\n",
      "Stopping early at epoch 158\n",
      "Stopping early at epoch 159\n",
      "Stopping early at epoch 160\n",
      "Stopping early at epoch 161\n",
      "Stopping early at epoch 162\n",
      "Stopping early at epoch 164\n",
      "Stopping early at epoch 165\n",
      "Stopping early at epoch 166\n",
      "Stopping early at epoch 168\n",
      "Stopping early at epoch 169\n",
      "Stopping early at epoch 170\n",
      "Stopping early at epoch 171\n",
      "Stopping early at epoch 172\n",
      "Stopping early at epoch 173\n",
      "Stopping early at epoch 174\n",
      "Stopping early at epoch 175\n",
      "Stopping early at epoch 176\n",
      "Stopping early at epoch 177\n",
      "Stopping early at epoch 178\n",
      "Stopping early at epoch 179\n",
      "Stopping early at epoch 181\n",
      "Stopping early at epoch 182\n",
      "Stopping early at epoch 183\n",
      "Stopping early at epoch 184\n",
      "Stopping early at epoch 185\n",
      "Stopping early at epoch 186\n",
      "Stopping early at epoch 187\n",
      "Stopping early at epoch 188\n",
      "Stopping early at epoch 190\n",
      "Stopping early at epoch 191\n",
      "Stopping early at epoch 192\n",
      "Stopping early at epoch 193\n",
      "Stopping early at epoch 194\n",
      "Stopping early at epoch 195\n",
      "Stopping early at epoch 196\n",
      "Stopping early at epoch 198\n",
      "Stopping early at epoch 199\n",
      "Stopping early at epoch 200\n",
      "Epoch: 200, Cumulative Loss: -1430.0\n",
      "Stopping early at epoch 201\n",
      "Stopping early at epoch 202\n",
      "Stopping early at epoch 203\n",
      "Stopping early at epoch 204\n",
      "Stopping early at epoch 205\n",
      "Stopping early at epoch 206\n",
      "Stopping early at epoch 207\n",
      "Stopping early at epoch 209\n",
      "Stopping early at epoch 210\n",
      "Stopping early at epoch 211\n",
      "Stopping early at epoch 212\n",
      "Stopping early at epoch 213\n",
      "Stopping early at epoch 214\n",
      "Stopping early at epoch 216\n",
      "Stopping early at epoch 217\n",
      "Stopping early at epoch 218\n",
      "Stopping early at epoch 219\n",
      "Stopping early at epoch 220\n",
      "Stopping early at epoch 222\n",
      "Stopping early at epoch 223\n",
      "Stopping early at epoch 224\n",
      "Stopping early at epoch 225\n",
      "Stopping early at epoch 226\n",
      "Stopping early at epoch 227\n",
      "Stopping early at epoch 228\n",
      "Stopping early at epoch 229\n",
      "Stopping early at epoch 230\n",
      "Stopping early at epoch 231\n",
      "Stopping early at epoch 232\n",
      "Stopping early at epoch 233\n",
      "Stopping early at epoch 234\n",
      "Stopping early at epoch 236\n",
      "Stopping early at epoch 237\n",
      "Stopping early at epoch 238\n",
      "Stopping early at epoch 240\n",
      "Stopping early at epoch 241\n",
      "Stopping early at epoch 243\n",
      "Stopping early at epoch 244\n",
      "Stopping early at epoch 245\n",
      "Stopping early at epoch 246\n",
      "Stopping early at epoch 247\n",
      "Stopping early at epoch 248\n",
      "Stopping early at epoch 249\n",
      "Stopping early at epoch 250\n",
      "Stopping early at epoch 251\n",
      "Stopping early at epoch 252\n",
      "Stopping early at epoch 253\n",
      "Stopping early at epoch 254\n",
      "Stopping early at epoch 255\n",
      "Stopping early at epoch 256\n",
      "Stopping early at epoch 257\n",
      "Stopping early at epoch 259\n",
      "Stopping early at epoch 260\n",
      "Stopping early at epoch 261\n",
      "Stopping early at epoch 262\n",
      "Stopping early at epoch 263\n",
      "Stopping early at epoch 264\n",
      "Stopping early at epoch 265\n",
      "Stopping early at epoch 266\n",
      "Stopping early at epoch 267\n",
      "Stopping early at epoch 268\n",
      "Stopping early at epoch 269\n",
      "Stopping early at epoch 270\n",
      "Stopping early at epoch 271\n",
      "Stopping early at epoch 272\n",
      "Stopping early at epoch 273\n",
      "Stopping early at epoch 274\n",
      "Stopping early at epoch 275\n",
      "Stopping early at epoch 277\n",
      "Stopping early at epoch 278\n",
      "Stopping early at epoch 279\n",
      "Stopping early at epoch 280\n",
      "Stopping early at epoch 281\n",
      "Stopping early at epoch 283\n",
      "Stopping early at epoch 284\n",
      "Stopping early at epoch 285\n",
      "Stopping early at epoch 286\n",
      "Stopping early at epoch 287\n",
      "Stopping early at epoch 288\n",
      "Stopping early at epoch 289\n",
      "Stopping early at epoch 290\n",
      "Stopping early at epoch 291\n",
      "Stopping early at epoch 292\n",
      "Stopping early at epoch 293\n",
      "Stopping early at epoch 294\n",
      "Stopping early at epoch 295\n",
      "Stopping early at epoch 296\n",
      "Stopping early at epoch 297\n",
      "Stopping early at epoch 298\n",
      "Stopping early at epoch 299\n",
      "Stopping early at epoch 300\n",
      "Epoch: 300, Cumulative Loss: -1434.0\n",
      "Stopping early at epoch 301\n",
      "Stopping early at epoch 303\n",
      "Stopping early at epoch 304\n",
      "Stopping early at epoch 305\n",
      "Stopping early at epoch 306\n",
      "Stopping early at epoch 307\n",
      "Stopping early at epoch 308\n",
      "Stopping early at epoch 309\n",
      "Stopping early at epoch 310\n",
      "Stopping early at epoch 311\n",
      "Stopping early at epoch 312\n",
      "Stopping early at epoch 313\n",
      "Stopping early at epoch 314\n",
      "Stopping early at epoch 315\n",
      "Stopping early at epoch 316\n",
      "Stopping early at epoch 317\n",
      "Stopping early at epoch 318\n",
      "Stopping early at epoch 319\n",
      "Stopping early at epoch 320\n",
      "Stopping early at epoch 321\n",
      "Stopping early at epoch 322\n",
      "Stopping early at epoch 323\n",
      "Stopping early at epoch 324\n",
      "Stopping early at epoch 325\n",
      "Stopping early at epoch 326\n",
      "Stopping early at epoch 327\n",
      "Stopping early at epoch 328\n",
      "Stopping early at epoch 329\n",
      "Stopping early at epoch 330\n",
      "Stopping early at epoch 331\n",
      "Stopping early at epoch 332\n",
      "Stopping early at epoch 333\n",
      "Stopping early at epoch 334\n",
      "Stopping early at epoch 335\n",
      "Stopping early at epoch 336\n",
      "Stopping early at epoch 338\n",
      "Stopping early at epoch 339\n",
      "Stopping early at epoch 340\n",
      "Stopping early at epoch 341\n",
      "Stopping early at epoch 342\n",
      "Stopping early at epoch 343\n",
      "Stopping early at epoch 344\n",
      "Stopping early at epoch 345\n",
      "Stopping early at epoch 347\n",
      "Stopping early at epoch 348\n",
      "Stopping early at epoch 349\n",
      "Stopping early at epoch 350\n",
      "Stopping early at epoch 351\n",
      "Stopping early at epoch 353\n",
      "Stopping early at epoch 354\n",
      "Stopping early at epoch 355\n",
      "Stopping early at epoch 356\n",
      "Stopping early at epoch 357\n",
      "Stopping early at epoch 358\n",
      "Stopping early at epoch 359\n",
      "Stopping early at epoch 360\n",
      "Stopping early at epoch 362\n",
      "Stopping early at epoch 363\n",
      "Stopping early at epoch 364\n",
      "Stopping early at epoch 365\n",
      "Stopping early at epoch 366\n",
      "Stopping early at epoch 367\n",
      "Stopping early at epoch 368\n",
      "Stopping early at epoch 369\n",
      "Stopping early at epoch 370\n",
      "Stopping early at epoch 371\n",
      "Stopping early at epoch 372\n",
      "Stopping early at epoch 373\n",
      "Stopping early at epoch 374\n",
      "Stopping early at epoch 375\n",
      "Stopping early at epoch 376\n",
      "Stopping early at epoch 377\n",
      "Stopping early at epoch 378\n",
      "Stopping early at epoch 379\n",
      "Stopping early at epoch 380\n",
      "Stopping early at epoch 381\n",
      "Stopping early at epoch 382\n",
      "Stopping early at epoch 383\n",
      "Stopping early at epoch 384\n",
      "Stopping early at epoch 385\n",
      "Stopping early at epoch 386\n",
      "Stopping early at epoch 387\n",
      "Stopping early at epoch 388\n",
      "Stopping early at epoch 389\n",
      "Stopping early at epoch 390\n",
      "Stopping early at epoch 391\n",
      "Stopping early at epoch 392\n",
      "Stopping early at epoch 393\n",
      "Stopping early at epoch 394\n",
      "Stopping early at epoch 395\n",
      "Stopping early at epoch 396\n",
      "Stopping early at epoch 397\n",
      "Stopping early at epoch 398\n",
      "Stopping early at epoch 399\n",
      "Stopping early at epoch 400\n",
      "Epoch: 400, Cumulative Loss: -1435.0\n",
      "Stopping early at epoch 401\n",
      "Stopping early at epoch 402\n",
      "Stopping early at epoch 403\n",
      "Stopping early at epoch 404\n",
      "Stopping early at epoch 405\n",
      "Stopping early at epoch 406\n",
      "Stopping early at epoch 407\n",
      "Stopping early at epoch 408\n",
      "Stopping early at epoch 409\n",
      "Stopping early at epoch 410\n",
      "Stopping early at epoch 411\n",
      "Stopping early at epoch 412\n",
      "Stopping early at epoch 413\n",
      "Stopping early at epoch 414\n",
      "Stopping early at epoch 415\n",
      "Stopping early at epoch 416\n",
      "Stopping early at epoch 417\n",
      "Stopping early at epoch 419\n",
      "Stopping early at epoch 420\n",
      "Stopping early at epoch 421\n",
      "Stopping early at epoch 422\n",
      "Stopping early at epoch 423\n",
      "Stopping early at epoch 425\n",
      "Stopping early at epoch 426\n",
      "Stopping early at epoch 427\n",
      "Stopping early at epoch 428\n",
      "Stopping early at epoch 429\n",
      "Stopping early at epoch 430\n",
      "Stopping early at epoch 431\n",
      "Stopping early at epoch 432\n",
      "Stopping early at epoch 433\n",
      "Stopping early at epoch 435\n",
      "Stopping early at epoch 436\n",
      "Stopping early at epoch 437\n",
      "Stopping early at epoch 438\n",
      "Stopping early at epoch 440\n",
      "Stopping early at epoch 441\n",
      "Stopping early at epoch 442\n",
      "Stopping early at epoch 443\n",
      "Stopping early at epoch 444\n",
      "Stopping early at epoch 445\n",
      "Stopping early at epoch 446\n",
      "Stopping early at epoch 447\n",
      "Stopping early at epoch 448\n",
      "Stopping early at epoch 449\n",
      "Stopping early at epoch 450\n",
      "Stopping early at epoch 451\n",
      "Stopping early at epoch 452\n",
      "Stopping early at epoch 453\n",
      "Stopping early at epoch 454\n",
      "Stopping early at epoch 455\n",
      "Stopping early at epoch 456\n",
      "Stopping early at epoch 457\n",
      "Stopping early at epoch 458\n",
      "Stopping early at epoch 459\n",
      "Stopping early at epoch 460\n",
      "Stopping early at epoch 461\n",
      "Stopping early at epoch 462\n",
      "Stopping early at epoch 463\n",
      "Stopping early at epoch 464\n",
      "Stopping early at epoch 465\n",
      "Stopping early at epoch 466\n",
      "Stopping early at epoch 467\n",
      "Stopping early at epoch 468\n",
      "Stopping early at epoch 469\n",
      "Stopping early at epoch 470\n",
      "Stopping early at epoch 471\n",
      "Stopping early at epoch 472\n",
      "Stopping early at epoch 473\n",
      "Stopping early at epoch 474\n",
      "Stopping early at epoch 475\n",
      "Stopping early at epoch 476\n",
      "Stopping early at epoch 477\n",
      "Stopping early at epoch 478\n",
      "Stopping early at epoch 479\n",
      "Stopping early at epoch 480\n",
      "Stopping early at epoch 481\n",
      "Stopping early at epoch 482\n",
      "Stopping early at epoch 483\n",
      "Stopping early at epoch 484\n",
      "Stopping early at epoch 485\n",
      "Stopping early at epoch 486\n",
      "Stopping early at epoch 487\n",
      "Stopping early at epoch 488\n",
      "Stopping early at epoch 489\n",
      "Stopping early at epoch 490\n",
      "Stopping early at epoch 491\n",
      "Stopping early at epoch 492\n",
      "Stopping early at epoch 493\n",
      "Stopping early at epoch 494\n",
      "Stopping early at epoch 495\n",
      "Stopping early at epoch 496\n",
      "Stopping early at epoch 497\n",
      "Stopping early at epoch 498\n",
      "Stopping early at epoch 499\n",
      "Stopping early at epoch 500\n",
      "Epoch: 500, Cumulative Loss: -1437.0\n",
      "Stopping early at epoch 501\n",
      "Stopping early at epoch 502\n",
      "Stopping early at epoch 503\n",
      "Stopping early at epoch 504\n",
      "Stopping early at epoch 506\n",
      "Stopping early at epoch 507\n",
      "Stopping early at epoch 508\n",
      "Stopping early at epoch 509\n",
      "Stopping early at epoch 510\n",
      "Stopping early at epoch 512\n",
      "Stopping early at epoch 513\n",
      "Stopping early at epoch 514\n",
      "Stopping early at epoch 515\n",
      "Stopping early at epoch 516\n",
      "Stopping early at epoch 517\n",
      "Stopping early at epoch 518\n",
      "Stopping early at epoch 519\n",
      "Stopping early at epoch 520\n",
      "Stopping early at epoch 521\n",
      "Stopping early at epoch 522\n",
      "Stopping early at epoch 523\n",
      "Stopping early at epoch 524\n",
      "Stopping early at epoch 525\n",
      "Stopping early at epoch 526\n",
      "Stopping early at epoch 527\n",
      "Stopping early at epoch 528\n",
      "Stopping early at epoch 529\n",
      "Stopping early at epoch 530\n",
      "Stopping early at epoch 531\n",
      "Stopping early at epoch 532\n",
      "Stopping early at epoch 533\n",
      "Stopping early at epoch 534\n",
      "Stopping early at epoch 535\n",
      "Stopping early at epoch 536\n",
      "Stopping early at epoch 537\n",
      "Stopping early at epoch 538\n",
      "Stopping early at epoch 539\n",
      "Stopping early at epoch 540\n",
      "Stopping early at epoch 541\n",
      "Stopping early at epoch 542\n",
      "Stopping early at epoch 543\n",
      "Stopping early at epoch 544\n",
      "Stopping early at epoch 545\n",
      "Stopping early at epoch 546\n",
      "Stopping early at epoch 547\n",
      "Stopping early at epoch 548\n",
      "Stopping early at epoch 549\n",
      "Stopping early at epoch 550\n",
      "Stopping early at epoch 551\n",
      "Stopping early at epoch 552\n",
      "Stopping early at epoch 553\n",
      "Stopping early at epoch 554\n",
      "Stopping early at epoch 555\n",
      "Stopping early at epoch 556\n",
      "Stopping early at epoch 557\n",
      "Stopping early at epoch 558\n",
      "Stopping early at epoch 559\n",
      "Stopping early at epoch 560\n",
      "Stopping early at epoch 561\n",
      "Stopping early at epoch 562\n",
      "Stopping early at epoch 563\n",
      "Stopping early at epoch 564\n",
      "Stopping early at epoch 565\n",
      "Stopping early at epoch 566\n",
      "Stopping early at epoch 567\n",
      "Stopping early at epoch 568\n",
      "Stopping early at epoch 569\n",
      "Stopping early at epoch 570\n",
      "Stopping early at epoch 571\n",
      "Stopping early at epoch 572\n",
      "Stopping early at epoch 573\n",
      "Stopping early at epoch 574\n",
      "Stopping early at epoch 575\n",
      "Stopping early at epoch 576\n",
      "Stopping early at epoch 577\n",
      "Stopping early at epoch 578\n",
      "Stopping early at epoch 579\n",
      "Stopping early at epoch 580\n",
      "Stopping early at epoch 581\n",
      "Stopping early at epoch 582\n",
      "Stopping early at epoch 583\n",
      "Stopping early at epoch 584\n",
      "Stopping early at epoch 585\n",
      "Stopping early at epoch 586\n",
      "Stopping early at epoch 587\n",
      "Stopping early at epoch 588\n",
      "Stopping early at epoch 589\n",
      "Stopping early at epoch 590\n",
      "Stopping early at epoch 591\n",
      "Stopping early at epoch 592\n",
      "Stopping early at epoch 593\n",
      "Stopping early at epoch 594\n",
      "Stopping early at epoch 595\n",
      "Stopping early at epoch 596\n",
      "Stopping early at epoch 597\n",
      "Stopping early at epoch 598\n",
      "Stopping early at epoch 599\n",
      "Stopping early at epoch 600\n",
      "Epoch: 600, Cumulative Loss: -1439.0\n",
      "Stopping early at epoch 601\n",
      "Stopping early at epoch 602\n",
      "Stopping early at epoch 603\n",
      "Stopping early at epoch 604\n",
      "Stopping early at epoch 605\n",
      "Stopping early at epoch 606\n",
      "Stopping early at epoch 607\n",
      "Stopping early at epoch 608\n",
      "Stopping early at epoch 609\n",
      "Stopping early at epoch 610\n",
      "Stopping early at epoch 611\n",
      "Stopping early at epoch 612\n",
      "Stopping early at epoch 613\n",
      "Stopping early at epoch 614\n",
      "Stopping early at epoch 615\n",
      "Stopping early at epoch 616\n",
      "Stopping early at epoch 617\n",
      "Stopping early at epoch 618\n",
      "Stopping early at epoch 619\n",
      "Stopping early at epoch 621\n",
      "Stopping early at epoch 622\n",
      "Stopping early at epoch 623\n",
      "Stopping early at epoch 624\n",
      "Stopping early at epoch 625\n",
      "Stopping early at epoch 626\n",
      "Stopping early at epoch 627\n",
      "Stopping early at epoch 628\n",
      "Stopping early at epoch 629\n",
      "Stopping early at epoch 630\n",
      "Stopping early at epoch 631\n",
      "Stopping early at epoch 632\n",
      "Stopping early at epoch 633\n",
      "Stopping early at epoch 634\n",
      "Stopping early at epoch 635\n",
      "Stopping early at epoch 636\n",
      "Stopping early at epoch 637\n",
      "Stopping early at epoch 638\n",
      "Stopping early at epoch 639\n",
      "Stopping early at epoch 640\n",
      "Stopping early at epoch 641\n",
      "Stopping early at epoch 642\n",
      "Stopping early at epoch 643\n",
      "Stopping early at epoch 644\n",
      "Stopping early at epoch 645\n",
      "Stopping early at epoch 646\n",
      "Stopping early at epoch 647\n",
      "Stopping early at epoch 648\n",
      "Stopping early at epoch 649\n",
      "Stopping early at epoch 650\n",
      "Stopping early at epoch 651\n",
      "Stopping early at epoch 652\n",
      "Stopping early at epoch 653\n",
      "Stopping early at epoch 654\n",
      "Stopping early at epoch 655\n",
      "Stopping early at epoch 656\n",
      "Stopping early at epoch 657\n",
      "Stopping early at epoch 658\n",
      "Stopping early at epoch 660\n",
      "Stopping early at epoch 661\n",
      "Stopping early at epoch 662\n",
      "Stopping early at epoch 663\n",
      "Stopping early at epoch 665\n",
      "Stopping early at epoch 666\n",
      "Stopping early at epoch 667\n",
      "Stopping early at epoch 669\n",
      "Stopping early at epoch 670\n",
      "Stopping early at epoch 671\n",
      "Stopping early at epoch 672\n",
      "Stopping early at epoch 673\n",
      "Stopping early at epoch 674\n",
      "Stopping early at epoch 675\n",
      "Stopping early at epoch 676\n",
      "Stopping early at epoch 677\n",
      "Stopping early at epoch 678\n",
      "Stopping early at epoch 679\n",
      "Stopping early at epoch 680\n",
      "Stopping early at epoch 681\n",
      "Stopping early at epoch 682\n",
      "Stopping early at epoch 683\n",
      "Stopping early at epoch 684\n",
      "Stopping early at epoch 685\n",
      "Stopping early at epoch 686\n",
      "Stopping early at epoch 687\n",
      "Stopping early at epoch 688\n",
      "Stopping early at epoch 689\n",
      "Stopping early at epoch 691\n",
      "Stopping early at epoch 692\n",
      "Stopping early at epoch 693\n",
      "Stopping early at epoch 694\n",
      "Stopping early at epoch 695\n",
      "Stopping early at epoch 696\n",
      "Stopping early at epoch 698\n",
      "Stopping early at epoch 699\n",
      "Stopping early at epoch 700\n",
      "Epoch: 700, Cumulative Loss: -1441.0\n",
      "Stopping early at epoch 701\n",
      "Stopping early at epoch 702\n",
      "Stopping early at epoch 703\n",
      "Stopping early at epoch 704\n",
      "Stopping early at epoch 705\n",
      "Stopping early at epoch 707\n",
      "Stopping early at epoch 708\n",
      "Stopping early at epoch 709\n",
      "Stopping early at epoch 710\n",
      "Stopping early at epoch 711\n",
      "Stopping early at epoch 713\n",
      "Stopping early at epoch 714\n",
      "Stopping early at epoch 715\n",
      "Stopping early at epoch 716\n",
      "Stopping early at epoch 717\n",
      "Stopping early at epoch 718\n",
      "Stopping early at epoch 719\n",
      "Stopping early at epoch 720\n",
      "Stopping early at epoch 721\n",
      "Stopping early at epoch 722\n",
      "Stopping early at epoch 723\n",
      "Stopping early at epoch 724\n",
      "Stopping early at epoch 725\n",
      "Stopping early at epoch 726\n",
      "Stopping early at epoch 727\n",
      "Stopping early at epoch 728\n",
      "Stopping early at epoch 729\n",
      "Stopping early at epoch 730\n",
      "Stopping early at epoch 731\n",
      "Stopping early at epoch 732\n",
      "Stopping early at epoch 733\n",
      "Stopping early at epoch 734\n",
      "Stopping early at epoch 735\n",
      "Stopping early at epoch 736\n",
      "Stopping early at epoch 737\n",
      "Stopping early at epoch 738\n",
      "Stopping early at epoch 739\n",
      "Stopping early at epoch 740\n",
      "Stopping early at epoch 741\n",
      "Stopping early at epoch 742\n",
      "Stopping early at epoch 743\n",
      "Stopping early at epoch 744\n",
      "Stopping early at epoch 745\n",
      "Stopping early at epoch 746\n",
      "Stopping early at epoch 747\n",
      "Stopping early at epoch 748\n",
      "Stopping early at epoch 749\n",
      "Stopping early at epoch 750\n",
      "Stopping early at epoch 751\n",
      "Stopping early at epoch 752\n",
      "Stopping early at epoch 753\n",
      "Stopping early at epoch 754\n",
      "Stopping early at epoch 755\n",
      "Stopping early at epoch 756\n",
      "Stopping early at epoch 757\n",
      "Stopping early at epoch 758\n",
      "Stopping early at epoch 759\n",
      "Stopping early at epoch 760\n",
      "Stopping early at epoch 761\n",
      "Stopping early at epoch 762\n",
      "Stopping early at epoch 763\n",
      "Stopping early at epoch 764\n",
      "Stopping early at epoch 765\n",
      "Stopping early at epoch 766\n",
      "Stopping early at epoch 767\n",
      "Stopping early at epoch 768\n",
      "Stopping early at epoch 769\n",
      "Stopping early at epoch 770\n",
      "Stopping early at epoch 771\n",
      "Stopping early at epoch 772\n",
      "Stopping early at epoch 773\n",
      "Stopping early at epoch 774\n",
      "Stopping early at epoch 775\n",
      "Stopping early at epoch 776\n",
      "Stopping early at epoch 777\n",
      "Stopping early at epoch 778\n",
      "Stopping early at epoch 779\n",
      "Stopping early at epoch 780\n",
      "Stopping early at epoch 781\n",
      "Stopping early at epoch 782\n",
      "Stopping early at epoch 783\n",
      "Stopping early at epoch 784\n",
      "Stopping early at epoch 785\n",
      "Stopping early at epoch 786\n",
      "Stopping early at epoch 787\n",
      "Stopping early at epoch 789\n",
      "Stopping early at epoch 790\n",
      "Stopping early at epoch 791\n",
      "Stopping early at epoch 792\n",
      "Stopping early at epoch 794\n",
      "Stopping early at epoch 795\n",
      "Stopping early at epoch 797\n",
      "Stopping early at epoch 798\n",
      "Stopping early at epoch 799\n",
      "Stopping early at epoch 800\n",
      "Epoch: 800, Cumulative Loss: -1444.0\n",
      "Stopping early at epoch 801\n",
      "Stopping early at epoch 802\n",
      "Stopping early at epoch 803\n",
      "Stopping early at epoch 804\n",
      "Stopping early at epoch 805\n",
      "Stopping early at epoch 806\n",
      "Stopping early at epoch 807\n",
      "Stopping early at epoch 808\n",
      "Stopping early at epoch 809\n",
      "Stopping early at epoch 810\n",
      "Stopping early at epoch 811\n",
      "Stopping early at epoch 812\n",
      "Stopping early at epoch 813\n",
      "Stopping early at epoch 814\n",
      "Stopping early at epoch 815\n",
      "Stopping early at epoch 816\n",
      "Stopping early at epoch 817\n",
      "Stopping early at epoch 818\n",
      "Stopping early at epoch 819\n",
      "Stopping early at epoch 820\n",
      "Stopping early at epoch 821\n",
      "Stopping early at epoch 822\n",
      "Stopping early at epoch 823\n",
      "Stopping early at epoch 824\n",
      "Stopping early at epoch 825\n",
      "Stopping early at epoch 826\n",
      "Stopping early at epoch 827\n",
      "Stopping early at epoch 828\n",
      "Stopping early at epoch 829\n",
      "Stopping early at epoch 830\n",
      "Stopping early at epoch 831\n",
      "Stopping early at epoch 832\n",
      "Stopping early at epoch 833\n",
      "Stopping early at epoch 834\n",
      "Stopping early at epoch 835\n",
      "Stopping early at epoch 836\n",
      "Stopping early at epoch 837\n",
      "Stopping early at epoch 838\n",
      "Stopping early at epoch 839\n",
      "Stopping early at epoch 840\n",
      "Stopping early at epoch 841\n",
      "Stopping early at epoch 842\n",
      "Stopping early at epoch 843\n",
      "Stopping early at epoch 844\n",
      "Stopping early at epoch 845\n",
      "Stopping early at epoch 846\n",
      "Stopping early at epoch 847\n",
      "Stopping early at epoch 848\n",
      "Stopping early at epoch 849\n",
      "Stopping early at epoch 850\n",
      "Stopping early at epoch 851\n",
      "Stopping early at epoch 852\n",
      "Stopping early at epoch 853\n",
      "Stopping early at epoch 854\n",
      "Stopping early at epoch 855\n",
      "Stopping early at epoch 856\n",
      "Stopping early at epoch 857\n",
      "Stopping early at epoch 858\n",
      "Stopping early at epoch 859\n",
      "Stopping early at epoch 860\n",
      "Stopping early at epoch 861\n",
      "Stopping early at epoch 862\n",
      "Stopping early at epoch 863\n",
      "Stopping early at epoch 864\n",
      "Stopping early at epoch 865\n",
      "Stopping early at epoch 866\n",
      "Stopping early at epoch 867\n",
      "Stopping early at epoch 869\n",
      "Stopping early at epoch 870\n",
      "Stopping early at epoch 871\n",
      "Stopping early at epoch 872\n",
      "Stopping early at epoch 873\n",
      "Stopping early at epoch 874\n",
      "Stopping early at epoch 875\n",
      "Stopping early at epoch 876\n",
      "Stopping early at epoch 877\n",
      "Stopping early at epoch 878\n",
      "Stopping early at epoch 879\n",
      "Stopping early at epoch 880\n",
      "Stopping early at epoch 881\n",
      "Stopping early at epoch 882\n",
      "Stopping early at epoch 883\n",
      "Stopping early at epoch 884\n",
      "Stopping early at epoch 885\n",
      "Stopping early at epoch 886\n",
      "Stopping early at epoch 887\n",
      "Stopping early at epoch 888\n",
      "Stopping early at epoch 889\n",
      "Stopping early at epoch 890\n",
      "Stopping early at epoch 891\n",
      "Stopping early at epoch 892\n",
      "Stopping early at epoch 893\n",
      "Stopping early at epoch 894\n",
      "Stopping early at epoch 895\n",
      "Stopping early at epoch 896\n",
      "Stopping early at epoch 897\n",
      "Stopping early at epoch 898\n",
      "Stopping early at epoch 899\n",
      "Stopping early at epoch 900\n",
      "Epoch: 900, Cumulative Loss: -1445.0\n",
      "Stopping early at epoch 901\n",
      "Stopping early at epoch 903\n",
      "Stopping early at epoch 904\n",
      "Stopping early at epoch 905\n",
      "Stopping early at epoch 906\n",
      "Stopping early at epoch 907\n",
      "Stopping early at epoch 908\n",
      "Stopping early at epoch 909\n",
      "Stopping early at epoch 910\n",
      "Stopping early at epoch 911\n",
      "Stopping early at epoch 913\n",
      "Stopping early at epoch 914\n",
      "Stopping early at epoch 915\n",
      "Stopping early at epoch 916\n",
      "Stopping early at epoch 917\n",
      "Stopping early at epoch 918\n",
      "Stopping early at epoch 919\n",
      "Stopping early at epoch 920\n",
      "Stopping early at epoch 921\n",
      "Stopping early at epoch 922\n",
      "Stopping early at epoch 923\n",
      "Stopping early at epoch 924\n",
      "Stopping early at epoch 925\n",
      "Stopping early at epoch 926\n",
      "Stopping early at epoch 927\n",
      "Stopping early at epoch 928\n",
      "Stopping early at epoch 929\n",
      "Stopping early at epoch 930\n",
      "Stopping early at epoch 931\n",
      "Stopping early at epoch 932\n",
      "Stopping early at epoch 933\n",
      "Stopping early at epoch 934\n",
      "Stopping early at epoch 935\n",
      "Stopping early at epoch 936\n",
      "Stopping early at epoch 937\n",
      "Stopping early at epoch 938\n",
      "Stopping early at epoch 939\n",
      "Stopping early at epoch 940\n",
      "Stopping early at epoch 941\n",
      "Stopping early at epoch 942\n",
      "Stopping early at epoch 943\n",
      "Stopping early at epoch 944\n",
      "Stopping early at epoch 945\n",
      "Stopping early at epoch 946\n",
      "Stopping early at epoch 947\n",
      "Stopping early at epoch 948\n",
      "Stopping early at epoch 949\n",
      "Stopping early at epoch 950\n",
      "Stopping early at epoch 951\n",
      "Stopping early at epoch 952\n",
      "Stopping early at epoch 953\n",
      "Stopping early at epoch 954\n",
      "Stopping early at epoch 955\n",
      "Stopping early at epoch 956\n",
      "Stopping early at epoch 957\n",
      "Stopping early at epoch 958\n",
      "Stopping early at epoch 959\n",
      "Stopping early at epoch 960\n",
      "Stopping early at epoch 961\n",
      "Stopping early at epoch 962\n",
      "Stopping early at epoch 963\n",
      "Stopping early at epoch 964\n",
      "Stopping early at epoch 965\n",
      "Stopping early at epoch 966\n",
      "Stopping early at epoch 967\n",
      "Stopping early at epoch 968\n",
      "Stopping early at epoch 969\n",
      "Stopping early at epoch 970\n",
      "Stopping early at epoch 971\n",
      "Stopping early at epoch 972\n",
      "Stopping early at epoch 973\n",
      "Stopping early at epoch 974\n",
      "Stopping early at epoch 975\n",
      "Stopping early at epoch 976\n",
      "Stopping early at epoch 977\n",
      "Stopping early at epoch 978\n",
      "Stopping early at epoch 979\n",
      "Stopping early at epoch 980\n",
      "Stopping early at epoch 981\n",
      "Stopping early at epoch 982\n",
      "Stopping early at epoch 983\n",
      "Stopping early at epoch 985\n",
      "Stopping early at epoch 986\n",
      "Stopping early at epoch 987\n",
      "Stopping early at epoch 988\n",
      "Stopping early at epoch 989\n",
      "Stopping early at epoch 990\n",
      "Stopping early at epoch 991\n",
      "Stopping early at epoch 992\n",
      "Stopping early at epoch 993\n",
      "Stopping early at epoch 994\n",
      "Stopping early at epoch 995\n",
      "Stopping early at epoch 996\n",
      "Stopping early at epoch 997\n",
      "Stopping early at epoch 998\n",
      "Stopping early at epoch 999\n",
      "GNN training took 2565.387 seconds.\n",
      "Best cumulative loss: -278073.0\n"
     ]
    }
   ],
   "source": [
    "trained_net, bestLost, epoch, inp, lossList = train1('_10000MaxwayCut_LossExp3_loss.pth', './testData/nx_generated_graph_n1000_d3_t200.pkl', 1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}