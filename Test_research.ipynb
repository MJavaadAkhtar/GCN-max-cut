{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minimum_cut"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.4946],\n         [0.4946],\n         [0.4946],\n         [0.4946]], grad_fn=<TanhBackward0>),\n tensor(0.0005, grad_fn=<AddBackward0>))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "from itertools import chain, islice, combinations\n",
    "\n",
    "class GCN_dev(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, number_classes, dropout, device):\n",
    "        super(GCN_dev, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, number_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = torch.tanh(h)\n",
    "        return h\n",
    "\n",
    "# Manual run of the Hamiltonian loss function on the graph we created earlier\n",
    "\n",
    "# Create a simple DGL graph\n",
    "edges = [(0, 1), (0, 2), (0, 3), (2, 3)]  # Edges as per the earlier example graph\n",
    "g = dgl.graph(edges)\n",
    "\n",
    "# Edge weight matrix as per the earlier example graph\n",
    "weights = torch.tensor([\n",
    "    [0, 1, 3, 2],\n",
    "    [1, 0, 0, 0],\n",
    "    [3, 0, 0, 1],\n",
    "    [2, 0, 1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Add self-edges to include self-connections in the GCN\n",
    "g = dgl.add_self_loop(g)\n",
    "\n",
    "# Assuming a device (for simplicity, using CPU here)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Instantiate the GCN model\n",
    "gcn_model = GCN_dev(in_feats=16, hidden_size=2, number_classes=1, dropout=0.5, device=device)\n",
    "\n",
    "#gcn_model = gcn_model.type(torch_dtype).to(torch_device)\n",
    "embed = nn.Embedding(4, 16)\n",
    "#embed = embed.type(torch_dtype).to(torch_device)\n",
    "\n",
    "# set up Adam optimizer\n",
    "params = chain(gcn_model.parameters(), embed.parameters())\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "optimizer = torch.optim.Adam(params, **opt_params)\n",
    "\n",
    "# Example input features (randomly initialized for this demonstration)\n",
    "features = torch.rand((4, 16), device=device)  # 5 nodes with 25 features each\n",
    "\n",
    "# Forward pass through the GCN\n",
    "# outputs = gcn_model(g, features)\n",
    "\n",
    "# Hamiltonian loss calculation\n",
    "def hamiltonian_loss(h, W):\n",
    "    # Compute the edge-cut term HB\n",
    "    probs_diff = torch.abs(h.unsqueeze(-1) - h.unsqueeze(0))\n",
    "    # Multiply by the weights matrix W\n",
    "    HB = torch.sum(W * probs_diff) / 2  # Divide by 2 to account for double-counting edges\n",
    "    return HB\n",
    "\n",
    "def hamiltonian_loss5(h, W):\n",
    "    # Compute the edge-cut term HB\n",
    "    probs_diff = torch.abs(h.unsqueeze(-1) - h.unsqueeze(0))\n",
    "    # Multiply by the weights matrix W\n",
    "    HB = torch.sum(W * probs_diff) / 2  # Divide by 2 to account for double-counting edges\n",
    "\n",
    "    terminal_loss = torch.abs(h[0] - h[3])\n",
    "    HB += (1 * (1 - terminal_loss))[0]\n",
    "\n",
    "    return HB\n",
    "\n",
    "def hamiltonian_loss1(h, W, A=1, B=1):\n",
    "    \"\"\"\n",
    "    Compute the Hamiltonian loss for a given set of node probabilities and edge weights.\n",
    "    This function is designed to be differentiable to retain gradients for backpropagation.\n",
    "\n",
    "    Parameters:\n",
    "    h (Tensor): The output probabilities from the GCN, should require gradient.\n",
    "    W (Tensor): The weight matrix for the edges, should not require gradient.\n",
    "    A (float): The weighting factor for the HA term.\n",
    "    B (float): The weighting factor for the HB term.\n",
    "\n",
    "    Returns:\n",
    "    Tensor: The computed Hamiltonian loss.\n",
    "    \"\"\"\n",
    "    # Convert the probabilities to 'spins'. Values > 0.5 are converted to 1, else -1.\n",
    "    spins = torch.where(h > 0.5, 1, -1).float()\n",
    "\n",
    "    # HA is a penalty term for the imbalance of vertices in two partitions\n",
    "    balance = torch.sum(spins, dim=0)  # Sum spins for balance\n",
    "    HA = balance ** 2 if balance.numel() % 2 == 0 else balance ** 2 / 2\n",
    "\n",
    "    # HB is the edge-cut term, calculated using the absolute difference of 'spins'\n",
    "    spins_diff = torch.abs(spins.unsqueeze(-1) - spins.unsqueeze(0))\n",
    "    HB = torch.sum(W * spins_diff) / 2  # Divide by 2 to account for double-counting edges\n",
    "\n",
    "    # The Hamiltonian loss is a combination of HA and HB, weighted by A and B\n",
    "    H = A * HA + B * HB\n",
    "    return H\n",
    "\n",
    "\n",
    "def hamiltonian_loss2(h, W, A=1, B=1):\n",
    "    \"\"\"\n",
    "    Compute the Hamiltonian loss for a given set of node probabilities and edge weights.\n",
    "    This function is designed to be differentiable to retain gradients for backpropagation.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    h (Tensor): The output probabilities from the GCN, should require gradient.\n",
    "    W (Tensor): The weight matrix for the edges, should not require gradient.\n",
    "    A (float): The weighting factor for the HA term.\n",
    "    B (float): The weighting factor for the HB term.\n",
    "\n",
    "    Returns:\n",
    "    Tensor: The computed Hamiltonian loss.\n",
    "    \"\"\"\n",
    "    num_nodes = h.size(0)\n",
    "    ideal_balance = num_nodes / 2.0\n",
    "\n",
    "    # HA is a penalty term for the deviation of sum of probabilities from the ideal balance\n",
    "    HA = (torch.sum(h) - ideal_balance) ** 2\n",
    "\n",
    "    # HB is the edge-cut term, calculated using the absolute difference of probabilities\n",
    "    probs_diff = torch.abs(h.unsqueeze(-1) - h.unsqueeze(0))\n",
    "    HB = torch.sum(W * probs_diff) / 2  # Divide by 2 to account for double-counting edges\n",
    "\n",
    "    # The Hamiltonian loss is a combination of HA and HB, weighted by A and B\n",
    "    H = A * HA + B * HB\n",
    "    return H\n",
    "# # Calculate the loss\n",
    "# loss = hamiltonian_loss(outputs, weights)\n",
    "# #loss2 = hamiltonian_loss1(outputs, weights)\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "#\n",
    "# outputs = gcn_model(g, features)\n",
    "# loss = hamiltonian_loss(outputs, weights)\n",
    "#loss2 = hamiltonian_loss1(outputs, weights)\n",
    "\n",
    "for i in range(100):\n",
    "    outputs = gcn_model(g, features)\n",
    "    loss = hamiltonian_loss2(outputs, weights)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Display the outputs and loss\n",
    "outputs, loss #, loss2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[0.5000],\n         [0.5000],\n         [0.5000],\n         [0.5000]], grad_fn=<TanhBackward0>),\n tensor(1., grad_fn=<AddBackward0>))"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN_dev(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, number_classes, dropout, device):\n",
    "        super(GCN_dev, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, number_classes).to(device)\n",
    "        self.skip_connection = nn.Linear(in_feats, number_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        x = inputs\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "\n",
    "        # Skip connection from input to output\n",
    "        skip = self.skip_connection(x)\n",
    "        h = h + skip\n",
    "\n",
    "        h = torch.tanh(h)\n",
    "        return h\n",
    "\n",
    "# Rest of your setup code remains the same...\n",
    "\n",
    "# Learning rate scheduler setup\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 500  # Number of epochs to wait before stopping without improvement\n",
    "\n",
    "for i in range(10000):\n",
    "    outputs = gcn_model(g, features)\n",
    "    loss = hamiltonian_loss5(outputs, weights)\n",
    "\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "# Display the outputs and loss\n",
    "outputs, loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 103\u001B[0m\n\u001B[1;32m    100\u001B[0m     action \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax([Q_table[(\u001B[38;5;28mtuple\u001B[39m(current_state), a)] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(g\u001B[38;5;241m.\u001B[39mnum_nodes())])\n\u001B[1;32m    102\u001B[0m \u001B[38;5;66;03m# Take the action and observe the new state and reward\u001B[39;00m\n\u001B[0;32m--> 103\u001B[0m new_state, reward \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# Update the Q-Table\u001B[39;00m\n\u001B[1;32m    106\u001B[0m old_value \u001B[38;5;241m=\u001B[39m Q_table[(\u001B[38;5;28mtuple\u001B[39m(current_state), action)]\n",
      "Cell \u001B[0;32mIn[48], line 41\u001B[0m, in \u001B[0;36mGraphEnv.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;66;03m# Action: flip the partition of a node\u001B[39;00m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate[action] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate[action]\n\u001B[0;32m---> 41\u001B[0m     new_cut_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalculate_cut_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mnew_cut_size\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, reward\n",
      "Cell \u001B[0;32mIn[48], line 50\u001B[0m, in \u001B[0;36mGraphEnv.calculate_cut_size\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     48\u001B[0m src, dst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\u001B[38;5;241m.\u001B[39medges()\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m u, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(src\u001B[38;5;241m.\u001B[39mtolist(), dst\u001B[38;5;241m.\u001B[39mtolist()):\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate[u] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate[v]:\n\u001B[1;32m     51\u001B[0m         cut_size \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights[u][v]\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cut_size\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN_dev(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, number_classes, dropout, device):\n",
    "        super(GCN_dev, self).__init__()\n",
    "        self.dropout_frac = dropout\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size).to(device)\n",
    "        self.conv2 = GraphConv(hidden_size, number_classes).to(device)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_frac, training=self.training)\n",
    "        h = self.conv2(g, h)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h\n",
    "\n",
    "# Graph environment for RL\n",
    "class GraphEnv:\n",
    "    def __init__(self, g, weights):\n",
    "        self.g = g\n",
    "        self.weights = weights\n",
    "        self.state = torch.rand((g.num_nodes(), in_feats), device=device)\n",
    "        self.num_nodes = g.num_nodes()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.rand((self.num_nodes, in_feats), device=device)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Action: flip the partition of a node\n",
    "        self.state[action] = 1 - self.state[action]\n",
    "        new_cut_size = self.calculate_cut_size()\n",
    "        reward = -new_cut_size\n",
    "        return self.state, reward\n",
    "\n",
    "    def calculate_cut_size(self):\n",
    "        # Calculate the cut size based on current state\n",
    "        cut_size = 0\n",
    "        src, dst = self.g.edges()\n",
    "        for u, v in zip(src.tolist(), dst.tolist()):\n",
    "            if self.state[u] != self.state[v]:\n",
    "                cut_size += self.weights[u][v].item()\n",
    "        return cut_size\n",
    "\n",
    "# Create a simple graph\n",
    "edges = [(0, 1), (1, 2), (2, 3), (3, 0)]  # Define the edges of the graph\n",
    "g = dgl.graph(edges)  # Create a DGL graph\n",
    "g = dgl.add_self_loop(g)  # Add self-loops\n",
    "\n",
    "# Edge weight matrix\n",
    "weights = torch.tensor([\n",
    "    [0, 1, 0, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [1, 0, 1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate the GCN model\n",
    "in_feats = 5  # Number of input features for each node\n",
    "hidden_size = 2  # Size of the hidden layer\n",
    "number_classes = 1  # Number of output classes (probabilities)\n",
    "dropout = 0.5  # Dropout rate\n",
    "\n",
    "gcn_model = GCN_dev(in_feats, hidden_size, number_classes, dropout, device).to(device)\n",
    "\n",
    "# Q-Learning Parameters\n",
    "learning_rate = 0.01\n",
    "discount_factor = 0.99\n",
    "exploration_rate = 0.1\n",
    "\n",
    "# Q-Table for storing Q-Values\n",
    "Q_table = defaultdict(float)\n",
    "\n",
    "# Instantiate the environment\n",
    "env = GraphEnv(g, weights)\n",
    "\n",
    "# Reinforcement Learning Training Loop\n",
    "for epoch in range(1000):\n",
    "    current_state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Choose an action based on the current state\n",
    "        if random.uniform(0, 1) < exploration_rate:\n",
    "            action = random.choice(range(g.num_nodes()))  # Explore\n",
    "        else:\n",
    "            # Exploit based on Q-Values\n",
    "            action = np.argmax([Q_table[(tuple(current_state), a)] for a in range(g.num_nodes())])\n",
    "\n",
    "        # Take the action and observe the new state and reward\n",
    "        new_state, reward = env.step(action)\n",
    "\n",
    "        # Update the Q-Table\n",
    "        old_value = Q_table[(tuple(current_state), action)]\n",
    "        next_max = max([Q_table[(tuple(new_state), a)] for a in range(g.num_nodes())])\n",
    "        Q_table[(tuple(current_state), action)] = old_value + learning_rate * (reward + discount_factor * next_max - old_value)\n",
    "\n",
    "        current_state = new_state\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Current Cut Size: {env.calculate_cut_size()}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}